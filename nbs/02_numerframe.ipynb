{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Custom data structure for Numerai data. Extends Pandas DataFrame.\n",
    "output-file: numerframe.html\n",
    "title: NumerFrame\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp numerframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 00:48:12.370607: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-10 00:48:12.664730: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-10 00:48:12.672194: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-10 00:48:12.672219: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-10 00:48:12.700884: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-10 00:48:13.441539: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-10 00:48:13.442058: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-10 00:48:13.442079: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import uuid\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from rich import print as rich_print\n",
    "from typing import Union, Tuple, Any, List\n",
    "\n",
    "from numerblox.misc import AttrDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview: The NumerFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NumerFrame` is a data structure that extends `pd.DataFrame` with functionality convenient for Numerai users. The main benefits include:\n",
    "1. Automatically track features, targets, prediction and other columns + easily retrieve these data slices.\n",
    "2. Add, export and import metadata. Furthermore, dynamically update or manipulate metadata within your Numerai data pipeline.\n",
    "3. Other library functionality automatically recognizes era column (`era`, `friday_date` or `date`).\n",
    "4. Integrations with other library components (i.e. `preprocessing`, `model`, `modelpipeline`, `postprocessing`, `evaluation` and `submission`) to create more solid inference pipelines and increase reliability.\n",
    "\n",
    "Besides, all functionality of Pandas DataFrames is still available in the `NumerFrame`. You therefore don't have to create new pipelines to process your data when using `NumerFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We adopt the convention:\n",
    " 1. All feature column names should start with `'feature'`.\n",
    " 2. All target column names should start with `'target'`.\n",
    " 3. All prediction column names should start with `'prediction'`.\n",
    " 4. Data should contain an `'era'`, `'friday_date'` or `'date'` column, as is almost always the case with Numerai datasets.\n",
    "\n",
    "Every column for which these conditions do not hold will be classified as an `'aux'` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NumerFrame(pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Data structure which extends Pandas DataFrames and\n",
    "    allows for additional Numerai specific functionality.\n",
    "    \"\"\"\n",
    "    _metadata = [\"meta\", \"feature_cols\", \"target_cols\",\n",
    "                 \"prediction_cols\", \"not_aux_cols\", \"aux_cols\"]\n",
    "    meta = AttrDict()\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__init_meta_attrs()\n",
    "        if not \"era_col_verified\" in self.meta:\n",
    "            self.__set_era_col()\n",
    "\n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return NumerFrame\n",
    "\n",
    "    def __init_meta_attrs(self):\n",
    "        \"\"\" Dynamically track column groups. \"\"\"\n",
    "        self.feature_cols = [col for col in self.columns if str(col).startswith(\"feature\")]\n",
    "        self.target_cols = [col for col in self.columns if str(col).startswith(\"target\")]\n",
    "        self.prediction_cols = [\n",
    "            col for col in self.columns if str(col).startswith(\"prediction\")\n",
    "        ]\n",
    "        self.not_aux_cols = self.feature_cols + self.target_cols + self.prediction_cols\n",
    "        self.aux_cols = [\n",
    "            col for col in self.columns if col not in self.not_aux_cols\n",
    "        ]\n",
    "\n",
    "    def __set_era_col(self):\n",
    "        \"\"\" Each NumerFrame should have an era column to benefit from all functionality. \"\"\"\n",
    "        if \"era\" in self.columns:\n",
    "            self.meta.era_col = \"era\"\n",
    "        elif \"friday_date\" in self.columns:\n",
    "            self.meta.era_col = \"friday_date\"\n",
    "        elif \"date\" in self.columns:\n",
    "            self.meta.era_col = \"date\"\n",
    "        else:\n",
    "            raise AttributeError(\"NumerFrame must contain either an 'era', 'friday_date' or 'date' column.\")\n",
    "        self.meta.era_col_verified = True\n",
    "\n",
    "    def add_metadata(self, *args, **kwargs):\n",
    "        \"\"\" Parse arbitrary metadata (i.e. Python objects) to the meta attribute. \"\"\"\n",
    "        self.meta.update(*args, **kwargs)\n",
    "\n",
    "    def export_json_metadata(self, file=\"config.json\", verbose=False, **kwargs):\n",
    "        \"\"\"Export all attributes in NumerFrame that can be serialized to json file.\"\"\"\n",
    "        rich_print(f\":file_folder: Exporting metadata to {file} :file_folder:\")\n",
    "        json_txt = json.dumps(\n",
    "            self.meta.__dict__, default=lambda o: \"<not serializable>\", **kwargs\n",
    "        )\n",
    "        if verbose:\n",
    "            rich_print(json_txt)\n",
    "        Path(file).write_text(json_txt)\n",
    "\n",
    "    def import_json_metadata(self, file=\"config.json\", verbose=False, **kwargs):\n",
    "        \"\"\"Load arbitrary data into NumerFrame object from json file.\"\"\"\n",
    "        rich_print(f\":file_folder: Importing metadata from {file} :file_folder:\")\n",
    "        with open(file) as json_file:\n",
    "            json_data = json.load(json_file, **kwargs)\n",
    "        if verbose:\n",
    "            rich_print(json_data)\n",
    "        self.meta.__dict__.update(json_data)\n",
    "\n",
    "    def get_column_selection(self, cols: Union[str, list]):\n",
    "        \"\"\" Return NumerFrame from selection of columns. \"\"\"\n",
    "        return self.loc[:, cols if isinstance(cols, list) else [cols]]\n",
    "\n",
    "    @property\n",
    "    def get_feature_data(self):\n",
    "        \"\"\" All columns for which name starts with 'target'.\"\"\"\n",
    "        return self.get_column_selection(cols=self.feature_cols)\n",
    "\n",
    "    @property\n",
    "    def get_target_data(self):\n",
    "        \"\"\" All columns for which name starts with 'target'.\"\"\"\n",
    "        return self.get_column_selection(cols=self.target_cols)\n",
    "\n",
    "    @property\n",
    "    def get_single_target_data(self):\n",
    "        \"\"\" Column with name 'target' (Main Numerai target column). \"\"\"\n",
    "        return self.get_column_selection(cols=['target'])\n",
    "\n",
    "    @property\n",
    "    def get_prediction_data(self):\n",
    "        \"\"\" All columns for which name starts with 'prediction'.\"\"\"\n",
    "        return self.get_column_selection(cols=self.prediction_cols)\n",
    "\n",
    "    @property\n",
    "    def get_aux_data(self):\n",
    "        \"\"\" All columns that are not features, targets or predictions. \"\"\"\n",
    "        return self.get_column_selection(cols=self.aux_cols)\n",
    "\n",
    "    @property\n",
    "    def get_prediction_aux_data(self):\n",
    "        \"\"\" All predictions columns and aux columns (for ensembling, etc.). \"\"\"\n",
    "        return self.get_column_selection(cols=self.prediction_cols+self.aux_cols)\n",
    "\n",
    "    def get_pattern_data(self, pattern: str):\n",
    "        \"\"\"\n",
    "        Get columns based on pattern (for example '_20' to get all 20-day Numerai targets).\n",
    "        :param pattern: A 'like' pattern (pattern in column_name == True)\n",
    "        \"\"\"\n",
    "        return self.filter(like=pattern)\n",
    "\n",
    "    def get_feature_target_pair(self, multi_target=False) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Get split of feature and target columns.\n",
    "        :param multi_target: Returns only 'target' column by default.\n",
    "        Returns all target columns when set to True.\n",
    "        \"\"\"\n",
    "        X = self.get_feature_data\n",
    "        y = self.get_target_data if multi_target else self.get_single_target_data\n",
    "        return X, y\n",
    "\n",
    "    def get_era_batch(self, eras: List[Any],\n",
    "                      convert_to_tf = False,\n",
    "                      aemlp_batch = False,\n",
    "                      features: list = None,\n",
    "                      targets: list = None,\n",
    "                      *args, **kwargs) -> tuple:\n",
    "        \"\"\"\n",
    "        Get feature target pair batch of 1 or multiple eras. \\n\n",
    "        :param eras: Selection of era names that should be present in era_col. \\n\n",
    "        :param convert_to_tf: Convert to tf.Tensor. \\n\n",
    "        :param aemlp_batch: Specific target batch for autoencoder training. \\n\n",
    "        `y` output will contain three components: features, targets and targets. \\n\n",
    "        :param features: List of features to select. All by default \\n\n",
    "        :param targets: List of targets to select. All by default. \\n\n",
    "        *args, **kwargs are passed to initialization of Tensor.\n",
    "        \"\"\"\n",
    "        valid_eras = []\n",
    "        for era in eras:\n",
    "            assert era in self[self.meta.era_col].unique(), f\"Era '{era}' not found in era column ({self.meta.era_col})\"\n",
    "            valid_eras.append(era)\n",
    "        features = features if features else self.feature_cols\n",
    "        targets = targets if targets else self.target_cols\n",
    "        X = self.loc[self[self.meta.era_col].isin(valid_eras)][features].values\n",
    "        y = self.loc[self[self.meta.era_col].isin(valid_eras)][targets].values\n",
    "        if aemlp_batch:\n",
    "            y = [X.copy(), y.copy(), y.copy()]\n",
    "\n",
    "        if convert_to_tf:\n",
    "            X = tf.convert_to_tensor(X, *args, **kwargs)\n",
    "            if aemlp_batch:\n",
    "                y = [tf.convert_to_tensor(i, *args, **kwargs) for i in y]\n",
    "            else:\n",
    "                y = tf.convert_to_tensor(y, *args, **kwargs)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`create_numerframe` automatically recognizes your data file format, loads it into a `NumerFrame`, allows for column selection before loading and optionally adds metadata.\n",
    "\n",
    "Support file formats are `.csv`, `.parquet`, `.pkl`, `.pickle`, `.xsl`, `.xslx`, `.xlsm`, `.xlsb`, `.odf`, `.ods` and `.odt`. If the file format for your use case is missing, feel free to create a Github issue or submit a pull request. See `README.md` for more information on contributing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_numerframe(file_path: str, metadata: dict = None, columns: list = None, *args, **kwargs) -> NumerFrame:\n",
    "    \"\"\"\n",
    "    Convenient function to initialize NumerFrame.\n",
    "    Support most used file formats for Pandas DataFrames \\n\n",
    "    (.csv, .parquet, .xls, .pkl, etc.).\n",
    "    For more details check https://pandas.pydata.org/docs/reference/io.html\n",
    "\n",
    "    :param file_path: Relative or absolute path to data file. \\n\n",
    "    :param metadata: Metadata to be stored in NumerFrame.meta. \\n\n",
    "    :param columns: Which columns to read (All by default). \\n\n",
    "    *args, **kwargs will be passed to Pandas loading function.\n",
    "    \"\"\"\n",
    "    assert Path(file_path).is_file(), f\"{file_path} does not point to file.\"\n",
    "    suffix = Path(file_path).suffix\n",
    "    if suffix in [\".csv\"]:\n",
    "        df = pd.read_csv(file_path, usecols=columns, *args, **kwargs)\n",
    "    elif suffix in [\".parquet\"]:\n",
    "        df = pd.read_parquet(file_path, columns=columns, *args, **kwargs)\n",
    "    elif suffix in [\".xls\", \".xlsx\", \".xlsm\", \"xlsb\", \".odf\", \".ods\", \".odt\"]:\n",
    "        df = pd.read_excel(file_path, usecols=columns, *args, **kwargs)\n",
    "    elif suffix in ['.pkl', '.pickle']:\n",
    "        df = pd.read_pickle(file_path, *args, **kwargs)\n",
    "        df = df.loc[:, columns] if columns else df\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Suffix '{suffix}' is not supported.\")\n",
    "    num_frame = NumerFrame(df)\n",
    "    if metadata:\n",
    "        num_frame.add_metadata(metadata)\n",
    "    return num_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumerFrame Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `NumerFrame` object can be initialized from memory just like you would with a Pandas DataFrame.\n",
    "You then have the option to add metadata with `.add_metadata`. All metadata will be stored in the `meta` attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialize from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = [f\"feature_{l}\" for l in \"ABCDEFGHIK\"]\n",
    "id_col = [uuid.uuid4().hex for _ in range(100)]\n",
    "\n",
    "# Random DataFrame\n",
    "dataf = pd.DataFrame(np.random.uniform(size=(100, 10)), columns=test_features)\n",
    "dataf[\"id\"] = id_col\n",
    "dataf[[\"target\", \"target_1\", \"target_2\"]] = np.random.normal(size=(100, 3))\n",
    "dataf[\"date\"] = range(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"version\": 42,\n",
    "    \"additional_info\": \"test_model\",\n",
    "    \"multi_target\": False,\n",
    "    \"tournament_type\": \"random\",\n",
    "}\n",
    "memory_dataf = NumerFrame(dataf)\n",
    "memory_dataf.add_metadata(metadata)\n",
    "assert memory_dataf.meta.version == 42\n",
    "assert memory_dataf.meta.tournament_type == \"random\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata stored in `.meta` and can be accessed as a dictionary or as attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'era_col': 'date',\n",
       " 'era_col_verified': True,\n",
       " 'version': 42,\n",
       " 'additional_info': 'test_model',\n",
       " 'multi_target': False,\n",
       " 'tournament_type': 'random'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_dataf.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_dataf.meta.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_dataf.meta['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert memory_dataf.meta.version == memory_dataf.meta['version']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize from file path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the convenience function `create_numerframe` so `NumerFrame` can be easily initialized. Think of it as a dynamic `pd.read_csv`, `pd.read_parquet`, etc. where you can also directly pass metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"version\": 2,\n",
    "    \"multi_target\": False,\n",
    "    \"tournament_type\": \"classic\",\n",
    "    \"era_col\": \"era\"\n",
    "}\n",
    "\n",
    "num_dataf = create_numerframe(\"test_assets/mini_numerai_version_2_data.parquet\",\n",
    "                          metadata=metadata\n",
    "                          )\n",
    "assert num_dataf.meta.version == 2\n",
    "assert num_dataf.meta.era_col == \"era\"\n",
    "assert not num_dataf.meta.multi_target\n",
    "num_dataf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Example functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataf.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.get_feature_data` will retrieve all columns where the column name starts with `feature`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataf.get_feature_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.get_target_data` retrieves all columns if the column name starts with `\"target\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataf.get_target_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.get_single_target_data` only retrieves the column `\"target\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataf.get_single_target_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.get_pattern_data` allows you to get columns based on a certain pattern. In this example we retrieve all 20-day targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataf.get_pattern_data(\"_20\").head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.get_era_batch` will return a `tf.Tensor` or `np.array` with feature data and target data for one or more eras. Convenient for creating neural network DataGenerators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_era, y_era = num_dataf.get_era_batch(['0003'], convert_to_tf=True, dtype=tf.float16)\n",
    "X_era"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For people training autoencoders + MLP you can get a target that contains 3 elements: features, targets and targets. Just define `aemlp_batch=True`.\n",
    "More info on this setup: [AutoEncoder and multitask MLP on new dataset forum post](https://forum.numer.ai/t/autoencoder-and-multitask-mlp-on-new-dataset-from-kaggle-jane-street/4338)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y_era_aemlp = num_dataf.get_era_batch(['0003'], convert_to_tf=True, aemlp_batch=True, dtype=tf.float16)\n",
    "y_era_aemlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.aux_cols` denotes all columns that are not features, targets or prediction columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataf.aux_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataf.get_aux_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataf['prediction_1'] = np.random.uniform(size=len(num_dataf))\n",
    "num_dataf['prediction_2'] = np.random.uniform(size=len(num_dataf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To track new columns like prediction columns, make sure to initialize a new `NumerFrame`. Prediction columns can easily be retrieved with `.get_prediction_data` and `get_prediction_aux_data` if you want to also get columns like `era` and `data_type`. This can be handy for ensembling and submission use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataf = NumerFrame(num_dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataf.get_prediction_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataf.get_prediction_aux_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbitrary `.json` metadata can be stored into the `NumerFrame`. All metadata can also be exported to a `.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataf.export_json_metadata(\"config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataf.import_json_metadata(\"config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_dataf.meta.version == 2\n",
    "assert not num_dataf.meta.multi_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `NumerFrame` inherits from `pd.DataFrame` you still have all functionality of a normal DataFrame at your disposal, like copying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf2 = num_dataf.copy()\n",
    "assert dataf2.equals(num_dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NumerFrame` dynamically tracks which feature, target, aux and prediction columns there are when initialized. For example, here we add a new prediction column. Upon initialization the column will be contained in `prediction_cols`. Prediction columns are all column names that start with `prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dataf.loc[:, \"prediction_test_1\"] = np.random.uniform(size=len(num_dataf))\n",
    "new_dataset = NumerFrame(num_dataf)\n",
    "assert \"prediction_test_1\" in new_dataset.prediction_cols\n",
    "assert new_dataset.meta.version == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbitrary columns van be retrieved with `.get_column_selection`. The input argument can be either a string or a list with column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection1 = num_dataf.get_column_selection(\"era\")\n",
    "selection1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection2 = num_dataf.get_column_selection([\"era\", \"prediction_test_1\"])\n",
    "selection2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "for sel in [selection1, selection2]:\n",
    "    assert isinstance(sel, NumerFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience we can get a feature, target pair with one method. If `multi_target=True` all columns where the column name starts with `target` will be retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, single_target = num_dataf.get_feature_target_pair(multi_target=False)\n",
    "features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_target.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('numerblox')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
