{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_formatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"# default_exp model\";\n                var nbb_formatted_code = \"# default_exp model\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default_exp model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_formatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"#export\\nimport gc\\nimport uuid\\nimport joblib\\nimport numpy as np\\nfrom tqdm.auto import tqdm\\nfrom pathlib import Path\\nfrom typeguard import typechecked\\nfrom abc import ABC, abstractmethod\\nfrom rich import print as rich_print\\nimport lightgbm as lgb\\nfrom catboost import CatBoostRegressor\\n\\nfrom numerai_blocks.dataset import Dataset\\nfrom numerai_blocks.preprocessing import display_processor_info\";\n                var nbb_formatted_code = \"# export\\nimport gc\\nimport uuid\\nimport joblib\\nimport numpy as np\\nfrom tqdm.auto import tqdm\\nfrom pathlib import Path\\nfrom typeguard import typechecked\\nfrom abc import ABC, abstractmethod\\nfrom rich import print as rich_print\\nimport lightgbm as lgb\\nfrom catboost import CatBoostRegressor\\n\\nfrom numerai_blocks.dataset import Dataset\\nfrom numerai_blocks.preprocessing import display_processor_info\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "import gc\n",
    "import uuid\n",
    "import joblib\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from typeguard import typechecked\n",
    "from abc import ABC, abstractmethod\n",
    "from rich import print as rich_print\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from numerai_blocks.dataset import Dataset\n",
    "from numerai_blocks.preprocessing import display_processor_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass BaseModel(ABC):\\n    def __init__(self, model_directory: str, file_suffix: str, model_name: str = None, *args, **kwargs):\\n        self.model_directory = Path(model_directory)\\n        self.__dict__.update(*args, **kwargs)\\n        self.model_name = model_name if model_name else uuid.uuid4().hex\\n        self.prediction_col_name = f\\\"prediction_{self.model_name}\\\"\\n        self.description = f\\\"{self.__class__.__name__}: '{self.model_name}' prediction\\\"\\n\\n        self.file_suffix = file_suffix\\n        self.model_paths = self.model_directory.glob(f'*.{self.file_suffix}')\\n        self.total_models = len(self.model_paths)\\n        assert self.model_paths, f\\\"No {self.file_suffix} files found in {self.model_directory}.\\\"\\n\\n    @abstractmethod\\n    def predict(self, dataset: Dataset) -> Dataset:\\n        \\\"\\\"\\\" Return Dataset with column added for prediction. \\\"\\\"\\\"\\n        ...\\n        return Dataset(**dataset.__dict__)\\n\\n    def __call__(self, dataset: Dataset):\\n        return self.predict(dataset)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass BaseModel(ABC):\\n    def __init__(\\n        self,\\n        model_directory: str,\\n        file_suffix: str,\\n        model_name: str = None,\\n        *args,\\n        **kwargs,\\n    ):\\n        self.model_directory = Path(model_directory)\\n        self.__dict__.update(*args, **kwargs)\\n        self.model_name = model_name if model_name else uuid.uuid4().hex\\n        self.prediction_col_name = f\\\"prediction_{self.model_name}\\\"\\n        self.description = f\\\"{self.__class__.__name__}: '{self.model_name}' prediction\\\"\\n\\n        self.file_suffix = file_suffix\\n        self.model_paths = self.model_directory.glob(f\\\"*.{self.file_suffix}\\\")\\n        self.total_models = len(self.model_paths)\\n        assert (\\n            self.model_paths\\n        ), f\\\"No {self.file_suffix} files found in {self.model_directory}.\\\"\\n\\n    @abstractmethod\\n    def predict(self, dataset: Dataset) -> Dataset:\\n        \\\"\\\"\\\"Return Dataset with column added for prediction.\\\"\\\"\\\"\\n        ...\\n        return Dataset(**dataset.__dict__)\\n\\n    def __call__(self, dataset: Dataset):\\n        return self.predict(dataset)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class BaseModel(ABC):\n",
    "    def __init__(self, model_directory: str, file_suffix: str, model_name: str = None, *args, **kwargs):\n",
    "        self.model_directory = Path(model_directory)\n",
    "        self.__dict__.update(*args, **kwargs)\n",
    "        self.model_name = model_name if model_name else uuid.uuid4().hex\n",
    "        self.prediction_col_name = f\"prediction_{self.model_name}\"\n",
    "        self.description = f\"{self.__class__.__name__}: '{self.model_name}' prediction\"\n",
    "\n",
    "        self.file_suffix = file_suffix\n",
    "        self.model_paths = self.model_directory.glob(f'*.{self.file_suffix}')\n",
    "        self.total_models = len(self.model_paths)\n",
    "        if self.file_suffix:\n",
    "            assert self.model_paths, f\"No {self.file_suffix} files found in {self.model_directory}.\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, dataset: Dataset) -> Dataset:\n",
    "        \"\"\" Return Dataset with column added for prediction. \"\"\"\n",
    "        ...\n",
    "        return Dataset(**dataset.__dict__)\n",
    "\n",
    "    def __call__(self, dataset: Dataset) -> Dataset:\n",
    "        return self.predict(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Standard model formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass JoblibModel(BaseModel):\\n    \\\"\\\"\\\" Load in arbitrary models saved as .joblib. \\\"\\\"\\\"\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = \\\"joblib\\\"\\n        super(JoblibModel, self).__init__(model_directory=model_directory,\\n                                          file_suffix=file_suffix,\\n                                          model_name=model_name,\\n                                          *args, **kwargs)\\n\\n    @display_processor_info\\n    def predict(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        dataset.dataf.loc[:, self.prediction_col_name] = np.zeros(len(dataset.dataf))\\n        feature_df = dataset.get_feature_data\\n        models = self._load_models()\\n        for model in tqdm(models, desc=self.description):\\n            predictions = model.predict(feature_df, *args, **kwargs)\\n            dataset.dataf.loc[:, self.prediction_col_name] += predictions\\n        del models; gc.collect()\\n        return Dataset(**dataset.__dict__)\\n\\n    def _load_models(self) -> list:\\n        return [joblib.load(path) for path in self.model_paths]\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass JoblibModel(BaseModel):\\n    \\\"\\\"\\\"Load in arbitrary models saved as .joblib.\\\"\\\"\\\"\\n\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = \\\"joblib\\\"\\n        super(JoblibModel, self).__init__(\\n            model_directory=model_directory,\\n            file_suffix=file_suffix,\\n            model_name=model_name,\\n            *args,\\n            **kwargs\\n        )\\n\\n    @display_processor_info\\n    def predict(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        dataset.dataf.loc[:, self.prediction_col_name] = np.zeros(len(dataset.dataf))\\n        feature_df = dataset.get_feature_data\\n        models = self._load_models()\\n        for model in tqdm(models, desc=self.description):\\n            predictions = model.predict(feature_df, *args, **kwargs)\\n            dataset.dataf.loc[:, self.prediction_col_name] += predictions\\n        del models\\n        gc.collect()\\n        return Dataset(**dataset.__dict__)\\n\\n    def _load_models(self) -> list:\\n        return [joblib.load(path) for path in self.model_paths]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class JoblibModel(BaseModel):\n",
    "    \"\"\" Load in arbitrary models saved as .joblib. \"\"\"\n",
    "    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\n",
    "        file_suffix = \"joblib\"\n",
    "        super(JoblibModel, self).__init__(model_directory=model_directory,\n",
    "                                          file_suffix=file_suffix,\n",
    "                                          model_name=model_name,\n",
    "                                          *args, **kwargs)\n",
    "\n",
    "    @display_processor_info\n",
    "    def predict(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n",
    "        dataset.dataf.loc[:, self.prediction_col_name] = np.zeros(len(dataset.dataf))\n",
    "        feature_df = dataset.get_feature_data\n",
    "        models = self._load_models()\n",
    "        for model in tqdm(models, desc=self.description):\n",
    "            predictions = model.predict(feature_df, *args, **kwargs)\n",
    "            dataset.dataf.loc[:, self.prediction_col_name] += predictions\n",
    "        del models; gc.collect()\n",
    "        return Dataset(**dataset.__dict__)\n",
    "\n",
    "    def _load_models(self) -> list:\n",
    "        return [joblib.load(path) for path in self.model_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Catboost (.cbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass CatboostModel(BaseModel):\\n    \\\"\\\"\\\" Predict using .cbm models (CatBoostRegressor) with all models in directory. \\\"\\\"\\\"\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = \\\"cbm\\\"\\n        super(CatboostModel, self).__init__(model_directory=model_directory,\\n                                            file_suffix=file_suffix,\\n                                            model_name=model_name, *args, **kwargs)\\n\\n    @display_processor_info\\n    def predict(self, dataset: Dataset) -> Dataset:\\n        dataset.dataf.loc[:, f\\\"prediction_{self.model_name}\\\"] = 0\\n        feature_df = dataset.get_feature_data\\n        models = self._load_models()\\n        for model in tqdm(models, desc=self.description):\\n            predictions = model.predict(feature_df)\\n            dataset.dataf.loc[:, self.model_name] += predictions\\n        del models; gc.collect()\\n        return Dataset(**dataset.__dict__)\\n\\n    def _load_models(self) -> list:\\n        return [CatBoostRegressor().load_model(path) for path in self.model_paths]\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass CatboostModel(BaseModel):\\n    \\\"\\\"\\\"Predict using .cbm models (CatBoostRegressor) with all models in directory.\\\"\\\"\\\"\\n\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = \\\"cbm\\\"\\n        super(CatboostModel, self).__init__(\\n            model_directory=model_directory,\\n            file_suffix=file_suffix,\\n            model_name=model_name,\\n            *args,\\n            **kwargs,\\n        )\\n\\n    @display_processor_info\\n    def predict(self, dataset: Dataset) -> Dataset:\\n        dataset.dataf.loc[:, f\\\"prediction_{self.model_name}\\\"] = 0\\n        feature_df = dataset.get_feature_data\\n        models = self._load_models()\\n        for model in tqdm(models, desc=self.description):\\n            predictions = model.predict(feature_df)\\n            dataset.dataf.loc[:, self.model_name] += predictions\\n        del models\\n        gc.collect()\\n        return Dataset(**dataset.__dict__)\\n\\n    def _load_models(self) -> list:\\n        return [CatBoostRegressor().load_model(path) for path in self.model_paths]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class CatboostModel(BaseModel):\n",
    "    \"\"\" Predict using .cbm models (CatBoostRegressor) with all models in directory. \"\"\"\n",
    "    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\n",
    "        file_suffix = \"cbm\"\n",
    "        super(CatboostModel, self).__init__(model_directory=model_directory,\n",
    "                                            file_suffix=file_suffix,\n",
    "                                            model_name=model_name, *args, **kwargs)\n",
    "\n",
    "    @display_processor_info\n",
    "    def predict(self, dataset: Dataset) -> Dataset:\n",
    "        dataset.dataf.loc[:, f\"prediction_{self.model_name}\"] = 0\n",
    "        feature_df = dataset.get_feature_data\n",
    "        models = self._load_models()\n",
    "        for model in tqdm(models, desc=self.description):\n",
    "            predictions = model.predict(feature_df)\n",
    "            dataset.dataf.loc[:, self.model_name] += predictions\n",
    "        del models; gc.collect()\n",
    "        return Dataset(**dataset.__dict__)\n",
    "\n",
    "    def _load_models(self) -> list:\n",
    "        return [CatBoostRegressor().load_model(path) for path in self.model_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. LightGBM (.lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass LGBMModel(BaseModel):\\n    \\\"\\\"\\\" Parse predict .cbm models (CatBoostRegressor) from directory. \\\"\\\"\\\"\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = \\\"lgb\\\"\\n        super(LGBMModel, self).__init__(model_directory=model_directory,\\n                                        file_suffix=file_suffix,\\n                                        model_name=model_name, *args, **kwargs)\\n\\n    @display_processor_info\\n    def predict(self, dataset: Dataset) -> Dataset:\\n        dataset.dataf.loc[:, f\\\"prediction_{self.model_name}\\\"] = 0\\n        feature_df = dataset.get_feature_data\\n        models = self._load_models()\\n        for model in tqdm(models, desc=self.description):\\n            predictions = model.predict(feature_df)\\n            dataset.dataf.loc[:, self.model_name] += predictions\\n        del models; gc.collect()\\n        return Dataset(**dataset.__dict__)\\n\\n    def _load_models(self) -> list:\\n        return [lgb.Booster(path) for path in self.model_paths]\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass LGBMModel(BaseModel):\\n    \\\"\\\"\\\"Parse predict .cbm models (CatBoostRegressor) from directory.\\\"\\\"\\\"\\n\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = \\\"lgb\\\"\\n        super(LGBMModel, self).__init__(\\n            model_directory=model_directory,\\n            file_suffix=file_suffix,\\n            model_name=model_name,\\n            *args,\\n            **kwargs,\\n        )\\n\\n    @display_processor_info\\n    def predict(self, dataset: Dataset) -> Dataset:\\n        dataset.dataf.loc[:, f\\\"prediction_{self.model_name}\\\"] = 0\\n        feature_df = dataset.get_feature_data\\n        models = self._load_models()\\n        for model in tqdm(models, desc=self.description):\\n            predictions = model.predict(feature_df)\\n            dataset.dataf.loc[:, self.model_name] += predictions\\n        del models\\n        gc.collect()\\n        return Dataset(**dataset.__dict__)\\n\\n    def _load_models(self) -> list:\\n        return [lgb.Booster(path) for path in self.model_paths]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class LGBMModel(BaseModel):\n",
    "    \"\"\" Parse predict .cbm models (CatBoostRegressor) from directory. \"\"\"\n",
    "    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\n",
    "        file_suffix = \"lgb\"\n",
    "        super(LGBMModel, self).__init__(model_directory=model_directory,\n",
    "                                        file_suffix=file_suffix,\n",
    "                                        model_name=model_name, *args, **kwargs)\n",
    "\n",
    "    @display_processor_info\n",
    "    def predict(self, dataset: Dataset) -> Dataset:\n",
    "        dataset.dataf.loc[:, f\"prediction_{self.model_name}\"] = 0\n",
    "        feature_df = dataset.get_feature_data\n",
    "        models = self._load_models()\n",
    "        for model in tqdm(models, desc=self.description):\n",
    "            predictions = model.predict(feature_df)\n",
    "            dataset.dataf.loc[:, self.model_name] += predictions\n",
    "        del models; gc.collect()\n",
    "        return Dataset(**dataset.__dict__)\n",
    "\n",
    "    def _load_models(self) -> list:\n",
    "        return [lgb.Booster(path) for path in self.model_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"class ConstantModel(BaseModel):\\n    def __init__(self, model_directory: str, constant_value: float = 0.5):\\n        self.constant_value = constant_value\\n        file_suffix = \\\"\\\"\\n        model_name = f\\\"constant_{self.constant_value}\\\"\\n        super(ConstantModel, self).__init__(model_directory=model_directory,\\n                                            file_suffix=file_suffix,\\n                                            model_name=model_name)\\n        self.clf = DummyRegressor(strategy='constant', constant=0.5)\\n\\n    def predict(self, dataset: Dataset) -> Dataset:\\n        feature_df = dataset.get_feature_data\\n        dataset.dataf.loc[:, f\\\"prediction_{self.model_name}\\\"] = self.clf.predict(feature_df)\\n        return Dataset(**dataset.__dict__)\";\n                var nbb_formatted_code = \"class ConstantModel(BaseModel):\\n    def __init__(self, model_directory: str, constant_value: float = 0.5):\\n        self.constant_value = constant_value\\n        file_suffix = \\\"\\\"\\n        model_name = f\\\"constant_{self.constant_value}\\\"\\n        super(ConstantModel, self).__init__(\\n            model_directory=model_directory,\\n            file_suffix=file_suffix,\\n            model_name=model_name,\\n        )\\n        self.clf = DummyRegressor(strategy=\\\"constant\\\", constant=0.5)\\n\\n    def predict(self, dataset: Dataset) -> Dataset:\\n        feature_df = dataset.get_feature_data\\n        dataset.dataf.loc[:, f\\\"prediction_{self.model_name}\\\"] = self.clf.predict(\\n            feature_df\\n        )\\n        return Dataset(**dataset.__dict__)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ConstantModel(BaseModel):\n",
    "    def __init__(self, model_directory: str, constant_value: float = 0.5):\n",
    "        self.constant_value = constant_value\n",
    "        file_suffix = \"\"\n",
    "        model_name = f\"constant_{self.constant_value}\"\n",
    "        super(ConstantModel, self).__init__(model_directory=model_directory,\n",
    "                                            file_suffix=file_suffix,\n",
    "                                            model_name=model_name)\n",
    "        self.clf = DummyRegressor(strategy='constant', constant=0.5)\n",
    "\n",
    "    def predict(self, dataset: Dataset) -> Dataset:\n",
    "        feature_df = dataset.get_feature_data\n",
    "        dataset.dataf.loc[:, f\"prediction_{self.model_name}\"] = self.clf.predict(feature_df)\n",
    "        return Dataset(**dataset.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbitrary models can be instantiated by inheriting from `BaseModel` and defining the `file_suffix`. All model_paths of models that are in `model_directory` will be defined upon instantiation. Arbitrary logic (model loading, prediction, etc.) can be defined in `.predict` as long as the method takes a `Dataset` as input and outputs a `Dataset`. The Model should be able to typecheck by adding the `@typeguard.typechecked` decorator at the top of the class.\n",
    "\n",
    "If loading model files is not relevant for your use case you should specify `file_suffix`=\"\".\n",
    "\n",
    "For clear console output we recommend adding the `@display_processor_info` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass AwesomeModel(BaseModel):\\n    \\\"\\\"\\\"\\n    - TEMPLATE -\\n    Predict with arbitrary model formats.\\n    \\\"\\\"\\\"\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = \\\"anything\\\"\\n        super(AwesomeModel, self).__init__(model_directory=model_directory,\\n                                           file_suffix=file_suffix,\\n                                           model_name=model_name, *args, **kwargs)\\n\\n    @display_processor_info\\n    def predict(self, dataset: Dataset) -> Dataset:\\n        \\\"\\\"\\\" Return Dataset with column added for prediction. \\\"\\\"\\\"\\n        dataset.dataf.loc[:, f\\\"prediction_{self.model_name}\\\"] = 0\\n        feature_df = dataset.get_feature_data\\n        ...\\n        return Dataset(**dataset.__dict__)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass AwesomeModel(BaseModel):\\n    \\\"\\\"\\\"\\n    - TEMPLATE -\\n    Predict with arbitrary model formats.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = \\\"anything\\\"\\n        super(AwesomeModel, self).__init__(\\n            model_directory=model_directory,\\n            file_suffix=file_suffix,\\n            model_name=model_name,\\n            *args,\\n            **kwargs,\\n        )\\n\\n    @display_processor_info\\n    def predict(self, dataset: Dataset) -> Dataset:\\n        \\\"\\\"\\\"Return Dataset with column added for prediction.\\\"\\\"\\\"\\n        dataset.dataf.loc[:, f\\\"prediction_{self.model_name}\\\"] = 0\\n        feature_df = dataset.get_feature_data\\n        ...\\n        return Dataset(**dataset.__dict__)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class AwesomeModel(BaseModel):\n",
    "    \"\"\"\n",
    "    - TEMPLATE -\n",
    "    Predict with arbitrary model formats.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\n",
    "        file_suffix = \"anything\"\n",
    "        super(AwesomeModel, self).__init__(model_directory=model_directory,\n",
    "                                           file_suffix=file_suffix,\n",
    "                                           model_name=model_name, *args, **kwargs)\n",
    "\n",
    "    @display_processor_info\n",
    "    def predict(self, dataset: Dataset) -> Dataset:\n",
    "        \"\"\" Return Dataset with column(s) added for prediction(s). \"\"\"\n",
    "        ...\n",
    "        dataset.dataf.loc[:, f\"prediction_{self.model_name}\"] = 0\n",
    "        feature_df = dataset.get_feature_data\n",
    "        ...\n",
    "        # Parse all contents of Dataset to the next pipeline step\n",
    "        return Dataset(**dataset.__dict__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
