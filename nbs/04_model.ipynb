{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_formatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"# default_exp model\";\n                var nbb_formatted_code = \"# default_exp model\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default_exp model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_formatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"#export\\nimport gc\\nimport uuid\\nimport joblib\\nimport pickle\\nimport numpy as np\\nimport pandas as pd\\nimport lightgbm as lgb\\nfrom pathlib import Path\\nfrom typing import Union\\nfrom tqdm.auto import tqdm\\nfrom catboost import CatBoost\\nfrom typeguard import typechecked\\nfrom abc import ABC, abstractmethod\\nfrom sklearn.dummy import DummyRegressor\\n\\nfrom numerai_blocks.dataset import NumerFrame, create_numerframe\\nfrom numerai_blocks.preprocessing import display_processor_info\";\n                var nbb_formatted_code = \"# export\\nimport gc\\nimport uuid\\nimport joblib\\nimport pickle\\nimport numpy as np\\nimport pandas as pd\\nimport lightgbm as lgb\\nfrom pathlib import Path\\nfrom typing import Union\\nfrom tqdm.auto import tqdm\\nfrom catboost import CatBoost\\nfrom typeguard import typechecked\\nfrom abc import ABC, abstractmethod\\nfrom sklearn.dummy import DummyRegressor\\n\\nfrom numerai_blocks.dataset import NumerFrame, create_numerframe\\nfrom numerai_blocks.preprocessing import display_processor_info\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "import gc\n",
    "import uuid\n",
    "import joblib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "from tqdm.auto import tqdm\n",
    "from catboost import CatBoost\n",
    "from typeguard import typechecked\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from numerai_blocks.dataset import NumerFrame, create_numerframe\n",
    "from numerai_blocks.preprocessing import display_processor_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BaseModel` is an abstract base class where the `predict` method is central. All models should inherit from `BaseModel` and be sure to implement the `predict` method.\n",
    "\n",
    "In general, models make use of files that are loaded in. Therefore, the correct `file_suffix` of the models in question should be specified. If no model files are involved in your model you should pass an empty string `\"\"` to the `file_suffix` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"#export\\nclass BaseModel(ABC):\\n    \\\"\\\"\\\"\\n    Setup for model prediction on a Dataset.\\n\\n    :param model_directory: Main directory from which to read in models.\\n    :param model_name: Name that will be used to create column names and for display purposes.\\n    \\\"\\\"\\\"\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        self.model_directory = Path(model_directory)\\n        self.__dict__.update(*args, **kwargs)\\n        self.model_name = model_name if model_name else uuid.uuid4().hex\\n        self.prediction_col_name = f\\\"prediction_{self.model_name}\\\"\\n        self.description = f\\\"{self.__class__.__name__}: '{self.model_name}' prediction\\\"\\n\\n    @abstractmethod\\n    def predict(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        \\\"\\\"\\\" Return NumerFrame with column added for prediction. \\\"\\\"\\\"\\n        ...\\n        return NumerFrame(dataf)\\n\\n    def __call__(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        return self.predict(dataf=dataf)\";\n                var nbb_formatted_code = \"# export\\nclass BaseModel(ABC):\\n    \\\"\\\"\\\"\\n    Setup for model prediction on a Dataset.\\n\\n    :param model_directory: Main directory from which to read in models.\\n    :param model_name: Name that will be used to create column names and for display purposes.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        self.model_directory = Path(model_directory)\\n        self.__dict__.update(*args, **kwargs)\\n        self.model_name = model_name if model_name else uuid.uuid4().hex\\n        self.prediction_col_name = f\\\"prediction_{self.model_name}\\\"\\n        self.description = f\\\"{self.__class__.__name__}: '{self.model_name}' prediction\\\"\\n\\n    @abstractmethod\\n    def predict(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        \\\"\\\"\\\"Return NumerFrame with column added for prediction.\\\"\\\"\\\"\\n        ...\\n        return NumerFrame(dataf)\\n\\n    def __call__(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        return self.predict(dataf=dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "class BaseModel(ABC):\n",
    "    \"\"\"\n",
    "    Setup for model prediction on a Dataset.\n",
    "\n",
    "    :param model_directory: Main directory from which to read in models.\n",
    "    :param model_name: Name that will be used to create column names and for display purposes.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\n",
    "        self.model_directory = Path(model_directory)\n",
    "        self.__dict__.update(*args, **kwargs)\n",
    "        self.model_name = model_name if model_name else uuid.uuid4().hex\n",
    "        self.prediction_col_name = f\"prediction_{self.model_name}\"\n",
    "        self.description = f\"{self.__class__.__name__}: '{self.model_name}' prediction\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        \"\"\" Return NumerFrame with column added for prediction. \"\"\"\n",
    "        ...\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def __call__(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        return self.predict(dataf=dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DirectoryModel` assumes that you have a directory of models and you want to load + predict for all models with a certain `file_suffix` (for example, `.joblib`, `.cbm` or `.lgb`). This class load in all models with the suffix and makes predictions for them.\n",
    "\n",
    "When inheriting from `DirectoryModel` the only method that needs to be implemented is `_load_models`. It should instantiate all models and return them as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"#export\\nclass DirectoryModel(BaseModel):\\n    \\\"\\\"\\\"\\n    Base class implementation for JoblibModel, CatBoostModel, LGBMModel, etc.\\n    Walks through every file with given file_suffix in a directory.\\n    :param model_directory: Main directory from which to read in models.\\n    :param file_suffix: File format to load (For example, .joblib, .cbm or .lgb)\\n    :param model_name: Name that will be used to create column names and for display purposes.\\n    \\\"\\\"\\\"\\n    def __init__(self, model_directory: str, file_suffix: str, model_name: str = None, *args, **kwargs):\\n        super().__init__(model_directory=model_directory,\\n                         model_name=model_name,\\n                         *args, **kwargs\\n                         )\\n        self.file_suffix = file_suffix\\n        self.model_paths = list(self.model_directory.glob(f'*.{self.file_suffix}'))\\n        if self.file_suffix:\\n            assert self.model_paths, f\\\"No {self.file_suffix} files found in {self.model_directory}.\\\"\\n        self.total_models = len(self.model_paths)\\n\\n    @display_processor_info\\n    def predict(self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs) -> NumerFrame:\\n        \\\"\\\"\\\"\\n        Use all recognized models to make predictions and average them out.\\n        :param dataf: A Preprocessed DataFrame where all its features can be passed to the model predict method.\\n        *args, **kwargs will be parsed into the model.predict method.\\n        :return: A new dataset with prediction column added.\\n        \\\"\\\"\\\"\\n        dataf.loc[:, self.prediction_col_name] = np.zeros(len(dataf))\\n        models = self.load_models()\\n        for model in tqdm(models, desc=self.description, position=1):\\n            predictions = model.predict(dataf.get_feature_data, *args, **kwargs)\\n            dataf.loc[:, self.prediction_col_name] += predictions / self.total_models\\n        del models; gc.collect()\\n        return NumerFrame(dataf)\\n\\n    @abstractmethod\\n    def load_models(self) -> list:\\n        \\\"\\\"\\\" Instantiate all models detected in self.model_paths. \\\"\\\"\\\"\\n        ...\";\n                var nbb_formatted_code = \"# export\\nclass DirectoryModel(BaseModel):\\n    \\\"\\\"\\\"\\n    Base class implementation for JoblibModel, CatBoostModel, LGBMModel, etc.\\n    Walks through every file with given file_suffix in a directory.\\n    :param model_directory: Main directory from which to read in models.\\n    :param file_suffix: File format to load (For example, .joblib, .cbm or .lgb)\\n    :param model_name: Name that will be used to create column names and for display purposes.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        model_directory: str,\\n        file_suffix: str,\\n        model_name: str = None,\\n        *args,\\n        **kwargs,\\n    ):\\n        super().__init__(\\n            model_directory=model_directory, model_name=model_name, *args, **kwargs\\n        )\\n        self.file_suffix = file_suffix\\n        self.model_paths = list(self.model_directory.glob(f\\\"*.{self.file_suffix}\\\"))\\n        if self.file_suffix:\\n            assert (\\n                self.model_paths\\n            ), f\\\"No {self.file_suffix} files found in {self.model_directory}.\\\"\\n        self.total_models = len(self.model_paths)\\n\\n    @display_processor_info\\n    def predict(\\n        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        \\\"\\\"\\\"\\n        Use all recognized models to make predictions and average them out.\\n        :param dataf: A Preprocessed DataFrame where all its features can be passed to the model predict method.\\n        *args, **kwargs will be parsed into the model.predict method.\\n        :return: A new dataset with prediction column added.\\n        \\\"\\\"\\\"\\n        dataf.loc[:, self.prediction_col_name] = np.zeros(len(dataf))\\n        models = self.load_models()\\n        for model in tqdm(models, desc=self.description, position=1):\\n            predictions = model.predict(dataf.get_feature_data, *args, **kwargs)\\n            dataf.loc[:, self.prediction_col_name] += predictions / self.total_models\\n        del models\\n        gc.collect()\\n        return NumerFrame(dataf)\\n\\n    @abstractmethod\\n    def load_models(self) -> list:\\n        \\\"\\\"\\\"Instantiate all models detected in self.model_paths.\\\"\\\"\\\"\\n        ...\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "class DirectoryModel(BaseModel):\n",
    "    \"\"\"\n",
    "    Base class implementation for JoblibModel, CatBoostModel, LGBMModel, etc.\n",
    "    Walks through every file with given file_suffix in a directory.\n",
    "    :param model_directory: Main directory from which to read in models.\n",
    "    :param file_suffix: File format to load (For example, .joblib, .cbm or .lgb)\n",
    "    :param model_name: Name that will be used to create column names and for display purposes.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_directory: str, file_suffix: str, model_name: str = None, *args, **kwargs):\n",
    "        super().__init__(model_directory=model_directory,\n",
    "                         model_name=model_name,\n",
    "                         *args, **kwargs\n",
    "                         )\n",
    "        self.file_suffix = file_suffix\n",
    "        self.model_paths = list(self.model_directory.glob(f'*.{self.file_suffix}'))\n",
    "        if self.file_suffix:\n",
    "            assert self.model_paths, f\"No {self.file_suffix} files found in {self.model_directory}.\"\n",
    "        self.total_models = len(self.model_paths)\n",
    "\n",
    "    @display_processor_info\n",
    "    def predict(self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs) -> NumerFrame:\n",
    "        \"\"\"\n",
    "        Use all recognized models to make predictions and average them out.\n",
    "        :param dataf: A Preprocessed DataFrame where all its features can be passed to the model predict method.\n",
    "        *args, **kwargs will be parsed into the model.predict method.\n",
    "        :return: A new dataset with prediction column added.\n",
    "        \"\"\"\n",
    "        dataf.loc[:, self.prediction_col_name] = np.zeros(len(dataf))\n",
    "        models = self.load_models()\n",
    "        for model in tqdm(models, desc=self.description, position=1):\n",
    "            predictions = model.predict(dataf.get_feature_data, *args, **kwargs)\n",
    "            dataf.loc[:, self.prediction_col_name] += predictions / self.total_models\n",
    "        del models; gc.collect()\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_models(self) -> list:\n",
    "        \"\"\" Instantiate all models detected in self.model_paths. \"\"\"\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Standard model formats"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1. Single Model file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In many cases you would just want to load a single model file and create prediction for that model.\n",
    "\n",
    "This class supports multiple model formats for easy use. All models should have a `.predict` method and currently `.joblib`, `.cbm`, `.lgb`, `.pkl` and `.pickle` format are supported. For XGBoost models we recommend saving them as `.joblib`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass SingleModel(BaseModel):\\n    def __init__(self, model_file_path: str, model_name: str = None, *args, **kwargs):\\n        self.model_file_path = Path(model_file_path)\\n        assert self.model_file_path.exists(), f\\\"File path '{self.model_file_path}' does not exist.\\\"\\n        assert self.model_file_path.is_file(), f\\\"File path must point to file. Not valid for '{self.model_file_path}'.\\\"\\n        super().__init__(model_directory=str(self.model_file_path.parent),\\n                         model_name=model_name,\\n                         *args, **kwargs\\n                         )\\n        self.model_suffix = self.model_file_path.suffix\\n        self.suffix_to_model_mapping = {\\\".joblib\\\": joblib.load,\\n                                        \\\".cbm\\\": CatBoost().load_model,\\n                                        \\\".pkl\\\": pickle.load,\\n                                        \\\".pickle\\\": pickle.load}\\n        self.__check_valid_suffix()\\n\\n    def predict(self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs) -> NumerFrame:\\n        model = self._load_model()\\n        predictions = model.predict(dataf.get_feature_data, *args, **kwargs)\\n        prediction_cols = self.get_prediction_col_names(predictions.shape)\\n        dataf.loc[:, prediction_cols] = predictions\\n        del model; gc.collect()\\n        return NumerFrame(dataf)\\n\\n    def _load_model(self, *args, **kwargs):\\n        \\\"\\\"\\\" Load arbitrary model from path using suffix to model mapping. \\\"\\\"\\\"\\n        return self.suffix_to_model_mapping[self.model_suffix](str(self.model_file_path), *args, **kwargs)\\n\\n    def get_prediction_col_names(self, pred_shape: tuple) -> list:\\n        \\\"\\\"\\\" Create multiple columns if predictions are multi-target. \\\"\\\"\\\"\\n        if len(pred_shape) > 1:\\n            # Multi target\\n            prediction_cols = [f\\\"{self.prediction_col_name}_{i}\\\" for i in range(pred_shape[1])]\\n        else:\\n            # Single target\\n            prediction_cols = [self.prediction_col_name]\\n        return prediction_cols\\n\\n    def __check_valid_suffix(self):\\n        \\\"\\\"\\\" Detailed message if model is not supported in this class. \\\"\\\"\\\"\\n        try:\\n            self.suffix_to_model_mapping[self.model_suffix]\\n        except KeyError:\\n            raise NotImplementedError(\\n                f\\\"Format '{self.model_suffix}' is not available. Available versions are {list(self.suffix_to_model_mapping.keys())}\\\"\\n            )\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass SingleModel(BaseModel):\\n    def __init__(self, model_file_path: str, model_name: str = None, *args, **kwargs):\\n        self.model_file_path = Path(model_file_path)\\n        assert (\\n            self.model_file_path.exists()\\n        ), f\\\"File path '{self.model_file_path}' does not exist.\\\"\\n        assert (\\n            self.model_file_path.is_file()\\n        ), f\\\"File path must point to file. Not valid for '{self.model_file_path}'.\\\"\\n        super().__init__(\\n            model_directory=str(self.model_file_path.parent),\\n            model_name=model_name,\\n            *args,\\n            **kwargs,\\n        )\\n        self.model_suffix = self.model_file_path.suffix\\n        self.suffix_to_model_mapping = {\\n            \\\".joblib\\\": joblib.load,\\n            \\\".cbm\\\": CatBoost().load_model,\\n            \\\".pkl\\\": pickle.load,\\n            \\\".pickle\\\": pickle.load,\\n        }\\n        self.__check_valid_suffix()\\n\\n    def predict(\\n        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        model = self._load_model()\\n        predictions = model.predict(dataf.get_feature_data, *args, **kwargs)\\n        prediction_cols = self.get_prediction_col_names(predictions.shape)\\n        dataf.loc[:, prediction_cols] = predictions\\n        del model\\n        gc.collect()\\n        return NumerFrame(dataf)\\n\\n    def _load_model(self, *args, **kwargs):\\n        \\\"\\\"\\\"Load arbitrary model from path using suffix to model mapping.\\\"\\\"\\\"\\n        return self.suffix_to_model_mapping[self.model_suffix](\\n            str(self.model_file_path), *args, **kwargs\\n        )\\n\\n    def get_prediction_col_names(self, pred_shape: tuple) -> list:\\n        \\\"\\\"\\\"Create multiple columns if predictions are multi-target.\\\"\\\"\\\"\\n        if len(pred_shape) > 1:\\n            # Multi target\\n            prediction_cols = [\\n                f\\\"{self.prediction_col_name}_{i}\\\" for i in range(pred_shape[1])\\n            ]\\n        else:\\n            # Single target\\n            prediction_cols = [self.prediction_col_name]\\n        return prediction_cols\\n\\n    def __check_valid_suffix(self):\\n        \\\"\\\"\\\"Detailed message if model is not supported in this class.\\\"\\\"\\\"\\n        try:\\n            self.suffix_to_model_mapping[self.model_suffix]\\n        except KeyError:\\n            raise NotImplementedError(\\n                f\\\"Format '{self.model_suffix}' is not available. Available versions are {list(self.suffix_to_model_mapping.keys())}\\\"\\n            )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class SingleModel(BaseModel):\n",
    "    def __init__(self, model_file_path: str, model_name: str = None, *args, **kwargs):\n",
    "        self.model_file_path = Path(model_file_path)\n",
    "        assert self.model_file_path.exists(), f\"File path '{self.model_file_path}' does not exist.\"\n",
    "        assert self.model_file_path.is_file(), f\"File path must point to file. Not valid for '{self.model_file_path}'.\"\n",
    "        super().__init__(model_directory=str(self.model_file_path.parent),\n",
    "                         model_name=model_name,\n",
    "                         *args, **kwargs\n",
    "                         )\n",
    "        self.model_suffix = self.model_file_path.suffix\n",
    "        self.suffix_to_model_mapping = {\".joblib\": joblib.load,\n",
    "                                        \".cbm\": CatBoost().load_model,\n",
    "                                        \".pkl\": pickle.load,\n",
    "                                        \".pickle\": pickle.load}\n",
    "        self.__check_valid_suffix()\n",
    "\n",
    "    def predict(self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs) -> NumerFrame:\n",
    "        model = self._load_model()\n",
    "        predictions = model.predict(dataf.get_feature_data, *args, **kwargs)\n",
    "        prediction_cols = self.get_prediction_col_names(predictions.shape)\n",
    "        dataf.loc[:, prediction_cols] = predictions\n",
    "        del model; gc.collect()\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def _load_model(self, *args, **kwargs):\n",
    "        \"\"\" Load arbitrary model from path using suffix to model mapping. \"\"\"\n",
    "        return self.suffix_to_model_mapping[self.model_suffix](str(self.model_file_path), *args, **kwargs)\n",
    "\n",
    "    def get_prediction_col_names(self, pred_shape: tuple) -> list:\n",
    "        \"\"\" Create multiple columns if predictions are multi-target. \"\"\"\n",
    "        if len(pred_shape) > 1:\n",
    "            # Multi target\n",
    "            prediction_cols = [f\"{self.prediction_col_name}_{i}\" for i in range(pred_shape[1])]\n",
    "        else:\n",
    "            # Single target\n",
    "            prediction_cols = [self.prediction_col_name]\n",
    "        return prediction_cols\n",
    "\n",
    "    def __check_valid_suffix(self):\n",
    "        \"\"\" Detailed message if model is not supported in this class. \"\"\"\n",
    "        try:\n",
    "            self.suffix_to_model_mapping[self.model_suffix]\n",
    "        except KeyError:\n",
    "            raise NotImplementedError(\n",
    "                f\"Format '{self.model_suffix}' is not available. Available versions are {list(self.suffix_to_model_mapping.keys())}\"\n",
    "            )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  prediction_test\n",
      "id                               \n",
      "n559bd06a8861222         0.506948\n",
      "n9d39dea58c9e3cf         0.492578\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"dataset = create_numerframe(\\\"test_assets/mini_numerai_version_2_data.parquet\\\")\\ntest_paths = [\\\"test_assets/joblib_v2_example_model.joblib\\\"]\\nfor path in test_paths:\\n    model = SingleModel(path, model_name=\\\"test\\\")\\n    print(model.predict(dataset).get_prediction_data.head(2))\";\n                var nbb_formatted_code = \"dataset = create_numerframe(\\\"test_assets/mini_numerai_version_2_data.parquet\\\")\\ntest_paths = [\\\"test_assets/joblib_v2_example_model.joblib\\\"]\\nfor path in test_paths:\\n    model = SingleModel(path, model_name=\\\"test\\\")\\n    print(model.predict(dataset).get_prediction_data.head(2))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = create_numerframe(\"test_assets/mini_numerai_version_2_data.parquet\")\n",
    "test_paths = [\"test_assets/joblib_v2_example_model.joblib\"]\n",
    "for path in test_paths:\n",
    "    model = SingleModel(path, model_name=\"test\")\n",
    "    print(model.predict(dataset).get_prediction_data.head(2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'.joblib': <function joblib.numpy_pickle.load(filename, mmap_mode=None)>,\n '.cbm': <bound method CatBoost.load_model of <catboost.core.CatBoost object at 0x7fbdc8d430d0>>,\n '.pkl': <function _pickle.load(file, *, fix_imports=True, encoding='ASCII', errors='strict')>,\n '.pickle': <function _pickle.load(file, *, fix_imports=True, encoding='ASCII', errors='strict')>}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"model = SingleModel(test_paths[0], model_name=\\\"test\\\")\\nmodel.suffix_to_model_mapping\";\n                var nbb_formatted_code = \"model = SingleModel(test_paths[0], model_name=\\\"test\\\")\\nmodel.suffix_to_model_mapping\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SingleModel(test_paths[0], model_name=\"test\")\n",
    "model.suffix_to_model_mapping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Joblib directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many frameworks like `sklearn` models can conveniently be saved as `.joblib` files. This class automatically load all `.joblib` files in a given folders and generates (averaged out) predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass JoblibModel(DirectoryModel):\\n    \\\"\\\"\\\" Load and predict for arbitrary models saved as .joblib. \\\"\\\"\\\"\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = 'joblib'\\n        super().__init__(model_directory=model_directory,\\n                         file_suffix=file_suffix,\\n                         model_name=model_name,\\n                         *args, **kwargs\\n                         )\\n\\n    def load_models(self) -> list:\\n        return [joblib.load(path) for path in self.model_paths]\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass JoblibModel(DirectoryModel):\\n    \\\"\\\"\\\"Load and predict for arbitrary models saved as .joblib.\\\"\\\"\\\"\\n\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = \\\"joblib\\\"\\n        super().__init__(\\n            model_directory=model_directory,\\n            file_suffix=file_suffix,\\n            model_name=model_name,\\n            *args,\\n            **kwargs\\n        )\\n\\n    def load_models(self) -> list:\\n        return [joblib.load(path) for path in self.model_paths]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class JoblibModel(DirectoryModel):\n",
    "    \"\"\" Load and predict for arbitrary models saved as .joblib. \"\"\"\n",
    "    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\n",
    "        file_suffix = 'joblib'\n",
    "        super().__init__(model_directory=model_directory,\n",
    "                         file_suffix=file_suffix,\n",
    "                         model_name=model_name,\n",
    "                         *args, **kwargs\n",
    "                         )\n",
    "\n",
    "    def load_models(self) -> list:\n",
    "        return [joblib.load(path) for path in self.model_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "JoblibModel: 'Joblib_LGB' prediction:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6198cde4f23742aabb6c9811ae7e9a9b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mDirectoryModel\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m1074\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m138489\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">DirectoryModel</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1074</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">138489</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                  prediction_Joblib_LGB\nid                                     \nn559bd06a8861222               0.506948\nn9d39dea58c9e3cf               0.492578\nnb64f06d3a9fc9f1               0.490879",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_Joblib_LGB</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>0.506948</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>0.492578</td>\n    </tr>\n    <tr>\n      <th>nb64f06d3a9fc9f1</th>\n      <td>0.490879</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"dataset = create_numerframe(\\\"test_assets/mini_numerai_version_2_data.parquet\\\", metadata={\\\"version\\\": 2})\\nmodel = JoblibModel(\\\"test_assets\\\", model_name=\\\"Joblib_LGB\\\")\\npredictions = model.predict(dataset).get_prediction_data\\nassert predictions['prediction_Joblib_LGB'].between(0, 1).all()\\npredictions.head(3)\";\n                var nbb_formatted_code = \"dataset = create_numerframe(\\n    \\\"test_assets/mini_numerai_version_2_data.parquet\\\", metadata={\\\"version\\\": 2}\\n)\\nmodel = JoblibModel(\\\"test_assets\\\", model_name=\\\"Joblib_LGB\\\")\\npredictions = model.predict(dataset).get_prediction_data\\nassert predictions[\\\"prediction_Joblib_LGB\\\"].between(0, 1).all()\\npredictions.head(3)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = create_numerframe(\"test_assets/mini_numerai_version_2_data.parquet\", metadata={\"version\": 2})\n",
    "model = JoblibModel(\"test_assets\", model_name=\"Joblib_LGB\")\n",
    "predictions = model.predict(dataset).get_prediction_data\n",
    "assert predictions['prediction_Joblib_LGB'].between(0, 1).all()\n",
    "predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Catboost directory (.cbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model setup loads in all `CatBoost` (`.cbm`) models present in a given directory and makes (averaged out) predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass CatBoostModel(DirectoryModel):\\n    \\\"\\\"\\\" Load and predict with all .cbm models (CatBoostRegressor) in directory. \\\"\\\"\\\"\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = 'cbm'\\n        super().__init__(model_directory=model_directory,\\n                         file_suffix=file_suffix,\\n                         model_name=model_name,\\n                         *args, **kwargs\\n                         )\\n\\n    def load_models(self) -> list:\\n        return [CatBoost().load_model(path) for path in self.model_paths]\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass CatBoostModel(DirectoryModel):\\n    \\\"\\\"\\\"Load and predict with all .cbm models (CatBoostRegressor) in directory.\\\"\\\"\\\"\\n\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = \\\"cbm\\\"\\n        super().__init__(\\n            model_directory=model_directory,\\n            file_suffix=file_suffix,\\n            model_name=model_name,\\n            *args,\\n            **kwargs\\n        )\\n\\n    def load_models(self) -> list:\\n        return [CatBoost().load_model(path) for path in self.model_paths]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class CatBoostModel(DirectoryModel):\n",
    "    \"\"\" Load and predict with all .cbm models (CatBoostRegressor) in directory. \"\"\"\n",
    "    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\n",
    "        file_suffix = 'cbm'\n",
    "        super().__init__(model_directory=model_directory,\n",
    "                         file_suffix=file_suffix,\n",
    "                         model_name=model_name,\n",
    "                         *args, **kwargs\n",
    "                         )\n",
    "\n",
    "    def load_models(self) -> list:\n",
    "        return [CatBoost().load_model(path) for path in self.model_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mGroupStatsPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m332\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m022835\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">GroupStatsPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">332</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">022835</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"from numerai_blocks.preprocessing import GroupStatsPreProcessor\\ndataset = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\", {\\\"version\\\": 1})\\nprocessed_dataset = GroupStatsPreProcessor()(dataset)\\nmodel = CatBoostModel(\\\"test_assets\\\", model_name=\\\"CB\\\")\";\n                var nbb_formatted_code = \"from numerai_blocks.preprocessing import GroupStatsPreProcessor\\n\\ndataset = create_numerframe(\\n    \\\"test_assets/mini_numerai_version_1_data.csv\\\", {\\\"version\\\": 1}\\n)\\nprocessed_dataset = GroupStatsPreProcessor()(dataset)\\nmodel = CatBoostModel(\\\"test_assets\\\", model_name=\\\"CB\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numerai_blocks.preprocessing import GroupStatsPreProcessor\n",
    "dataset = create_numerframe(\"test_assets/mini_numerai_version_1_data.csv\", {\"version\": 1})\n",
    "processed_dataset = GroupStatsPreProcessor()(dataset)\n",
    "model = CatBoostModel(\"test_assets\", model_name=\"CB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "CatBoostModel: 'CB' prediction:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "314c6610509b44fbb53701649de72c80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mDirectoryModel\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m333\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m095464\u001B[0m.\n✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">DirectoryModel</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">333</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">095464</span>.\n✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   prediction_CB\n0       0.492046\n1       0.499881\n2       0.485325",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_CB</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.492046</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.499881</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.485325</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"predictions = model.predict(processed_dataset).get_prediction_data\\nassert predictions['prediction_CB'].between(0, 1).all()\\npredictions.head(3)\";\n                var nbb_formatted_code = \"predictions = model.predict(processed_dataset).get_prediction_data\\nassert predictions[\\\"prediction_CB\\\"].between(0, 1).all()\\npredictions.head(3)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(processed_dataset).get_prediction_data\n",
    "assert predictions['prediction_CB'].between(0, 1).all()\n",
    "predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. LightGBM (.lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model setup loads in all `LightGBM` (`.lgb`) models present in a given directory and makes (averaged out) predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 15;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass LGBMModel(DirectoryModel):\\n    \\\"\\\"\\\" Load and predict with all .lgb models (LightGBM) in directory. \\\"\\\"\\\"\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = 'lgb'\\n        super().__init__(model_directory=model_directory,\\n                         file_suffix=file_suffix,\\n                         model_name=model_name,\\n                         *args, **kwargs\\n                         )\\n\\n    def load_models(self) -> list:\\n        return [lgb.Booster(model_file=str(path)) for path in self.model_paths]\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass LGBMModel(DirectoryModel):\\n    \\\"\\\"\\\"Load and predict with all .lgb models (LightGBM) in directory.\\\"\\\"\\\"\\n\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = \\\"lgb\\\"\\n        super().__init__(\\n            model_directory=model_directory,\\n            file_suffix=file_suffix,\\n            model_name=model_name,\\n            *args,\\n            **kwargs\\n        )\\n\\n    def load_models(self) -> list:\\n        return [lgb.Booster(model_file=str(path)) for path in self.model_paths]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class LGBMModel(DirectoryModel):\n",
    "    \"\"\" Load and predict with all .lgb models (LightGBM) in directory. \"\"\"\n",
    "    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\n",
    "        file_suffix = 'lgb'\n",
    "        super().__init__(model_directory=model_directory,\n",
    "                         file_suffix=file_suffix,\n",
    "                         model_name=model_name,\n",
    "                         *args, **kwargs\n",
    "                         )\n",
    "\n",
    "    def load_models(self) -> list:\n",
    "        return [lgb.Booster(model_file=str(path)) for path in self.model_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "LGBMModel: 'LGB' prediction:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f6f0b56d5cc411fbdc0e38993c147a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mDirectoryModel\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m1074\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m142040\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">DirectoryModel</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1074</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">142040</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                  prediction_LGB\nid                              \nn559bd06a8861222        0.506948\nn9d39dea58c9e3cf        0.492578\nnb64f06d3a9fc9f1        0.490879",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_LGB</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>0.506948</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>0.492578</td>\n    </tr>\n    <tr>\n      <th>nb64f06d3a9fc9f1</th>\n      <td>0.490879</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"dataset = create_numerframe(\\\"test_assets/mini_numerai_version_2_data.parquet\\\")\\nmodel = LGBMModel(\\\"test_assets\\\", model_name=\\\"LGB\\\")\\npredictions = model.predict(dataset).get_prediction_data\\nassert predictions['prediction_LGB'].between(0, 1).all()\\npredictions.head(3)\";\n                var nbb_formatted_code = \"dataset = create_numerframe(\\\"test_assets/mini_numerai_version_2_data.parquet\\\")\\nmodel = LGBMModel(\\\"test_assets\\\", model_name=\\\"LGB\\\")\\npredictions = model.predict(dataset).get_prediction_data\\nassert predictions[\\\"prediction_LGB\\\"].between(0, 1).all()\\npredictions.head(3)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = create_numerframe(\"test_assets/mini_numerai_version_2_data.parquet\")\n",
    "model = LGBMModel(\"test_assets\", model_name=\"LGB\")\n",
    "predictions = model.predict(dataset).get_prediction_data\n",
    "assert predictions['prediction_LGB'].between(0, 1).all()\n",
    "predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a baseline is always an important step when modeling new data. Therefore, we have implemented a few different baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. ConstantModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model simply outputs a constant of your choice. Great for setting classification baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 17;\n                var nbb_unformatted_code = \"#export\\nclass ConstantModel(BaseModel):\\n    \\\"\\\"\\\"\\n    WARNING: Only use this Model for testing purposes.\\n    Create constant prediction.\\n    \\\"\\\"\\\"\\n    def __init__(self, constant: float = 0.5, model_name: str = None):\\n        self.constant = constant\\n        model_name = model_name if model_name else f\\\"constant_{self.constant}\\\"\\n        super().__init__(model_directory=\\\"\\\",\\n                         model_name=model_name\\n                         )\\n        self.clf = DummyRegressor(strategy='constant', constant=constant).fit([0.], [0.])\\n\\n    def predict(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        dataf.loc[:, self.prediction_col_name] = self.clf.predict(dataf.get_feature_data)\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\nclass ConstantModel(BaseModel):\\n    \\\"\\\"\\\"\\n    WARNING: Only use this Model for testing purposes.\\n    Create constant prediction.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, constant: float = 0.5, model_name: str = None):\\n        self.constant = constant\\n        model_name = model_name if model_name else f\\\"constant_{self.constant}\\\"\\n        super().__init__(model_directory=\\\"\\\", model_name=model_name)\\n        self.clf = DummyRegressor(strategy=\\\"constant\\\", constant=constant).fit(\\n            [0.0], [0.0]\\n        )\\n\\n    def predict(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        dataf.loc[:, self.prediction_col_name] = self.clf.predict(\\n            dataf.get_feature_data\\n        )\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "class ConstantModel(BaseModel):\n",
    "    \"\"\"\n",
    "    WARNING: Only use this Model for testing purposes.\n",
    "    Create constant prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, constant: float = 0.5, model_name: str = None):\n",
    "        self.constant = constant\n",
    "        model_name = model_name if model_name else f\"constant_{self.constant}\"\n",
    "        super().__init__(model_directory=\"\",\n",
    "                         model_name=model_name\n",
    "                         )\n",
    "        self.clf = DummyRegressor(strategy='constant', constant=constant).fit([0.], [0.])\n",
    "\n",
    "    def predict(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        dataf.loc[:, self.prediction_col_name] = self.clf.predict(dataf.get_feature_data)\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   prediction_constant_0.85\n0                      0.85\n1                      0.85\n2                      0.85",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_constant_0.85</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.85</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.85</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.85</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"constant = 0.85\\ndataset = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\nconstant_model = ConstantModel(constant=constant)\\npredictions = constant_model.predict(dataset).get_prediction_data\\nassert (predictions.to_numpy() == constant).all()\\npredictions.head(3)\";\n                var nbb_formatted_code = \"constant = 0.85\\ndataset = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\nconstant_model = ConstantModel(constant=constant)\\npredictions = constant_model.predict(dataset).get_prediction_data\\nassert (predictions.to_numpy() == constant).all()\\npredictions.head(3)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "constant = 0.85\n",
    "dataset = create_numerframe(\"test_assets/mini_numerai_version_1_data.csv\")\n",
    "constant_model = ConstantModel(constant=constant)\n",
    "predictions = constant_model.predict(dataset).get_prediction_data\n",
    "assert (predictions.to_numpy() == constant).all()\n",
    "predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. RandomModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model returns uniformly distributed predictions (range $[0...1)$). Great baseline for evaluating regression models against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 19;\n                var nbb_unformatted_code = \"#export\\nclass RandomModel(BaseModel):\\n    \\\"\\\"\\\"\\n    WARNING: Only use this Model for testing purposes.\\n    Create uniformly distributed predictions.\\n    \\\"\\\"\\\"\\n    def __init__(self, model_name: str = None):\\n        model_name = model_name if model_name else \\\"random\\\"\\n        super().__init__(model_directory=\\\"\\\",\\n                         model_name=model_name\\n                         )\\n\\n    def predict(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        dataf.loc[:, self.prediction_col_name] = np.random.uniform(size=len(dataf))\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\nclass RandomModel(BaseModel):\\n    \\\"\\\"\\\"\\n    WARNING: Only use this Model for testing purposes.\\n    Create uniformly distributed predictions.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, model_name: str = None):\\n        model_name = model_name if model_name else \\\"random\\\"\\n        super().__init__(model_directory=\\\"\\\", model_name=model_name)\\n\\n    def predict(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        dataf.loc[:, self.prediction_col_name] = np.random.uniform(size=len(dataf))\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "class RandomModel(BaseModel):\n",
    "    \"\"\"\n",
    "    WARNING: Only use this Model for testing purposes.\n",
    "    Create uniformly distributed predictions.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str = None):\n",
    "        model_name = model_name if model_name else \"random\"\n",
    "        super().__init__(model_directory=\"\",\n",
    "                         model_name=model_name\n",
    "                         )\n",
    "\n",
    "    def predict(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        dataf.loc[:, self.prediction_col_name] = np.random.uniform(size=len(dataf))\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   prediction_random\n0           0.813524\n1           0.043787\n2           0.925226",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_random</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.813524</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.043787</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.925226</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 20;\n                var nbb_unformatted_code = \"dataset = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\", metadata={})\\nrandom_model = RandomModel()\\npredictions = random_model.predict(dataset).get_prediction_data\\nassert predictions['prediction_random'].between(0, 1).all()\\npredictions.head(3)\";\n                var nbb_formatted_code = \"dataset = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\", metadata={})\\nrandom_model = RandomModel()\\npredictions = random_model.predict(dataset).get_prediction_data\\nassert predictions[\\\"prediction_random\\\"].between(0, 1).all()\\npredictions.head(3)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = create_numerframe(\"test_assets/mini_numerai_version_1_data.csv\", metadata={})\n",
    "random_model = RandomModel()\n",
    "predictions = random_model.predict(dataset).get_prediction_data\n",
    "assert predictions['prediction_random'].between(0, 1).all()\n",
    "predictions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. From BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbitrary models can be instantiated by inheriting from `BaseModel` and defining the `file_suffix`. All model_paths of models that are in `model_directory` will be defined upon instantiation. Arbitrary logic (model loading, prediction, etc.) can be defined in `.predict` as long as the method takes a `NumerFrame` or `DataFrame` as input and outputs a `NumerFrame`. The Model should be able to typecheck by adding the `@typeguard.typechecked` decorator at the top of the class.\n",
    "\n",
    "For clear console output we recommend adding the `@display_processor_info` decorator to the `predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 21;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass AwesomeModel(BaseModel):\\n    \\\"\\\"\\\"\\n    - TEMPLATE -\\n    Predict with arbitrary model formats.\\n    \\\"\\\"\\\"\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        super().__init__(model_directory=model_directory,\\n                         model_name=model_name,\\n                         *args, **kwargs\\n                         )\\n\\n    @display_processor_info\\n    def predict(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        \\\"\\\"\\\" Return Dataset with column(s) added for prediction(s). \\\"\\\"\\\"\\n        # NumerFrame functionality to get all features\\n        feature_df = dataf.get_feature_data\\n        # Predict and add to new column\\n        ...\\n        # Parse all contents of Dataset to the next pipeline step\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass AwesomeModel(BaseModel):\\n    \\\"\\\"\\\"\\n    - TEMPLATE -\\n    Predict with arbitrary model formats.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        super().__init__(\\n            model_directory=model_directory, model_name=model_name, *args, **kwargs\\n        )\\n\\n    @display_processor_info\\n    def predict(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        \\\"\\\"\\\"Return Dataset with column(s) added for prediction(s).\\\"\\\"\\\"\\n        # NumerFrame functionality to get all features\\n        feature_df = dataf.get_feature_data\\n        # Predict and add to new column\\n        ...\\n        # Parse all contents of Dataset to the next pipeline step\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class AwesomeModel(BaseModel):\n",
    "    \"\"\"\n",
    "    - TEMPLATE -\n",
    "    Predict with arbitrary model formats.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\n",
    "        super().__init__(model_directory=model_directory,\n",
    "                         model_name=model_name,\n",
    "                         *args, **kwargs\n",
    "                         )\n",
    "\n",
    "    @display_processor_info\n",
    "    def predict(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        \"\"\" Return Dataset with column(s) added for prediction(s). \"\"\"\n",
    "        # NumerFrame functionality to get all features\n",
    "        feature_df = dataf.get_feature_data\n",
    "        # Predict and add to new column\n",
    "        ...\n",
    "        # Parse all contents of Dataset to the next pipeline step\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. From DirectoryModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also may want to implement a setup similar to `JoblibModel` and `CatBoostModel`, where you want to load in all models of a certain type from a directory and predict for all. The model should also have a `.predict` method. If this sounds like your use case, inherit from `DirectoryModel` and be sure to implement the `load_models` method.\n",
    "\n",
    "For an `DirectoryModel` you should also specify a `file_suffix` (like joblib or cbm) which will be used to load in the models from a directory.\n",
    "\n",
    "The `.predict` method will in this case already be implemented, but can be overridden if the prediction logic is more complex. For example, if you want to apply weighted averaging or geometric mean for models within a given directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 22;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass AwesomeDirectoryModel(DirectoryModel):\\n    \\\"\\\"\\\"\\n    - TEMPLATE -\\n    Load in all models of arbitrary file format where model has .predict method.\\n    \\\"\\\"\\\"\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = 'anything'\\n        super().__init__(model_directory=model_directory,\\n                         file_suffix=file_suffix,\\n                         model_name=model_name,\\n                         *args, **kwargs\\n                         )\\n\\n    def load_models(self) -> list:\\n        \\\"\\\"\\\" Instantiate all models and return as a list. (abstract method) \\\"\\\"\\\"\\n        ...\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass AwesomeDirectoryModel(DirectoryModel):\\n    \\\"\\\"\\\"\\n    - TEMPLATE -\\n    Load in all models of arbitrary file format where model has .predict method.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\\n        file_suffix = \\\"anything\\\"\\n        super().__init__(\\n            model_directory=model_directory,\\n            file_suffix=file_suffix,\\n            model_name=model_name,\\n            *args,\\n            **kwargs\\n        )\\n\\n    def load_models(self) -> list:\\n        \\\"\\\"\\\"Instantiate all models and return as a list. (abstract method)\\\"\\\"\\\"\\n        ...\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class AwesomeDirectoryModel(DirectoryModel):\n",
    "    \"\"\"\n",
    "    - TEMPLATE -\n",
    "    Load in all models of arbitrary file format where model has .predict method.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):\n",
    "        file_suffix = 'anything'\n",
    "        super().__init__(model_directory=model_directory,\n",
    "                         file_suffix=file_suffix,\n",
    "                         model_name=model_name,\n",
    "                         *args, **kwargs\n",
    "                         )\n",
    "\n",
    "    def load_models(self) -> list:\n",
    "        \"\"\" Instantiate all models and return as a list. (abstract method) \"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_download.ipynb.\n",
      "Converted 02_numerframe.ipynb.\n",
      "Converted 03_preprocessing.ipynb.\n",
      "Converted 04_model.ipynb.\n",
      "Converted 05_postprocessing.ipynb.\n",
      "Converted 06_modelpipeline.ipynb.\n",
      "Converted 07_evaluation.ipynb.\n",
      "Converted 08_key.ipynb.\n",
      "Converted 09_submission.ipynb.\n",
      "Converted 10_staking.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 23;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# Run this cell to sync all changes with library\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}