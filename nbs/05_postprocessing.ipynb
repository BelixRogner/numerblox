{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n",
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 36;\n                var nbb_unformatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_formatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 37;\n                var nbb_unformatted_code = \"# default_exp postprocessing\";\n                var nbb_formatted_code = \"# default_exp postprocessing\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default_exp postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The postprocessing procedure is very similar to preprocessing.\n",
    "\n",
    "The only difference between a postprocessing step and a preprocessing step is that preprocessing works on `feature` columns while postprocessing manipulates `prediction` columns.\n",
    "\n",
    "We inherit from `BasePostProcessor` for postprocessing. The PostProcessor should take a `NumerFrame` or `DataFrame` as input and output a `NumerFrame` where one or more new prediction column(s) are added with prefix `prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 38;\n                var nbb_unformatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_formatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 39;\n                var nbb_unformatted_code = \"#export\\nimport scipy\\nimport numpy as np\\nimport pandas as pd\\nimport tensorflow as tf\\nfrom typing import Union\\nimport scipy.stats as sp\\nfrom tqdm.auto import tqdm\\nfrom typeguard import typechecked\\nfrom rich import print as rich_print\\nfrom scipy.stats.mstats import gmean\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\nfrom numerai_blocks.numerframe import NumerFrame, create_numerframe\\nfrom numerai_blocks.preprocessing import BaseProcessor, display_processor_info\";\n                var nbb_formatted_code = \"# export\\nimport scipy\\nimport numpy as np\\nimport pandas as pd\\nimport tensorflow as tf\\nfrom typing import Union\\nimport scipy.stats as sp\\nfrom tqdm.auto import tqdm\\nfrom typeguard import typechecked\\nfrom rich import print as rich_print\\nfrom scipy.stats.mstats import gmean\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\nfrom numerai_blocks.numerframe import NumerFrame, create_numerframe\\nfrom numerai_blocks.preprocessing import BaseProcessor, display_processor_info\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from typing import Union\n",
    "import scipy.stats as sp\n",
    "from tqdm.auto import tqdm\n",
    "from typeguard import typechecked\n",
    "from rich import print as rich_print\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from numerai_blocks.numerframe import NumerFrame, create_numerframe\n",
    "from numerai_blocks.preprocessing import BaseProcessor, display_processor_info"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. BasePostProcessor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some characteristics are particular to PostProcessors, but not suitable to put in the `Processor` base class.\n",
    "This functionality is implemented in `BasePostProcessor`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 40;\n                var nbb_unformatted_code = \"#export\\nclass BasePostProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Base class for postprocessing objects.\\n    Postprocessors manipulate or ensemble prediction column(s)\\n    and add them to a Dataset.\\n    \\\"\\\"\\\"\\n    def __init__(self, final_col_name: str):\\n        super().__init__()\\n        self.final_col_name = final_col_name\\n        assert final_col_name.startswith(\\\"prediction\\\"), f\\\"final_col name should start with 'prediction'. Got {final_col_name}\\\"\\n\\n    def transform(self, dataset: Union[pd.DataFrame, NumerFrame], *args, **kwargs) -> NumerFrame:\\n        ...\";\n                var nbb_formatted_code = \"# export\\nclass BasePostProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Base class for postprocessing objects.\\n    Postprocessors manipulate or ensemble prediction column(s)\\n    and add them to a Dataset.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, final_col_name: str):\\n        super().__init__()\\n        self.final_col_name = final_col_name\\n        assert final_col_name.startswith(\\n            \\\"prediction\\\"\\n        ), f\\\"final_col name should start with 'prediction'. Got {final_col_name}\\\"\\n\\n    def transform(\\n        self, dataset: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        ...\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "class BasePostProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Base class for postprocessing objects.\n",
    "    Postprocessors manipulate or ensemble prediction column(s)\n",
    "    and add them to a Dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, final_col_name: str):\n",
    "        super().__init__()\n",
    "        self.final_col_name = final_col_name\n",
    "        assert final_col_name.startswith(\"prediction\"), f\"final_col name should start with 'prediction'. Got {final_col_name}\"\n",
    "\n",
    "    def transform(self, dataset: Union[pd.DataFrame, NumerFrame], *args, **kwargs) -> NumerFrame:\n",
    "        ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Common postprocessing steps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1. Version agnostic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1.0. Standardization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Standardizing is an essential step in order to combine Numerai predictions and is a default postprocessor for `ModelPipeline`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 41;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass Standardizer(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Uniform standardization of prediction columns.\\n    All values should only contain values in the range [0...1].\\n    \\\"\\\"\\\"\\n    def __init__(self, cols: list = None):\\n        super().__init__()\\n        self.cols = cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        cols = dataf.prediction_cols if not self.cols else self.cols\\n        for col in cols:\\n            assert dataf[col].between(0, 1).all(), f\\\"All values should only contain values between 0 and 1. Does not hold for '{col}'\\\"\\n        dataf.loc[:, cols] = dataf.groupby('era')[cols].rank(pct=True)\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass Standardizer(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Uniform standardization of prediction columns.\\n    All values should only contain values in the range [0...1].\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, cols: list = None):\\n        super().__init__()\\n        self.cols = cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        cols = dataf.prediction_cols if not self.cols else self.cols\\n        for col in cols:\\n            assert (\\n                dataf[col].between(0, 1).all()\\n            ), f\\\"All values should only contain values between 0 and 1. Does not hold for '{col}'\\\"\\n        dataf.loc[:, cols] = dataf.groupby(\\\"era\\\")[cols].rank(pct=True)\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class Standardizer(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Uniform standardization of prediction columns.\n",
    "    All values should only contain values in the range [0...1].\n",
    "    \"\"\"\n",
    "    def __init__(self, cols: list = None):\n",
    "        super().__init__()\n",
    "        self.cols = cols\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        cols = dataf.prediction_cols if not self.cols else self.cols\n",
    "        for col in cols:\n",
    "            assert dataf[col].between(0, 1).all(), f\"All values should only contain values between 0 and 1. Does not hold for '{col}'\"\n",
    "        dataf.loc[:, cols] = dataf.groupby('era')[cols].rank(pct=True)\n",
    "        return NumerFrame(dataf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 42;\n                var nbb_unformatted_code = \"# Random DataFrame\\ntest_features = [f\\\"prediction_{l}\\\" for l in \\\"ABCDE\\\"]\\ndf = pd.DataFrame(np.random.uniform(size=(100, 5)), columns=test_features)\\ndf[\\\"target\\\"] = np.random.normal(size=100)\\ndf[\\\"era\\\"] = [0, 1, 2, 3] * 25\\ntest_dataset = NumerFrame(df)\";\n                var nbb_formatted_code = \"# Random DataFrame\\ntest_features = [f\\\"prediction_{l}\\\" for l in \\\"ABCDE\\\"]\\ndf = pd.DataFrame(np.random.uniform(size=(100, 5)), columns=test_features)\\ndf[\\\"target\\\"] = np.random.normal(size=100)\\ndf[\\\"era\\\"] = [0, 1, 2, 3] * 25\\ntest_dataset = NumerFrame(df)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random DataFrame\n",
    "test_features = [f\"prediction_{l}\" for l in \"ABCDE\"]\n",
    "df = pd.DataFrame(np.random.uniform(size=(100, 5)), columns=test_features)\n",
    "df[\"target\"] = np.random.normal(size=100)\n",
    "df[\"era\"] = [0, 1, 2, 3] * 25\n",
    "test_dataset = NumerFrame(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mStandardizer\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m100\u001B[0m, \u001B[1;36m7\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m006198\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">Standardizer</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">006198</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   prediction_A  prediction_B  prediction_C  prediction_D  prediction_E\n0          0.96          0.92          0.28          0.64          0.84\n1          1.00          0.60          0.72          0.12          0.96",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_A</th>\n      <th>prediction_B</th>\n      <th>prediction_C</th>\n      <th>prediction_D</th>\n      <th>prediction_E</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.96</td>\n      <td>0.92</td>\n      <td>0.28</td>\n      <td>0.64</td>\n      <td>0.84</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.00</td>\n      <td>0.60</td>\n      <td>0.72</td>\n      <td>0.12</td>\n      <td>0.96</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 43;\n                var nbb_unformatted_code = \"std = Standardizer()\\nstd.transform(test_dataset).get_prediction_data.head(2)\";\n                var nbb_formatted_code = \"std = Standardizer()\\nstd.transform(test_dataset).get_prediction_data.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "std = Standardizer()\n",
    "std.transform(test_dataset).get_prediction_data.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1. Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple prediction results can be ensembled in multiple ways, but we provide the most common use cases here."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Simple Mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 44;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass MeanEnsembler(BasePostProcessor):\\n    \\\"\\\"\\\" Take simple mean of multiple cols and store in new col. \\\"\\\"\\\"\\n    def __init__(self, cols: list, final_col_name: str):\\n        super().__init__(final_col_name=final_col_name)\\n        self.cols = cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        dataf.loc[:, self.final_col_name] = dataf.loc[:, self.cols].mean(axis=1)\\n        rich_print(f\\\":stew: Ensembled [blue]'{self.cols}'[blue] with simple mean and saved in [bold]'{self.final_col_name}'[bold] :stew:\\\")\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass MeanEnsembler(BasePostProcessor):\\n    \\\"\\\"\\\"Take simple mean of multiple cols and store in new col.\\\"\\\"\\\"\\n\\n    def __init__(self, cols: list, final_col_name: str):\\n        super().__init__(final_col_name=final_col_name)\\n        self.cols = cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        dataf.loc[:, self.final_col_name] = dataf.loc[:, self.cols].mean(axis=1)\\n        rich_print(\\n            f\\\":stew: Ensembled [blue]'{self.cols}'[blue] with simple mean and saved in [bold]'{self.final_col_name}'[bold] :stew:\\\"\\n        )\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class MeanEnsembler(BasePostProcessor):\n",
    "    \"\"\" Take simple mean of multiple cols and store in new col. \"\"\"\n",
    "    def __init__(self, cols: list, final_col_name: str):\n",
    "        super().__init__(final_col_name=final_col_name)\n",
    "        self.cols = cols\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        dataf.loc[:, self.final_col_name] = dataf.loc[:, self.cols].mean(axis=1)\n",
    "        rich_print(f\":stew: Ensembled [blue]'{self.cols}'[blue] with simple mean and saved in [bold]'{self.final_col_name}'[bold] :stew:\")\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Donate's formula"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 45;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass DonateWeightedEnsembler(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Weighted average as per Donate et al.'s formula\\n    https://doi.org/10.1016/j.neucom.2012.02.053\\n    [0.0625, 0.0625, 0.125, 0.25, 0.5] for 5 fold\\n    Source: https://www.kaggle.com/gogo827jz/jane-street-supervised-autoencoder-mlp\\n    \\\"\\\"\\\"\\n    def __init__(self, cols: list, final_col_name: str):\\n        super().__init__(final_col_name=final_col_name)\\n        self.cols = cols\\n        self.n_cols = len(cols)\\n        self.weights = self._get_weights()\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        dataf.loc[:, self.final_col_name] = np.average(dataf.loc[:, self.cols],\\n                                                       weights=self.weights, axis=1)\\n        rich_print(f\\\":stew: Ensembled [blue]'{self.cols}'[/blue] with [bold]{self.__class__.__name__}[/bold] and saved in [bold]'{self.final_col_name}'[bold] :stew:\\\")\\n        return NumerFrame(dataf)\\n\\n    def _get_weights(self) -> list:\\n        weights = []\\n        for j in range(1, self.n_cols+1):\\n            j = 2 if j == 1 else j\\n            weights.append(1 / (2**(self.n_cols + 1 - j)))\\n        return weights\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass DonateWeightedEnsembler(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Weighted average as per Donate et al.'s formula\\n    https://doi.org/10.1016/j.neucom.2012.02.053\\n    [0.0625, 0.0625, 0.125, 0.25, 0.5] for 5 fold\\n    Source: https://www.kaggle.com/gogo827jz/jane-street-supervised-autoencoder-mlp\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, cols: list, final_col_name: str):\\n        super().__init__(final_col_name=final_col_name)\\n        self.cols = cols\\n        self.n_cols = len(cols)\\n        self.weights = self._get_weights()\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        dataf.loc[:, self.final_col_name] = np.average(\\n            dataf.loc[:, self.cols], weights=self.weights, axis=1\\n        )\\n        rich_print(\\n            f\\\":stew: Ensembled [blue]'{self.cols}'[/blue] with [bold]{self.__class__.__name__}[/bold] and saved in [bold]'{self.final_col_name}'[bold] :stew:\\\"\\n        )\\n        return NumerFrame(dataf)\\n\\n    def _get_weights(self) -> list:\\n        weights = []\\n        for j in range(1, self.n_cols + 1):\\n            j = 2 if j == 1 else j\\n            weights.append(1 / (2 ** (self.n_cols + 1 - j)))\\n        return weights\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class DonateWeightedEnsembler(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Weighted average as per Donate et al.'s formula\n",
    "    https://doi.org/10.1016/j.neucom.2012.02.053\n",
    "    [0.0625, 0.0625, 0.125, 0.25, 0.5] for 5 fold\n",
    "    Source: https://www.kaggle.com/gogo827jz/jane-street-supervised-autoencoder-mlp\n",
    "    \"\"\"\n",
    "    def __init__(self, cols: list, final_col_name: str):\n",
    "        super().__init__(final_col_name=final_col_name)\n",
    "        self.cols = cols\n",
    "        self.n_cols = len(cols)\n",
    "        self.weights = self._get_weights()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        dataf.loc[:, self.final_col_name] = np.average(dataf.loc[:, self.cols],\n",
    "                                                       weights=self.weights, axis=1)\n",
    "        rich_print(f\":stew: Ensembled [blue]'{self.cols}'[/blue] with [bold]{self.__class__.__name__}[/bold] and saved in [bold]'{self.final_col_name}'[bold] :stew:\")\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def _get_weights(self) -> list:\n",
    "        weights = []\n",
    "        for j in range(1, self.n_cols+1):\n",
    "            j = 2 if j == 1 else j\n",
    "            weights.append(1 / (2**(self.n_cols + 1 - j)))\n",
    "        return weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 46;\n                var nbb_unformatted_code = \"# Random DataFrame\\ntest_features = [f\\\"prediction_{l}\\\" for l in \\\"ABCDE\\\"]\\ndf = pd.DataFrame(np.random.uniform(size=(100, 5)), columns=test_features)\\ndf[\\\"target\\\"] = np.random.normal(size=100)\\ndf[\\\"era\\\"] = range(100)\\ntest_dataset = NumerFrame(df)\";\n                var nbb_formatted_code = \"# Random DataFrame\\ntest_features = [f\\\"prediction_{l}\\\" for l in \\\"ABCDE\\\"]\\ndf = pd.DataFrame(np.random.uniform(size=(100, 5)), columns=test_features)\\ndf[\\\"target\\\"] = np.random.normal(size=100)\\ndf[\\\"era\\\"] = range(100)\\ntest_dataset = NumerFrame(df)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random DataFrame\n",
    "test_features = [f\"prediction_{l}\" for l in \"ABCDE\"]\n",
    "df = pd.DataFrame(np.random.uniform(size=(100, 5)), columns=test_features)\n",
    "df[\"target\"] = np.random.normal(size=100)\n",
    "df[\"era\"] = range(100)\n",
    "test_dataset = NumerFrame(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "🍲 Ensembled \u001B[34m'\u001B[0m\u001B[34m[\u001B[0m\u001B[34m'\u001B[0m\u001B[34mprediction_A', \u001B[0m\u001B[34m'prediction_B'\u001B[0m\u001B[34m, \u001B[0m\u001B[34m'prediction_C'\u001B[0m\u001B[34m, \u001B[0m\u001B[34m'prediction_D'\u001B[0m\u001B[34m, \u001B[0m\n\u001B[34m'prediction_E'\u001B[0m\u001B[1;34m]\u001B[0m\u001B[34m'\u001B[0m\u001B[32m with \u001B[0m\u001B[1;32mDonateWeightedEnsembler\u001B[0m\u001B[32m and saved in \u001B[0m\u001B[1;32m'\u001B[0m\u001B[1mprediction'\u001B[0m\u001B[1m 🍲\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍲 Ensembled <span style=\"color: #000080; text-decoration-color: #000080\">'['</span><span style=\"color: #000080; text-decoration-color: #000080\">prediction_A', </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_B'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_C'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_D'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span>\n<span style=\"color: #000080; text-decoration-color: #000080\">'prediction_E'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span><span style=\"color: #000080; text-decoration-color: #000080\">'</span><span style=\"color: #008000; text-decoration-color: #008000\"> with </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">DonateWeightedEnsembler</span><span style=\"color: #008000; text-decoration-color: #008000\"> and saved in </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'</span><span style=\"font-weight: bold\">prediction' 🍲</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mDonateWeightedEnsembler\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m100\u001B[0m, \u001B[1;36m8\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m004209\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">DonateWeightedEnsembler</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">004209</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   prediction_A  prediction_B  prediction_C  prediction_D  prediction_E  \\\n0      0.965094      0.400478      0.022906      0.560659      0.086063   \n1      0.326810      0.271006      0.053055      0.046910      0.401494   \n\n   prediction  \n0    0.271408  \n1    0.256470  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_A</th>\n      <th>prediction_B</th>\n      <th>prediction_C</th>\n      <th>prediction_D</th>\n      <th>prediction_E</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.965094</td>\n      <td>0.400478</td>\n      <td>0.022906</td>\n      <td>0.560659</td>\n      <td>0.086063</td>\n      <td>0.271408</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.326810</td>\n      <td>0.271006</td>\n      <td>0.053055</td>\n      <td>0.046910</td>\n      <td>0.401494</td>\n      <td>0.256470</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 47;\n                var nbb_unformatted_code = \"# [0.0625, 0.0625, 0.125, 0.25, 0.5] for 5 fold\\nw_5_fold = [0.0625, 0.0625, 0.125, 0.25, 0.5]\\ndonate = DonateWeightedEnsembler(cols=test_dataset.prediction_cols, final_col_name='prediction')\\nensembled = donate(test_dataset).get_prediction_data\\nassert ensembled['prediction'][0] == np.sum([w * elem for w, elem in zip(w_5_fold, ensembled[test_features].iloc[0])])\\nensembled.head(2)\";\n                var nbb_formatted_code = \"# [0.0625, 0.0625, 0.125, 0.25, 0.5] for 5 fold\\nw_5_fold = [0.0625, 0.0625, 0.125, 0.25, 0.5]\\ndonate = DonateWeightedEnsembler(\\n    cols=test_dataset.prediction_cols, final_col_name=\\\"prediction\\\"\\n)\\nensembled = donate(test_dataset).get_prediction_data\\nassert ensembled[\\\"prediction\\\"][0] == np.sum(\\n    [w * elem for w, elem in zip(w_5_fold, ensembled[test_features].iloc[0])]\\n)\\nensembled.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [0.0625, 0.0625, 0.125, 0.25, 0.5] for 5 fold\n",
    "w_5_fold = [0.0625, 0.0625, 0.125, 0.25, 0.5]\n",
    "donate = DonateWeightedEnsembler(cols=test_dataset.prediction_cols, final_col_name='prediction')\n",
    "ensembled = donate(test_dataset).get_prediction_data\n",
    "assert ensembled['prediction'][0] == np.sum([w * elem for w, elem in zip(w_5_fold, ensembled[test_features].iloc[0])])\n",
    "ensembled.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Geometric Mean\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 48;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass GeometricMeanEnsembler(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Calculate the weighted Geometric mean using inverse correlation.\\n    \\\"\\\"\\\"\\n    def __init__(self, cols: list, final_col_name: str):\\n        super().__init__(final_col_name=final_col_name)\\n        self.cols = cols\\n        self.n_cols = len(cols)\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs) -> NumerFrame:\\n        new_col = dataf.loc[:, self.cols].apply(gmean, axis=1)\\n        dataf.loc[:, self.final_col_name] = new_col\\n        rich_print(f\\\":stew: Ensembled [blue]'{self.cols}'[/blue] with [bold]{self.__class__.__name__}[/bold] and saved in [bold]'{self.final_col_name}'[bold] :stew:\\\")\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass GeometricMeanEnsembler(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Calculate the weighted Geometric mean using inverse correlation.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, cols: list, final_col_name: str):\\n        super().__init__(final_col_name=final_col_name)\\n        self.cols = cols\\n        self.n_cols = len(cols)\\n\\n    @display_processor_info\\n    def transform(\\n        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        new_col = dataf.loc[:, self.cols].apply(gmean, axis=1)\\n        dataf.loc[:, self.final_col_name] = new_col\\n        rich_print(\\n            f\\\":stew: Ensembled [blue]'{self.cols}'[/blue] with [bold]{self.__class__.__name__}[/bold] and saved in [bold]'{self.final_col_name}'[bold] :stew:\\\"\\n        )\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class GeometricMeanEnsembler(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Calculate the weighted Geometric mean using inverse correlation.\n",
    "    \"\"\"\n",
    "    def __init__(self, cols: list, final_col_name: str):\n",
    "        super().__init__(final_col_name=final_col_name)\n",
    "        self.cols = cols\n",
    "        self.n_cols = len(cols)\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs) -> NumerFrame:\n",
    "        new_col = dataf.loc[:, self.cols].apply(gmean, axis=1)\n",
    "        dataf.loc[:, self.final_col_name] = new_col\n",
    "        rich_print(f\":stew: Ensembled [blue]'{self.cols}'[/blue] with [bold]{self.__class__.__name__}[/bold] and saved in [bold]'{self.final_col_name}'[bold] :stew:\")\n",
    "        return NumerFrame(dataf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "🍲 Ensembled \u001B[34m'\u001B[0m\u001B[34m[\u001B[0m\u001B[34m'\u001B[0m\u001B[34mprediction_A', \u001B[0m\u001B[34m'prediction_B'\u001B[0m\u001B[34m, \u001B[0m\u001B[34m'prediction_C'\u001B[0m\u001B[34m, \u001B[0m\u001B[34m'prediction_D'\u001B[0m\u001B[34m, \u001B[0m\n\u001B[34m'prediction_E'\u001B[0m\u001B[1;34m]\u001B[0m\u001B[34m'\u001B[0m\u001B[32m with \u001B[0m\u001B[1;32mGeometricMeanEnsembler\u001B[0m\u001B[32m and saved in \u001B[0m\u001B[1;32m'\u001B[0m\u001B[1mprediction'\u001B[0m\u001B[1m 🍲\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍲 Ensembled <span style=\"color: #000080; text-decoration-color: #000080\">'['</span><span style=\"color: #000080; text-decoration-color: #000080\">prediction_A', </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_B'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_C'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_D'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span>\n<span style=\"color: #000080; text-decoration-color: #000080\">'prediction_E'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span><span style=\"color: #000080; text-decoration-color: #000080\">'</span><span style=\"color: #008000; text-decoration-color: #008000\"> with </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">GeometricMeanEnsembler</span><span style=\"color: #008000; text-decoration-color: #008000\"> and saved in </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'</span><span style=\"font-weight: bold\">prediction' 🍲</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mGeometricMeanEnsembler\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m100\u001B[0m, \u001B[1;36m8\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m006623\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">GeometricMeanEnsembler</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">006623</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "   prediction_A  prediction_B  prediction_C  prediction_D  prediction_E  \\\n0      0.965094      0.400478      0.022906      0.560659      0.086063   \n1      0.326810      0.271006      0.053055      0.046910      0.401494   \n\n   prediction  \n0    0.211896  \n1    0.154663  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_A</th>\n      <th>prediction_B</th>\n      <th>prediction_C</th>\n      <th>prediction_D</th>\n      <th>prediction_E</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.965094</td>\n      <td>0.400478</td>\n      <td>0.022906</td>\n      <td>0.560659</td>\n      <td>0.086063</td>\n      <td>0.211896</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.326810</td>\n      <td>0.271006</td>\n      <td>0.053055</td>\n      <td>0.046910</td>\n      <td>0.401494</td>\n      <td>0.154663</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 49;\n                var nbb_unformatted_code = \"geo_mean = GeometricMeanEnsembler(cols=test_dataset.prediction_cols, final_col_name='prediction')\\nensembled = geo_mean(test_dataset).get_prediction_data\\nensembled.head(2)\";\n                var nbb_formatted_code = \"geo_mean = GeometricMeanEnsembler(\\n    cols=test_dataset.prediction_cols, final_col_name=\\\"prediction\\\"\\n)\\nensembled = geo_mean(test_dataset).get_prediction_data\\nensembled.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "geo_mean = GeometricMeanEnsembler(cols=test_dataset.prediction_cols, final_col_name='prediction')\n",
    "ensembled = geo_mean(test_dataset).get_prediction_data\n",
    "ensembled.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2. Feature Neutralization"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classic feature neutralization (subtracting linear model from scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 50;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass FeatureNeutralizer(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Classic feature neutralization\\n    Subtracting Linear model.\\n    :param feature_names: List of column names to neutralize against.\\n    :param pred_name: Prediction column to neutralize.\\n    :param era_col: Numerai era column\\n    :param proportion: Number in range [0...1] indication how much to neutralize.\\n    \\\"\\\"\\\"\\n    def __init__(self,\\n                 feature_names: list = None,\\n                 pred_name: str = \\\"prediction\\\",\\n                 era_col: str = \\\"era\\\",\\n                 proportion: float = 0.5):\\n        self.pred_name = pred_name\\n        self.proportion = proportion\\n        assert 0. <= proportion <= 1., f\\\"'proportion' should be a float in range [0...1]. Got '{proportion}'.\\\"\\n        self.new_col_name = f\\\"{self.pred_name}_neutralized_{self.proportion}\\\"\\n        super().__init__(final_col_name=self.new_col_name)\\n\\n        self.feature_names = feature_names\\n        self.era_col = era_col\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\\n        neutralized_preds = dataf.groupby(self.era_col)\\\\\\n            .apply(lambda x: self.normalize_and_neutralize(x, [self.pred_name], feature_names))\\n        dataf.loc[:, self.new_col_name] = MinMaxScaler().fit_transform(neutralized_preds)\\n        rich_print(f\\\":robot: Neutralized [bold blue]'{self.pred_name}'[bold blue] with proportion [bold]'{self.proportion}'[/bold] :robot:\\\")\\n        rich_print(f\\\"New neutralized column = [bold green]'{self.new_col_name}'[/bold green].\\\")\\n        return NumerFrame(dataf)\\n\\n    def neutralize(self, dataf: pd.DataFrame, columns: list, by: list) -> pd.DataFrame:\\n        scores = dataf[columns]\\n        exposures = dataf[by].values\\n        scores = scores - self.proportion * exposures.dot(np.linalg.pinv(exposures).dot(scores))\\n        return scores / scores.std()\\n\\n    @staticmethod\\n    def normalize(dataf: pd.DataFrame) -> np.ndarray:\\n        normalized_ranks = (dataf.rank(method=\\\"first\\\") - 0.5) / len(dataf)\\n        return sp.norm.ppf(normalized_ranks)\\n\\n    def normalize_and_neutralize(self, dataf: pd.DataFrame, columns: list, by: list) -> pd.DataFrame:\\n        # Convert the scores to a normal distribution\\n        dataf[columns] = self.normalize(dataf[columns])\\n        dataf[columns] = self.neutralize(dataf, columns, by)\\n        return dataf[columns]\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass FeatureNeutralizer(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Classic feature neutralization\\n    Subtracting Linear model.\\n    :param feature_names: List of column names to neutralize against.\\n    :param pred_name: Prediction column to neutralize.\\n    :param era_col: Numerai era column\\n    :param proportion: Number in range [0...1] indication how much to neutralize.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        feature_names: list = None,\\n        pred_name: str = \\\"prediction\\\",\\n        era_col: str = \\\"era\\\",\\n        proportion: float = 0.5,\\n    ):\\n        self.pred_name = pred_name\\n        self.proportion = proportion\\n        assert (\\n            0.0 <= proportion <= 1.0\\n        ), f\\\"'proportion' should be a float in range [0...1]. Got '{proportion}'.\\\"\\n        self.new_col_name = f\\\"{self.pred_name}_neutralized_{self.proportion}\\\"\\n        super().__init__(final_col_name=self.new_col_name)\\n\\n        self.feature_names = feature_names\\n        self.era_col = era_col\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\\n        neutralized_preds = dataf.groupby(self.era_col).apply(\\n            lambda x: self.normalize_and_neutralize(x, [self.pred_name], feature_names)\\n        )\\n        dataf.loc[:, self.new_col_name] = MinMaxScaler().fit_transform(\\n            neutralized_preds\\n        )\\n        rich_print(\\n            f\\\":robot: Neutralized [bold blue]'{self.pred_name}'[bold blue] with proportion [bold]'{self.proportion}'[/bold] :robot:\\\"\\n        )\\n        rich_print(\\n            f\\\"New neutralized column = [bold green]'{self.new_col_name}'[/bold green].\\\"\\n        )\\n        return NumerFrame(dataf)\\n\\n    def neutralize(self, dataf: pd.DataFrame, columns: list, by: list) -> pd.DataFrame:\\n        scores = dataf[columns]\\n        exposures = dataf[by].values\\n        scores = scores - self.proportion * exposures.dot(\\n            np.linalg.pinv(exposures).dot(scores)\\n        )\\n        return scores / scores.std()\\n\\n    @staticmethod\\n    def normalize(dataf: pd.DataFrame) -> np.ndarray:\\n        normalized_ranks = (dataf.rank(method=\\\"first\\\") - 0.5) / len(dataf)\\n        return sp.norm.ppf(normalized_ranks)\\n\\n    def normalize_and_neutralize(\\n        self, dataf: pd.DataFrame, columns: list, by: list\\n    ) -> pd.DataFrame:\\n        # Convert the scores to a normal distribution\\n        dataf[columns] = self.normalize(dataf[columns])\\n        dataf[columns] = self.neutralize(dataf, columns, by)\\n        return dataf[columns]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class FeatureNeutralizer(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Classic feature neutralization\n",
    "    Subtracting Linear model.\n",
    "    :param feature_names: List of column names to neutralize against.\n",
    "    :param pred_name: Prediction column to neutralize.\n",
    "    :param era_col: Numerai era column\n",
    "    :param proportion: Number in range [0...1] indication how much to neutralize.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 feature_names: list = None,\n",
    "                 pred_name: str = \"prediction\",\n",
    "                 era_col: str = \"era\",\n",
    "                 proportion: float = 0.5):\n",
    "        self.pred_name = pred_name\n",
    "        self.proportion = proportion\n",
    "        assert 0. <= proportion <= 1., f\"'proportion' should be a float in range [0...1]. Got '{proportion}'.\"\n",
    "        self.new_col_name = f\"{self.pred_name}_neutralized_{self.proportion}\"\n",
    "        super().__init__(final_col_name=self.new_col_name)\n",
    "\n",
    "        self.feature_names = feature_names\n",
    "        self.era_col = era_col\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\n",
    "        neutralized_preds = dataf.groupby(self.era_col)\\\n",
    "            .apply(lambda x: self.normalize_and_neutralize(x, [self.pred_name], feature_names))\n",
    "        dataf.loc[:, self.new_col_name] = MinMaxScaler().fit_transform(neutralized_preds)\n",
    "        rich_print(f\":robot: Neutralized [bold blue]'{self.pred_name}'[bold blue] with proportion [bold]'{self.proportion}'[/bold] :robot:\")\n",
    "        rich_print(f\"New neutralized column = [bold green]'{self.new_col_name}'[/bold green].\")\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def neutralize(self, dataf: pd.DataFrame, columns: list, by: list) -> pd.DataFrame:\n",
    "        scores = dataf[columns]\n",
    "        exposures = dataf[by].values\n",
    "        scores = scores - self.proportion * exposures.dot(np.linalg.pinv(exposures).dot(scores))\n",
    "        return scores / scores.std()\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(dataf: pd.DataFrame) -> np.ndarray:\n",
    "        normalized_ranks = (dataf.rank(method=\"first\") - 0.5) / len(dataf)\n",
    "        return sp.norm.ppf(normalized_ranks)\n",
    "\n",
    "    def normalize_and_neutralize(self, dataf: pd.DataFrame, columns: list, by: list) -> pd.DataFrame:\n",
    "        # Convert the scores to a normal distribution\n",
    "        dataf[columns] = self.normalize(dataf[columns])\n",
    "        dataf[columns] = self.neutralize(dataf, columns, by)\n",
    "        return dataf[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 51;\n                var nbb_unformatted_code = \"test_dataset = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\ntest_dataset.loc[:, 'prediction'] = np.random.uniform(size=len(test_dataset))\";\n                var nbb_formatted_code = \"test_dataset = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\ntest_dataset.loc[:, \\\"prediction\\\"] = np.random.uniform(size=len(test_dataset))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = create_numerframe(\"test_assets/mini_numerai_version_1_data.csv\")\n",
    "test_dataset.loc[:, 'prediction'] = np.random.uniform(size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "🤖 Neutralized \u001B[1;34m'prediction'\u001B[0m\u001B[1;34m with proportion \u001B[0m\u001B[1;34m'0.8'\u001B[0m\u001B[1;34m 🤖\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🤖 Neutralized <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">'prediction'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> with proportion </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">'0.8'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 🤖</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "New neutralized column = \u001B[1;32m'prediction_neutralized_0.8'\u001B[0m.\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New neutralized column = <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'prediction_neutralized_0.8'</span>.\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mFeatureNeutralizer\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m316\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m019507\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">FeatureNeutralizer</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">316</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">019507</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 52;\n                var nbb_unformatted_code = \"ft = FeatureNeutralizer(feature_names=test_dataset.feature_cols, pred_name='prediction', proportion=0.8)\\nnew_dataset = ft.transform(test_dataset);\";\n                var nbb_formatted_code = \"ft = FeatureNeutralizer(\\n    feature_names=test_dataset.feature_cols, pred_name=\\\"prediction\\\", proportion=0.8\\n)\\nnew_dataset = ft.transform(test_dataset)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ft = FeatureNeutralizer(feature_names=test_dataset.feature_cols, pred_name='prediction', proportion=0.8)\n",
    "new_dataset = ft.transform(test_dataset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 53;\n                var nbb_unformatted_code = \"assert \\\"prediction_neutralized_0.8\\\" in new_dataset.prediction_cols\\nassert 0. in new_dataset.get_prediction_data['prediction_neutralized_0.8']\\nassert 1. in new_dataset.get_prediction_data['prediction_neutralized_0.8']\";\n                var nbb_formatted_code = \"assert \\\"prediction_neutralized_0.8\\\" in new_dataset.prediction_cols\\nassert 0.0 in new_dataset.get_prediction_data[\\\"prediction_neutralized_0.8\\\"]\\nassert 1.0 in new_dataset.get_prediction_data[\\\"prediction_neutralized_0.8\\\"]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert \"prediction_neutralized_0.8\" in new_dataset.prediction_cols\n",
    "assert 0. in new_dataset.get_prediction_data['prediction_neutralized_0.8']\n",
    "assert 1. in new_dataset.get_prediction_data['prediction_neutralized_0.8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['prediction', 'prediction_neutralized_0.8']"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 54;\n                var nbb_unformatted_code = \"new_dataset.prediction_cols\";\n                var nbb_formatted_code = \"new_dataset.prediction_cols\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_dataset.prediction_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   prediction  prediction_neutralized_0.8\n0    0.694602                    0.538198\n1    0.681106                    0.461802\n2    0.309822                    0.294970",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction</th>\n      <th>prediction_neutralized_0.8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.694602</td>\n      <td>0.538198</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.681106</td>\n      <td>0.461802</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.309822</td>\n      <td>0.294970</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 55;\n                var nbb_unformatted_code = \"new_dataset.get_prediction_data.head(3)\";\n                var nbb_formatted_code = \"new_dataset.get_prediction_data.head(3)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_dataset.get_prediction_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1.3. Feature Penalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 56;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass FeaturePenalizer(BasePostProcessor):\\n    \\\"\\\"\\\" Feature penalization with Tensorflow. \\\"\\\"\\\"\\n    def __init__(self, model_list: list, max_exposure: float,\\n                 risky_feature_names: list = None, pred_name: str = \\\"prediction\\\", era_col: str = 'era'):\\n        self.pred_name = pred_name\\n        self.max_exposure = max_exposure\\n        assert 0. <= max_exposure <= 1., f\\\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\\\"\\n        self.new_col_name = f\\\"{self.pred_name}_penalized_{self.max_exposure}\\\"\\n        super().__init__(final_col_name=self.new_col_name)\\n\\n        self.model_list = model_list\\n        self.risky_feature_names = risky_feature_names\\n        self.era_col = era_col\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        risky_feature_names = dataf.feature_cols if not self.risky_feature_names else self.risky_feature_names\\n        for model_name in tqdm(self.model_list, desc=\\\"Feature Penalization\\\"):\\n            penalized_data = self.reduce_all_exposures(\\n                            df=dataf,\\n                            column=self.pred_name,\\n                            neutralizers=risky_feature_names,\\n                        )\\n            new_pred_col = f\\\"prediction_{self.pred_name}_{model_name}_FP_{self.max_exposure}\\\"\\n            dataf.loc[:, new_pred_col] = penalized_data[self.pred_name]\\n        return NumerFrame(dataf)\\n\\n    def reduce_all_exposures(self, df: pd.DataFrame,\\n                             column: str = \\\"prediction\\\",\\n                             neutralizers: list = None,\\n                             normalize=True,\\n                             gaussianize=True,\\n                             ):\\n        if neutralizers is None:\\n            neutralizers = [x for x in df.columns if x.startswith(\\\"feature\\\")]\\n        neutralized = []\\n\\n        for era in tqdm(df[self.era_col].unique()):\\n            df_era = df[df[self.era_col] == era]\\n            scores = df_era[[column]].values\\n            exposure_values = df_era[neutralizers].values\\n\\n            if normalize:\\n                scores2 = []\\n                for x in scores.T:\\n                    x = (scipy.stats.rankdata(x, method='ordinal') - .5) / len(x)\\n                    if gaussianize:\\n                        x = scipy.stats.norm.ppf(x)\\n                    scores2.append(x)\\n                scores = np.array(scores2)[0]\\n\\n            scores, weights = self._reduce_exposure(scores, exposure_values,\\n                                                    len(neutralizers), None)\\n\\n            scores /= tf.math.reduce_std(scores)\\n            scores -= tf.reduce_min(scores)\\n            scores /= tf.reduce_max(scores)\\n            neutralized.append(scores.numpy())\\n\\n        predictions = pd.DataFrame(np.concatenate(neutralized),\\n                                   columns=[column], index=df.index)\\n        return predictions\\n\\n    def _reduce_exposure(self, prediction, features, input_size=50, weights=None):\\n        model = tf.keras.models.Sequential([\\n            tf.keras.layers.Input(input_size),\\n            tf.keras.experimental.LinearModel(use_bias=False),\\n        ])\\n        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\\n        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\\n        if weights is None:\\n            optimizer = tf.keras.optimizers.Adamax()\\n            start_exp = self.__exposures(feats, pred[:, None])\\n            target_exps = tf.clip_by_value(start_exp, -self.max_exposure, self.max_exposure)\\n            self._train_loop(model, optimizer, feats, pred, target_exps)\\n        else:\\n            model.set_weights(weights)\\n        return pred[:,None] - model(feats), model.get_weights()\\n\\n\\n    def _train_loop(self, model, optimizer, feats, pred, target_exps):\\n        for i in range(1000000):\\n            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\\n            if loss < 1e-7:\\n                break\\n\\n    @tf.function(experimental_relax_shapes=True)\\n    def __train_loop_body(self, model, feats, pred, target_exps):\\n        with tf.GradientTape() as tape:\\n            exps = self.__exposures(feats, pred[:, None] - model(feats, training=True))\\n            loss = tf.reduce_sum(tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps)) +\\n                                 tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps)))\\n        return loss, tape.gradient(loss, model.trainable_variables)\\n\\n    @staticmethod\\n    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\\n    def __exposures(x, y):\\n        x = x - tf.math.reduce_mean(x, axis=0)\\n        x = x / tf.norm(x, axis=0)\\n        y = y - tf.math.reduce_mean(y, axis=0)\\n        y = y / tf.norm(y, axis=0)\\n        return tf.matmul(x, y, transpose_a=True)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass FeaturePenalizer(BasePostProcessor):\\n    \\\"\\\"\\\"Feature penalization with Tensorflow.\\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        model_list: list,\\n        max_exposure: float,\\n        risky_feature_names: list = None,\\n        pred_name: str = \\\"prediction\\\",\\n        era_col: str = \\\"era\\\",\\n    ):\\n        self.pred_name = pred_name\\n        self.max_exposure = max_exposure\\n        assert (\\n            0.0 <= max_exposure <= 1.0\\n        ), f\\\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\\\"\\n        self.new_col_name = f\\\"{self.pred_name}_penalized_{self.max_exposure}\\\"\\n        super().__init__(final_col_name=self.new_col_name)\\n\\n        self.model_list = model_list\\n        self.risky_feature_names = risky_feature_names\\n        self.era_col = era_col\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        risky_feature_names = (\\n            dataf.feature_cols\\n            if not self.risky_feature_names\\n            else self.risky_feature_names\\n        )\\n        for model_name in tqdm(self.model_list, desc=\\\"Feature Penalization\\\"):\\n            penalized_data = self.reduce_all_exposures(\\n                df=dataf,\\n                column=self.pred_name,\\n                neutralizers=risky_feature_names,\\n            )\\n            new_pred_col = (\\n                f\\\"prediction_{self.pred_name}_{model_name}_FP_{self.max_exposure}\\\"\\n            )\\n            dataf.loc[:, new_pred_col] = penalized_data[self.pred_name]\\n        return NumerFrame(dataf)\\n\\n    def reduce_all_exposures(\\n        self,\\n        df: pd.DataFrame,\\n        column: str = \\\"prediction\\\",\\n        neutralizers: list = None,\\n        normalize=True,\\n        gaussianize=True,\\n    ):\\n        if neutralizers is None:\\n            neutralizers = [x for x in df.columns if x.startswith(\\\"feature\\\")]\\n        neutralized = []\\n\\n        for era in tqdm(df[self.era_col].unique()):\\n            df_era = df[df[self.era_col] == era]\\n            scores = df_era[[column]].values\\n            exposure_values = df_era[neutralizers].values\\n\\n            if normalize:\\n                scores2 = []\\n                for x in scores.T:\\n                    x = (scipy.stats.rankdata(x, method=\\\"ordinal\\\") - 0.5) / len(x)\\n                    if gaussianize:\\n                        x = scipy.stats.norm.ppf(x)\\n                    scores2.append(x)\\n                scores = np.array(scores2)[0]\\n\\n            scores, weights = self._reduce_exposure(\\n                scores, exposure_values, len(neutralizers), None\\n            )\\n\\n            scores /= tf.math.reduce_std(scores)\\n            scores -= tf.reduce_min(scores)\\n            scores /= tf.reduce_max(scores)\\n            neutralized.append(scores.numpy())\\n\\n        predictions = pd.DataFrame(\\n            np.concatenate(neutralized), columns=[column], index=df.index\\n        )\\n        return predictions\\n\\n    def _reduce_exposure(self, prediction, features, input_size=50, weights=None):\\n        model = tf.keras.models.Sequential(\\n            [\\n                tf.keras.layers.Input(input_size),\\n                tf.keras.experimental.LinearModel(use_bias=False),\\n            ]\\n        )\\n        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\\n        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\\n        if weights is None:\\n            optimizer = tf.keras.optimizers.Adamax()\\n            start_exp = self.__exposures(feats, pred[:, None])\\n            target_exps = tf.clip_by_value(\\n                start_exp, -self.max_exposure, self.max_exposure\\n            )\\n            self._train_loop(model, optimizer, feats, pred, target_exps)\\n        else:\\n            model.set_weights(weights)\\n        return pred[:, None] - model(feats), model.get_weights()\\n\\n    def _train_loop(self, model, optimizer, feats, pred, target_exps):\\n        for i in range(1000000):\\n            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\\n            if loss < 1e-7:\\n                break\\n\\n    @tf.function(experimental_relax_shapes=True)\\n    def __train_loop_body(self, model, feats, pred, target_exps):\\n        with tf.GradientTape() as tape:\\n            exps = self.__exposures(feats, pred[:, None] - model(feats, training=True))\\n            loss = tf.reduce_sum(\\n                tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps))\\n                + tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps))\\n            )\\n        return loss, tape.gradient(loss, model.trainable_variables)\\n\\n    @staticmethod\\n    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\\n    def __exposures(x, y):\\n        x = x - tf.math.reduce_mean(x, axis=0)\\n        x = x / tf.norm(x, axis=0)\\n        y = y - tf.math.reduce_mean(y, axis=0)\\n        y = y / tf.norm(y, axis=0)\\n        return tf.matmul(x, y, transpose_a=True)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class FeaturePenalizer(BasePostProcessor):\n",
    "    \"\"\" Feature penalization with Tensorflow. \"\"\"\n",
    "    def __init__(self, model_list: list, max_exposure: float,\n",
    "                 risky_feature_names: list = None, pred_name: str = \"prediction\", era_col: str = 'era'):\n",
    "        self.pred_name = pred_name\n",
    "        self.max_exposure = max_exposure\n",
    "        assert 0. <= max_exposure <= 1., f\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\"\n",
    "        self.new_col_name = f\"{self.pred_name}_penalized_{self.max_exposure}\"\n",
    "        super().__init__(final_col_name=self.new_col_name)\n",
    "\n",
    "        self.model_list = model_list\n",
    "        self.risky_feature_names = risky_feature_names\n",
    "        self.era_col = era_col\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        risky_feature_names = dataf.feature_cols if not self.risky_feature_names else self.risky_feature_names\n",
    "        for model_name in tqdm(self.model_list, desc=\"Feature Penalization\"):\n",
    "            penalized_data = self.reduce_all_exposures(\n",
    "                            df=dataf,\n",
    "                            column=self.pred_name,\n",
    "                            neutralizers=risky_feature_names,\n",
    "                        )\n",
    "            new_pred_col = f\"prediction_{self.pred_name}_{model_name}_FP_{self.max_exposure}\"\n",
    "            dataf.loc[:, new_pred_col] = penalized_data[self.pred_name]\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def reduce_all_exposures(self, df: pd.DataFrame,\n",
    "                             column: str = \"prediction\",\n",
    "                             neutralizers: list = None,\n",
    "                             normalize=True,\n",
    "                             gaussianize=True,\n",
    "                             ):\n",
    "        if neutralizers is None:\n",
    "            neutralizers = [x for x in df.columns if x.startswith(\"feature\")]\n",
    "        neutralized = []\n",
    "\n",
    "        for era in tqdm(df[self.era_col].unique()):\n",
    "            df_era = df[df[self.era_col] == era]\n",
    "            scores = df_era[[column]].values\n",
    "            exposure_values = df_era[neutralizers].values\n",
    "\n",
    "            if normalize:\n",
    "                scores2 = []\n",
    "                for x in scores.T:\n",
    "                    x = (scipy.stats.rankdata(x, method='ordinal') - .5) / len(x)\n",
    "                    if gaussianize:\n",
    "                        x = scipy.stats.norm.ppf(x)\n",
    "                    scores2.append(x)\n",
    "                scores = np.array(scores2)[0]\n",
    "\n",
    "            scores, weights = self._reduce_exposure(scores, exposure_values,\n",
    "                                                    len(neutralizers), None)\n",
    "\n",
    "            scores /= tf.math.reduce_std(scores)\n",
    "            scores -= tf.reduce_min(scores)\n",
    "            scores /= tf.reduce_max(scores)\n",
    "            neutralized.append(scores.numpy())\n",
    "\n",
    "        predictions = pd.DataFrame(np.concatenate(neutralized),\n",
    "                                   columns=[column], index=df.index)\n",
    "        return predictions\n",
    "\n",
    "    def _reduce_exposure(self, prediction, features, input_size=50, weights=None):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Input(input_size),\n",
    "            tf.keras.experimental.LinearModel(use_bias=False),\n",
    "        ])\n",
    "        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\n",
    "        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\n",
    "        if weights is None:\n",
    "            optimizer = tf.keras.optimizers.Adamax()\n",
    "            start_exp = self.__exposures(feats, pred[:, None])\n",
    "            target_exps = tf.clip_by_value(start_exp, -self.max_exposure, self.max_exposure)\n",
    "            self._train_loop(model, optimizer, feats, pred, target_exps)\n",
    "        else:\n",
    "            model.set_weights(weights)\n",
    "        return pred[:,None] - model(feats), model.get_weights()\n",
    "\n",
    "\n",
    "    def _train_loop(self, model, optimizer, feats, pred, target_exps):\n",
    "        for i in range(1000000):\n",
    "            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            if loss < 1e-7:\n",
    "                break\n",
    "\n",
    "    @tf.function(experimental_relax_shapes=True)\n",
    "    def __train_loop_body(self, model, feats, pred, target_exps):\n",
    "        with tf.GradientTape() as tape:\n",
    "            exps = self.__exposures(feats, pred[:, None] - model(feats, training=True))\n",
    "            loss = tf.reduce_sum(tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps)) +\n",
    "                                 tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps)))\n",
    "        return loss, tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    @staticmethod\n",
    "    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\n",
    "    def __exposures(x, y):\n",
    "        x = x - tf.math.reduce_mean(x, axis=0)\n",
    "        x = x / tf.norm(x, axis=0)\n",
    "        y = y - tf.math.reduce_mean(y, axis=0)\n",
    "        y = y / tf.norm(y, axis=0)\n",
    "        return tf.matmul(x, y, transpose_a=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 57;\n                var nbb_unformatted_code = \"# TODO Test Feature penalizer\\ntest_dataset = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\ntest_dataset.loc[:, 'prediction'] = np.random.uniform(size=len(test_dataset))\";\n                var nbb_formatted_code = \"# TODO Test Feature penalizer\\ntest_dataset = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\ntest_dataset.loc[:, \\\"prediction\\\"] = np.random.uniform(size=len(test_dataset))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO Test Feature penalizer\n",
    "test_dataset = create_numerframe(\"test_assets/mini_numerai_version_1_data.csv\")\n",
    "test_dataset.loc[:, 'prediction'] = np.random.uniform(size=len(test_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "Feature Penalization: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2dae7e156b11484d80f52b1ae15a6940"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mFeaturePenalizer\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m315\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m026732\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">FeaturePenalizer</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">315</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">026732</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 58;\n                var nbb_unformatted_code = \"ft = FeaturePenalizer(model_list=[], pred_name='prediction', max_exposure=0.8)\\nnew_dataset = ft.transform(test_dataset);\";\n                var nbb_formatted_code = \"ft = FeaturePenalizer(model_list=[], pred_name=\\\"prediction\\\", max_exposure=0.8)\\nnew_dataset = ft.transform(test_dataset)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ft = FeaturePenalizer(model_list=[], pred_name='prediction', max_exposure=0.8)\n",
    "new_dataset = ft.transform(test_dataset);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2. Version 1 specific"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3. Version 2 specific"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4. Signals specific"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom PostProcessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are an almost unlimited number of ways to postprocess data. We invite the Numerai community to develop Numerai Classic and Signals preprocessors for `numerai-blocks`.\n",
    "\n",
    "A new PostProcessor should inherit from `BasePostProcessor` and implement a `transform` method. The `transform` method should take a `NumerFrame` or `DataFrame` as input and return a `NumerFrame` object as output. A template is given below.\n",
    "\n",
    "We recommend adding `@typechecked` at the top of a new PostProcessor class to enforce types and provide useful debugging stacktraces.\n",
    "\n",
    "To enable fancy logging output. Add the `@display_processor_info` decorator to the `transform` method.\n",
    "\n",
    "Note that arbitrary metadata can be added or changed in the `NumerFrame` class during a postprocessing step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 59;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass AwesomePostProcessor(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    - TEMPLATE -\\n    Do some awesome postprocessing.\\n    :param final_col_name: Column name to store manipulated or ensembled predictions in.\\n    \\\"\\\"\\\"\\n    def __init__(self, final_col_name: str, *args, **kwargs):\\n        super().__init__(final_col_name=final_col_name)\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs) -> NumerFrame:\\n        # Do processing\\n        ...\\n        # Add new column(s) for manipulated data (optional)\\n        dataf.loc[:, self.final_col_name] = ...\\n        ...\\n        # Parse all contents to the next pipeline step\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass AwesomePostProcessor(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    - TEMPLATE -\\n    Do some awesome postprocessing.\\n    :param final_col_name: Column name to store manipulated or ensembled predictions in.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, final_col_name: str, *args, **kwargs):\\n        super().__init__(final_col_name=final_col_name)\\n\\n    @display_processor_info\\n    def transform(\\n        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        # Do processing\\n        ...\\n        # Add new column(s) for manipulated data (optional)\\n        dataf.loc[:, self.final_col_name] = ...\\n        ...\\n        # Parse all contents to the next pipeline step\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class AwesomePostProcessor(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    - TEMPLATE -\n",
    "    Do some awesome postprocessing.\n",
    "    :param final_col_name: Column name to store manipulated or ensembled predictions in.\n",
    "    \"\"\"\n",
    "    def __init__(self, final_col_name: str, *args, **kwargs):\n",
    "        super().__init__(final_col_name=final_col_name)\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs) -> NumerFrame:\n",
    "        # Do processing\n",
    "        ...\n",
    "        # Add new column(s) for manipulated data (optional)\n",
    "        dataf.loc[:, self.final_col_name] = ...\n",
    "        ...\n",
    "        # Parse all contents to the next pipeline step\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_download.ipynb.\n",
      "Converted 02_numerframe.ipynb.\n",
      "Converted 03_preprocessing.ipynb.\n",
      "Converted 04_model.ipynb.\n",
      "Converted 05_postprocessing.ipynb.\n",
      "Converted 06_modelpipeline.ipynb.\n",
      "Converted 07_evaluation.ipynb.\n",
      "Converted 08_key.ipynb.\n",
      "Converted 09_submission.ipynb.\n",
      "Converted 10_staking.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 60;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# Run this cell to sync all changes with library\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 60;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}