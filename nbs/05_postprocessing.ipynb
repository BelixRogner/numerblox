{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_formatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"# default_exp postprocessing\";\n                var nbb_formatted_code = \"# default_exp postprocessing\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default_exp postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The postprocessing procedure is very similar to preprocessing.\n",
    "\n",
    "The only difference between a postprocessing step and a preprocessing step is that preprocessing works on `feature_` columns while postprocessing manipulates `prediction_` columns.\n",
    "\n",
    "Therefore, we also inherit from `BaseProcessor` for postprocessing. The PostProcessor should take a `Dataset` as input and output a `Dataset` where either:\n",
    "1. `prediction_` columns are manipulated or\n",
    "2. A new prediction column is added with prefix `prediction_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_formatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"#export\\nimport numpy as np\\nimport pandas as pd\\nimport scipy.stats as sp\\nfrom typeguard import typechecked\\nfrom rich import print as rich_print\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\nfrom numerai_blocks.preprocessing import BaseProcessor, display_processor_info\\nfrom numerai_blocks.dataset import Dataset\";\n                var nbb_formatted_code = \"# export\\nimport numpy as np\\nimport pandas as pd\\nimport scipy.stats as sp\\nfrom typeguard import typechecked\\nfrom rich import print as rich_print\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\nfrom numerai_blocks.preprocessing import BaseProcessor, display_processor_info\\nfrom numerai_blocks.dataset import Dataset\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sp\n",
    "from typeguard import typechecked\n",
    "from rich import print as rich_print\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from numerai_blocks.preprocessing import BaseProcessor, display_processor_info\n",
    "from numerai_blocks.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple prediction results can be ensembled in multiple ways, but we provide the most common use cases here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass MeanEnsembler(BaseProcessor):\\n    \\\"\\\"\\\" Take simple mean of multiple cols and store in new col. \\\"\\\"\\\"\\n    def __init__(self, cols: list, final_col_name: str):\\n        super(MeanEnsembler, self).__init__()\\n        self.cols = cols\\n        self.final_col_name = final_col_name\\n        assert final_col_name.startswith(\\\"prediction\\\"), f\\\"final_col name should start with 'prediction'. Got {final_col_name}\\\"\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        dataset.dataf.loc[:, [self.cols]][self.final_col_name] = dataset.dataf.loc[:, self.cols].mean(axis=1)\\n        rich_print(f\\\":stew: Ensembled '{self.cols}' with simple mean and saved in '{self.final_col_name}' :stew:\\\")\\n        return Dataset(**dataset.__dict__)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass MeanEnsembler(BaseProcessor):\\n    \\\"\\\"\\\"Take simple mean of multiple cols and store in new col.\\\"\\\"\\\"\\n\\n    def __init__(self, cols: list, final_col_name: str):\\n        super(MeanEnsembler, self).__init__()\\n        self.cols = cols\\n        self.final_col_name = final_col_name\\n        assert final_col_name.startswith(\\n            \\\"prediction\\\"\\n        ), f\\\"final_col name should start with 'prediction'. Got {final_col_name}\\\"\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        dataset.dataf.loc[:, [self.cols]][self.final_col_name] = dataset.dataf.loc[\\n            :, self.cols\\n        ].mean(axis=1)\\n        rich_print(\\n            f\\\":stew: Ensembled '{self.cols}' with simple mean and saved in '{self.final_col_name}' :stew:\\\"\\n        )\\n        return Dataset(**dataset.__dict__)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class MeanEnsembler(BaseProcessor):\n",
    "    \"\"\" Take simple mean of multiple cols and store in new col. \"\"\"\n",
    "    def __init__(self, cols: list, final_col_name: str):\n",
    "        super(MeanEnsembler, self).__init__()\n",
    "        self.cols = cols\n",
    "        self.final_col_name = final_col_name\n",
    "        assert final_col_name.startswith(\"prediction\"), f\"final_col name should start with 'prediction'. Got {final_col_name}\"\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n",
    "        dataset.dataf.loc[:, [self.cols]][self.final_col_name] = dataset.dataf.loc[:, self.cols].mean(axis=1)\n",
    "        rich_print(f\":stew: Ensembled '{self.cols}' with simple mean and saved in '{self.final_col_name}' :stew:\")\n",
    "        return Dataset(**dataset.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Neutralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass FeatureNeutralizer(BaseProcessor):\\n    \\\"\\\"\\\" Feature \\\"\\\"\\\"\\n    def __init__(self, feature_names: list,\\n                 pred_name: str = \\\"prediction\\\",\\n                 proportion=0.5):\\n        super(FeatureNeutralizer, self).__init__()\\n        self.proportion = proportion\\n        self.feature_names = feature_names\\n        self.pred_name = pred_name\\n        self.new_col_name = f\\\"{self.pred_name}_neutralized_{self.proportion}\\\"\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset):\\n        neutralized_preds = dataset.dataf.groupby(\\\"era\\\").apply(lambda x: self.normalize_and_neutralize(x, [self.pred_name], self.feature_names))\\n        min_max_scaled_preds = MinMaxScaler().fit_transform(neutralized_preds)\\n        dataset.dataf.loc[:, self.new_col_name] = min_max_scaled_preds\\n        rich_print(f\\\":robot: Neutralized [bold]'{self.pred_name}'[bold] with proportion [bold]'{self.proportion}'[/bold] :robot:\\\")\\n        rich_print(f\\\"New neutralized column = [bold green]'{self.new_col_name}'[/bold green]\\\")\\n        return Dataset(**dataset.__dict__)\\n\\n    def _neutralize(self, scores, exposures):\\n        neutral_scores = scores - self.proportion * exposures.dot(np.linalg.pinv(exposures).dot(scores))\\n        return neutral_scores / scores.std()\\n\\n    @staticmethod\\n    def _normalize(dataf: pd.DataFrame):\\n        normalized_ranks = (dataf.rank(method=\\\"first\\\") - 0.5) / len(dataf)\\n        return sp.norm.ppf(normalized_ranks)\\n\\n    def normalize_and_neutralize(self, dataf: pd.DataFrame, pred_cols, by):\\n        # Convert the scores to a normal distribution\\n        preds, by_matrix = dataf[pred_cols], dataf[by].values\\n        preds = self._normalize(preds)\\n        preds = self._neutralize(preds, by_matrix)\\n        return preds\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass FeatureNeutralizer(BaseProcessor):\\n    \\\"\\\"\\\"Feature\\\"\\\"\\\"\\n\\n    def __init__(\\n        self, feature_names: list, pred_name: str = \\\"prediction\\\", proportion=0.5\\n    ):\\n        super(FeatureNeutralizer, self).__init__()\\n        self.proportion = proportion\\n        self.feature_names = feature_names\\n        self.pred_name = pred_name\\n        self.new_col_name = f\\\"{self.pred_name}_neutralized_{self.proportion}\\\"\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset):\\n        neutralized_preds = dataset.dataf.groupby(\\\"era\\\").apply(\\n            lambda x: self.normalize_and_neutralize(\\n                x, [self.pred_name], self.feature_names\\n            )\\n        )\\n        min_max_scaled_preds = MinMaxScaler().fit_transform(neutralized_preds)\\n        dataset.dataf.loc[:, self.new_col_name] = min_max_scaled_preds\\n        rich_print(\\n            f\\\":robot: Neutralized [bold]'{self.pred_name}'[bold] with proportion [bold]'{self.proportion}'[/bold] :robot:\\\"\\n        )\\n        rich_print(\\n            f\\\"New neutralized column = [bold green]'{self.new_col_name}'[/bold green]\\\"\\n        )\\n        return Dataset(**dataset.__dict__)\\n\\n    def _neutralize(self, scores, exposures):\\n        neutral_scores = scores - self.proportion * exposures.dot(\\n            np.linalg.pinv(exposures).dot(scores)\\n        )\\n        return neutral_scores / scores.std()\\n\\n    @staticmethod\\n    def _normalize(dataf: pd.DataFrame):\\n        normalized_ranks = (dataf.rank(method=\\\"first\\\") - 0.5) / len(dataf)\\n        return sp.norm.ppf(normalized_ranks)\\n\\n    def normalize_and_neutralize(self, dataf: pd.DataFrame, pred_cols, by):\\n        # Convert the scores to a normal distribution\\n        preds, by_matrix = dataf[pred_cols], dataf[by].values\\n        preds = self._normalize(preds)\\n        preds = self._neutralize(preds, by_matrix)\\n        return preds\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class FeatureNeutralizer(BaseProcessor):\n",
    "    \"\"\" Feature \"\"\"\n",
    "    def __init__(self, feature_names: list,\n",
    "                 pred_name: str = \"prediction\",\n",
    "                 proportion=0.5):\n",
    "        super(FeatureNeutralizer, self).__init__()\n",
    "        self.proportion = proportion\n",
    "        self.feature_names = feature_names\n",
    "        self.pred_name = pred_name\n",
    "        self.new_col_name = f\"{self.pred_name}_neutralized_{self.proportion}\"\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n",
    "        neutralized_preds = dataset.dataf.groupby(\"era\").apply(lambda x: self.normalize_and_neutralize(x, [self.pred_name], self.feature_names))\n",
    "        min_max_scaled_preds = MinMaxScaler().fit_transform(neutralized_preds)\n",
    "        dataset.dataf.loc[:, self.new_col_name] = min_max_scaled_preds\n",
    "        rich_print(f\":robot: Neutralized [bold]'{self.pred_name}'[bold] with proportion [bold]'{self.proportion}'[/bold] :robot:\")\n",
    "        rich_print(f\"New neutralized column = [bold green]'{self.new_col_name}'[/bold green]\")\n",
    "        return Dataset(**dataset.__dict__)\n",
    "\n",
    "    def _neutralize(self, scores, exposures):\n",
    "        neutral_scores = scores - self.proportion * exposures.dot(np.linalg.pinv(exposures).dot(scores))\n",
    "        return neutral_scores / scores.std()\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize(dataf: pd.DataFrame):\n",
    "        normalized_ranks = (dataf.rank(method=\"first\") - 0.5) / len(dataf)\n",
    "        return sp.norm.ppf(normalized_ranks)\n",
    "\n",
    "    def normalize_and_neutralize(self, dataf: pd.DataFrame, pred_cols, by):\n",
    "        # Convert the scores to a normal distribution\n",
    "        preds, by_matrix = dataf[pred_cols], dataf[by].values\n",
    "        preds = self._normalize(preds)\n",
    "        preds = self._neutralize(preds, by_matrix)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom PostProcessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are an almost unlimited number of ways to postprocess data. We invite the Numerai community to develop Numerai Classic and Signals preprocessors for `numerai-blocks`.\n",
    "\n",
    "A new PostProcessor should inherit from `BaseProcessor` and implement a `transform` method. The `transform` method should take a `Dataset` as input and return a `Dataset` object as output. An example is given below.\n",
    "\n",
    "We recommend adding `@typechecked` at the top of a new PostProcessor class to enforce types and provide useful debugging stacktraces.\n",
    "\n",
    "To enable fancy logging output. Add the `@display_processor_info` decorator to the `transform` method.\n",
    "\n",
    "Note that arbitrary metadata can be added or changed in the `Dataset` class during a postprocessing step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass AwesomePostProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    - TEMPLATE -\\n    Do some awesome postprocessing.\\n    \\\"\\\"\\\"\\n    def __init__(self, *args, **kwargs):\\n        super(AwesomePostProcessor, self).__init__()\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        # Do processing\\n        ...\\n        # Add new column for manipulated data (optional)\\n        new_column_name = \\\"NEW_COLUMN_NAME\\\"\\n        dataset.dataf.loc[:, f\\\"prediction_{new_column_name}\\\"] = ...\\n        return Dataset(**dataset.__dict__)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass AwesomePostProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    - TEMPLATE -\\n    Do some awesome postprocessing.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, *args, **kwargs):\\n        super(AwesomePostProcessor, self).__init__()\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        # Do processing\\n        ...\\n        # Add new column for manipulated data (optional)\\n        new_column_name = \\\"NEW_COLUMN_NAME\\\"\\n        dataset.dataf.loc[:, f\\\"prediction_{new_column_name}\\\"] = ...\\n        return Dataset(**dataset.__dict__)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class AwesomePostProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    - TEMPLATE -\n",
    "    Do some awesome postprocessing.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AwesomePostProcessor, self).__init__()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n",
    "        # Do processing\n",
    "        ...\n",
    "        # Add new column for manipulated data (optional)\n",
    "        new_column_name = \"NEW_COLUMN_NAME\"\n",
    "        dataset.dataf.loc[:, f\"prediction_{new_column_name}\"] = ...\n",
    "        ...\n",
    "        # Parse all contents of Dataset to the next pipeline step\n",
    "        return Dataset(**dataset.__dict__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
