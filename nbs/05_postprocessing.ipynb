{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Prediction manipulation.\n",
    "output-file: postprocessing.html\n",
    "title: Postprocessing\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The postprocessing procedure is similar to preprocessing. Preprocessors manipulate and/or add `feature` columns, while postprocessors manipulate and/or add `prediction` columns.\n",
    "\n",
    "Every postprocessor should inherit from `BasePostProcessor`. A postprocessor should take a `NumerFrame` as input and output a `NumerFrame`. One or more new prediction column(s) with prefix `prediction` are added or manipulated in a postprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import scipy.stats as sp\n",
    "from tqdm.auto import tqdm\n",
    "from typeguard import typechecked\n",
    "from rich import print as rich_print\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from numerblox.numerframe import NumerFrame, create_numerframe\n",
    "from numerblox.preprocessing import BaseProcessor, display_processor_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. BasePostProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some characteristics are particular to Postprocessors, but not suitable to put in the `Processor` base class.\n",
    "This functionality is implemented in `BasePostProcessor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BasePostProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Base class for postprocessing objects.\n",
    "\n",
    "    Postprocessors manipulate or introduce new prediction columns in a NumerFrame.\n",
    "    \"\"\"\n",
    "    def __init__(self, final_col_name: str):\n",
    "        super().__init__()\n",
    "        self.final_col_name = final_col_name\n",
    "        if not final_col_name.startswith(\"prediction\"):\n",
    "            rich_print(f\":warning: WARNING: final_col_name should start with 'prediction'. Column output will be: '{final_col_name}'. :warning:\")\n",
    "\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Common postprocessing steps\n",
    "\n",
    "We invite the Numerai community to develop new postprocessors so that everyone can benefit from new insights and research.\n",
    "This section implements commonly used postprocessing for Numerai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0. Tournament agnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postprocessing that works for both Numerai Classic and Numerai Signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.1. Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing is an essential step in order to reliably combine Numerai predictions. It is a default postprocessor for `ModelPipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class Standardizer(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Uniform standardization of prediction columns.\n",
    "    All values should only contain values in the range [0...1].\n",
    "\n",
    "    :param cols: All prediction columns that should be standardized. Use all prediction columns by default.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cols: list = None):\n",
    "        super().__init__(final_col_name=\"prediction\")\n",
    "        self.cols = cols\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        cols = dataf.prediction_cols if not self.cols else self.cols\n",
    "        dataf.loc[:, cols] = dataf.groupby(dataf.meta.era_col)[cols].rank(pct=True)\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random DataFrame\n",
    "test_features = [f\"prediction_{l}\" for l in \"ABCDE\"]\n",
    "df = pd.DataFrame(np.random.uniform(size=(100, 5)), columns=test_features)\n",
    "df[\"target\"] = np.random.normal(size=100)\n",
    "df[\"date\"] = [0, 1, 2, 3] * 25\n",
    "test_dataf = NumerFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameGroupBy' object has no attribute '_obj_with_exclusions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m std \u001b[39m=\u001b[39m Standardizer()\n\u001b[0;32m----> 2\u001b[0m std\u001b[39m.\u001b[39;49mtransform(test_dataf)\u001b[39m.\u001b[39mget_prediction_data\u001b[39m.\u001b[39mhead(\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[39m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m~/projects/numerblox/numerblox/preprocessing.py:56\u001b[0m, in \u001b[0;36mdisplay_processor_info.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     55\u001b[0m     tic \u001b[39m=\u001b[39m dt\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m---> 56\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     57\u001b[0m     time_taken \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(dt\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow() \u001b[39m-\u001b[39m tic)\n\u001b[1;32m     58\u001b[0m     class_name \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn [6], line 18\u001b[0m, in \u001b[0;36mStandardizer.transform\u001b[0;34m(self, dataf)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m@display_processor_info\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, dataf: NumerFrame) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NumerFrame:\n\u001b[1;32m     17\u001b[0m     cols \u001b[39m=\u001b[39m dataf\u001b[39m.\u001b[39mprediction_cols \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcols \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcols\n\u001b[0;32m---> 18\u001b[0m     dataf\u001b[39m.\u001b[39mloc[:, cols] \u001b[39m=\u001b[39m dataf\u001b[39m.\u001b[39;49mgroupby(dataf\u001b[39m.\u001b[39;49mmeta\u001b[39m.\u001b[39;49mera_col)[cols]\u001b[39m.\u001b[39;49mrank(pct\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m NumerFrame(dataf)\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:3621\u001b[0m, in \u001b[0;36mGroupBy.rank\u001b[0;34m(self, method, ascending, na_option, pct, axis)\u001b[0m\n\u001b[1;32m   3616\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_apply_general(\n\u001b[1;32m   3617\u001b[0m         f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_selected_obj, is_transform\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   3618\u001b[0m     )\n\u001b[1;32m   3619\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m-> 3621\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cython_transform(\n\u001b[1;32m   3622\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrank\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   3623\u001b[0m     numeric_only\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   3624\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   3625\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   3626\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/groupby/generic.py:1167\u001b[0m, in \u001b[0;36mDataFrameGroupBy._cython_transform\u001b[0;34m(self, how, numeric_only, axis, **kwargs)\u001b[0m\n\u001b[1;32m   1160\u001b[0m numeric_only_bool \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_numeric_only(how, numeric_only, axis)\n\u001b[1;32m   1162\u001b[0m \u001b[39m# With self.axis == 0, we have multi-block tests\u001b[39;00m\n\u001b[1;32m   1163\u001b[0m \u001b[39m#  e.g. test_rank_min_int, test_cython_transform_frame\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \u001b[39m#  test_transform_numeric_ret\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m \u001b[39m# With self.axis == 1, _get_data_to_aggregate does a transpose\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[39m#  so we always have a single block.\u001b[39;00m\n\u001b[0;32m-> 1167\u001b[0m mgr: Manager2D \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data_to_aggregate()\n\u001b[1;32m   1168\u001b[0m orig_mgr_len \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(mgr)\n\u001b[1;32m   1169\u001b[0m \u001b[39mif\u001b[39;00m numeric_only_bool:\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/groupby/generic.py:1467\u001b[0m, in \u001b[0;36mDataFrameGroupBy._get_data_to_aggregate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_data_to_aggregate\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Manager2D:\n\u001b[0;32m-> 1467\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_obj_with_exclusions\n\u001b[1;32m   1468\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1469\u001b[0m         \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39m_mgr\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:981\u001b[0m, in \u001b[0;36mGroupBy.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj:\n\u001b[1;32m    979\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[attr]\n\u001b[0;32m--> 981\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    982\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    983\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrameGroupBy' object has no attribute '_obj_with_exclusions'"
     ]
    }
   ],
   "source": [
    "std = Standardizer()\n",
    "std.transform(test_dataf).get_prediction_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.2. Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple prediction results can be ensembled in multiple ways. We provide the most common use cases here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0.2.1. Simple Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class MeanEnsembler(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Take simple mean of multiple cols and store in new col.\n",
    "\n",
    "    :param final_col_name: Name of new averaged column.\n",
    "    final_col_name should start with \"prediction\". \\n\n",
    "    :param cols: Column names to average. \\n\n",
    "    :param standardize: Whether to standardize by era before averaging. Highly recommended as columns that are averaged may have different distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, final_col_name: str, cols: list = None, standardize: bool = False\n",
    "    ):\n",
    "        self.cols = cols\n",
    "        self.standardize = standardize\n",
    "        super().__init__(final_col_name=final_col_name)\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        cols = self.cols if self.cols else dataf.prediction_cols\n",
    "        if self.standardize:\n",
    "            to_average = dataf.groupby(dataf.meta.era_col)[cols].rank(pct=True)\n",
    "        else:\n",
    "            to_average = dataf[cols]\n",
    "        dataf.loc[:, self.final_col_name] = to_average.mean(axis=1)\n",
    "        rich_print(\n",
    "            f\":stew: Ensembled [blue]'{cols}'[blue] with simple mean and saved in [bold]'{self.final_col_name}'[bold] :stew:\"\n",
    "        )\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0.2.2. Donate's formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method for weighted averaging is mostly suitable if you have multiple models trained on a time series cross validation scheme. The first models will be trained on less data so we want to give them a lower weighting compared to the later models.\n",
    "\n",
    "Source: [Yirun Zhang in his winning solution for the Jane Street 2021 Kaggle competition](https://www.kaggle.com/gogo827jz/jane-street-supervised-autoencoder-mlp).\n",
    "Based on a [paper by Donate et al.](https://doi.org/10.1016/j.neucom.2012.02.053)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class DonateWeightedEnsembler(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Weighted average as per Donate et al.'s formula\n",
    "    Paper Link: https://doi.org/10.1016/j.neucom.2012.02.053\n",
    "    Code source: https://www.kaggle.com/gogo827jz/jane-street-supervised-autoencoder-mlp\n",
    "\n",
    "    Weightings for 5 folds: [0.0625, 0.0625, 0.125, 0.25, 0.5]\n",
    "\n",
    "    :param cols: Prediction columns to ensemble.\n",
    "    Uses all prediction columns by default. \\n\n",
    "    :param final_col_name: New column name for ensembled values.\n",
    "    \"\"\"\n",
    "    def __init__(self, final_col_name: str, cols: list = None):\n",
    "        super().__init__(final_col_name=final_col_name)\n",
    "        self.cols = cols\n",
    "        self.n_cols = len(cols)\n",
    "        self.weights = self._get_weights()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        cols = self.cols if self.cols else dataf.prediction_cols\n",
    "        dataf.loc[:, self.final_col_name] = np.average(\n",
    "            dataf.loc[:, cols], weights=self.weights, axis=1\n",
    "        )\n",
    "        rich_print(\n",
    "            f\":stew: Ensembled [blue]'{cols}'[/blue] with [bold]{self.__class__.__name__}[/bold] and saved in [bold]'{self.final_col_name}'[bold] :stew:\"\n",
    "        )\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def _get_weights(self) -> list:\n",
    "        \"\"\"Exponential weights.\"\"\"\n",
    "        weights = []\n",
    "        for j in range(1, self.n_cols + 1):\n",
    "            j = 2 if j == 1 else j\n",
    "            weights.append(1 / (2 ** (self.n_cols + 1 - j)))\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random DataFrame\n",
    "#| include: false\n",
    "test_features = [f\"prediction_{l}\" for l in \"ABCDE\"]\n",
    "df = pd.DataFrame(np.random.uniform(size=(100, 5)), columns=test_features)\n",
    "df[\"target\"] = np.random.normal(size=100)\n",
    "df[\"era\"] = range(100)\n",
    "test_dataf = NumerFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 5 folds, the weightings are `[0.0625, 0.0625, 0.125, 0.25, 0.5]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍲 Ensembled <span style=\"color: #000080; text-decoration-color: #000080\">'['</span><span style=\"color: #000080; text-decoration-color: #000080\">prediction_A', </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_B'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_C'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_D'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_E'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span><span style=\"color: #000080; text-decoration-color: #000080\">'</span><span style=\"color: #008000; text-decoration-color: #008000\"> with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">DonateWeightedEnsembler</span><span style=\"color: #008000; text-decoration-color: #008000\"> and saved in </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'</span><span style=\"font-weight: bold\">prediction' 🍲</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🍲 Ensembled \u001b[34m'\u001b[0m\u001b[34m[\u001b[0m\u001b[34m'\u001b[0m\u001b[34mprediction_A', \u001b[0m\u001b[34m'prediction_B'\u001b[0m\u001b[34m, \u001b[0m\u001b[34m'prediction_C'\u001b[0m\u001b[34m, \u001b[0m\u001b[34m'prediction_D'\u001b[0m\u001b[34m, \u001b[0m\u001b[34m'prediction_E'\u001b[0m\u001b[1;34m]\u001b[0m\u001b[34m'\u001b[0m\u001b[32m with \u001b[0m\n",
       "\u001b[1;32mDonateWeightedEnsembler\u001b[0m\u001b[32m and saved in \u001b[0m\u001b[1;32m'\u001b[0m\u001b[1mprediction'\u001b[0m\u001b[1m 🍲\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">DonateWeightedEnsembler</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">009190</span>. ✅\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Finished step \u001b[1mDonateWeightedEnsembler\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \u001b[1;34m0:00:00\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m009190\u001b[0m. ✅\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_A</th>\n",
       "      <th>prediction_B</th>\n",
       "      <th>prediction_C</th>\n",
       "      <th>prediction_D</th>\n",
       "      <th>prediction_E</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.676536</td>\n",
       "      <td>0.470445</td>\n",
       "      <td>0.984205</td>\n",
       "      <td>0.796912</td>\n",
       "      <td>0.998436</td>\n",
       "      <td>0.893158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146905</td>\n",
       "      <td>0.264019</td>\n",
       "      <td>0.319603</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.807348</td>\n",
       "      <td>0.469645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction_A  prediction_B  prediction_C  prediction_D  prediction_E  \\\n",
       "0      0.676536      0.470445      0.984205      0.796912      0.998436   \n",
       "1      0.146905      0.264019      0.319603      0.001351      0.807348   \n",
       "\n",
       "   prediction  \n",
       "0    0.893158  \n",
       "1    0.469645  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_5_fold = [0.0625, 0.0625, 0.125, 0.25, 0.5]\n",
    "donate = DonateWeightedEnsembler(\n",
    "    cols=test_dataf.prediction_cols, final_col_name=\"prediction\"\n",
    ")\n",
    "ensembled = donate(test_dataf).get_prediction_data\n",
    "assert ensembled[\"prediction\"][0] == np.sum(\n",
    "    [w * elem for w, elem in zip(w_5_fold, ensembled[test_features].iloc[0])]\n",
    ")\n",
    "ensembled.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0.2.3. Geometric Mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the mean of multiple prediction columns using the product of values.\n",
    "\n",
    "**More info on Geometric mean:**\n",
    "- [Wikipedia](https://en.wikipedia.org/wiki/Geometric_mean)\n",
    "- [Investopedia](https://www.investopedia.com/terms/g/geometricmean.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class GeometricMeanEnsembler(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Calculate the weighted Geometric mean.\n",
    "\n",
    "    :param cols: Prediction columns to ensemble.\n",
    "    Uses all prediction columns by default. \\n\n",
    "    :param final_col_name: New column name for ensembled values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, final_col_name: str, cols: list = None):\n",
    "        super().__init__(final_col_name=final_col_name)\n",
    "        self.cols = cols\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        cols = self.cols if self.cols else dataf.prediction_cols\n",
    "        new_col = dataf.loc[:, cols].apply(gmean, axis=1)\n",
    "        dataf.loc[:, self.final_col_name] = new_col\n",
    "        rich_print(\n",
    "            f\":stew: Ensembled [blue]'{cols}'[/blue] with [bold]{self.__class__.__name__}[/bold] and saved in [bold]'{self.final_col_name}'[bold] :stew:\"\n",
    "        )\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍲 Ensembled <span style=\"color: #000080; text-decoration-color: #000080\">'['</span><span style=\"color: #000080; text-decoration-color: #000080\">prediction_A', </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_B'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_C'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_D'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_E'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span><span style=\"color: #000080; text-decoration-color: #000080\">'</span><span style=\"color: #008000; text-decoration-color: #008000\"> with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">GeometricMeanEnsembler</span><span style=\"color: #008000; text-decoration-color: #008000\"> and saved in </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'</span><span style=\"font-weight: bold\">prediction_geo' 🍲</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🍲 Ensembled \u001b[34m'\u001b[0m\u001b[34m[\u001b[0m\u001b[34m'\u001b[0m\u001b[34mprediction_A', \u001b[0m\u001b[34m'prediction_B'\u001b[0m\u001b[34m, \u001b[0m\u001b[34m'prediction_C'\u001b[0m\u001b[34m, \u001b[0m\u001b[34m'prediction_D'\u001b[0m\u001b[34m, \u001b[0m\u001b[34m'prediction_E'\u001b[0m\u001b[1;34m]\u001b[0m\u001b[34m'\u001b[0m\u001b[32m with \u001b[0m\n",
       "\u001b[1;32mGeometricMeanEnsembler\u001b[0m\u001b[32m and saved in \u001b[0m\u001b[1;32m'\u001b[0m\u001b[1mprediction_geo'\u001b[0m\u001b[1m 🍲\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">GeometricMeanEnsembler</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">059241</span>. ✅\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Finished step \u001b[1mGeometricMeanEnsembler\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m9\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \u001b[1;34m0:00:00\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m059241\u001b[0m. ✅\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_A</th>\n",
       "      <th>prediction_B</th>\n",
       "      <th>prediction_C</th>\n",
       "      <th>prediction_D</th>\n",
       "      <th>prediction_E</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prediction_geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.676536</td>\n",
       "      <td>0.470445</td>\n",
       "      <td>0.984205</td>\n",
       "      <td>0.796912</td>\n",
       "      <td>0.998436</td>\n",
       "      <td>0.893158</td>\n",
       "      <td>0.757396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146905</td>\n",
       "      <td>0.264019</td>\n",
       "      <td>0.319603</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.807348</td>\n",
       "      <td>0.469645</td>\n",
       "      <td>0.106222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction_A  prediction_B  prediction_C  prediction_D  prediction_E  \\\n",
       "0      0.676536      0.470445      0.984205      0.796912      0.998436   \n",
       "1      0.146905      0.264019      0.319603      0.001351      0.807348   \n",
       "\n",
       "   prediction  prediction_geo  \n",
       "0    0.893158        0.757396  \n",
       "1    0.469645        0.106222  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_mean = GeometricMeanEnsembler(final_col_name=\"prediction_geo\")\n",
    "ensembled = geo_mean(test_dataf).get_prediction_data\n",
    "ensembled.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.3. Neutralization and penalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0.3.1. Feature Neutralization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classic feature neutralization (subtracting linear model from scores).\n",
    "\n",
    "New column name for neutralized values will be `{pred_name}_neutralized_{PROPORTION}`. `pred_name` should start with `'prediction'`.\n",
    "\n",
    "Optionally, you can run feature neutralization on the GPU using [cupy](https://docs.cupy.dev/en/stable/overview.html) by setting `cuda=True`. Make sure you have `cupy` installed with the correct CUDA Toolkit version. More information: [docs.cupy.dev/en/stable/install.html](https://docs.cupy.dev/en/stable/install.html)\n",
    "\n",
    "[Detailed explanation of Feature Neutralization by Katsu1110](https://www.kaggle.com/code1110/janestreet-avoid-overfit-feature-neutralization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class FeatureNeutralizer(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Classic feature neutralization by subtracting linear model.\n",
    "\n",
    "    :param feature_names: List of column names to neutralize against. Uses all feature columns by default. \\n\n",
    "    :param pred_name: Prediction column to neutralize. \\n\n",
    "    :param proportion: Number in range [0...1] indicating how much to neutralize. \\n\n",
    "    :param suffix: Optional suffix that is added to new column name. \\n\n",
    "    :param cuda: Do neutralization on the GPU \\n\n",
    "    Make sure you have CuPy installed when setting cuda to True. \\n\n",
    "    Installation docs: docs.cupy.dev/en/stable/install.html\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_names: list = None,\n",
    "        pred_name: str = \"prediction\",\n",
    "        proportion: float = 0.5,\n",
    "        suffix: str = None,\n",
    "        cuda = False,\n",
    "    ):\n",
    "        self.pred_name = pred_name\n",
    "        self.proportion = proportion\n",
    "        assert (\n",
    "            0.0 <= proportion <= 1.0\n",
    "        ), f\"'proportion' should be a float in range [0...1]. Got '{proportion}'.\"\n",
    "        self.new_col_name = (\n",
    "            f\"{self.pred_name}_neutralized_{self.proportion}_{suffix}\"\n",
    "            if suffix\n",
    "            else f\"{self.pred_name}_neutralized_{self.proportion}\"\n",
    "        )\n",
    "        super().__init__(final_col_name=self.new_col_name)\n",
    "        self.feature_names = feature_names\n",
    "        self.cuda = cuda\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\n",
    "        neutralized_preds = dataf.groupby(dataf.meta.era_col).apply(\n",
    "            lambda x: self.normalize_and_neutralize(x, [self.pred_name], feature_names)\n",
    "        )\n",
    "        dataf.loc[:, self.new_col_name] = MinMaxScaler().fit_transform(\n",
    "            neutralized_preds\n",
    "        )\n",
    "        rich_print(\n",
    "            f\":robot: Neutralized [bold blue]'{self.pred_name}'[bold blue] with proportion [bold]'{self.proportion}'[/bold] :robot:\"\n",
    "        )\n",
    "        rich_print(\n",
    "            f\"New neutralized column = [bold green]'{self.new_col_name}'[/bold green].\"\n",
    "        )\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def neutralize(self, dataf: pd.DataFrame, columns: list, by: list) -> pd.DataFrame:\n",
    "        \"\"\" Neutralize on CPU. \"\"\"\n",
    "        scores = dataf[columns]\n",
    "        exposures = dataf[by].values\n",
    "        scores = scores - self.proportion * exposures.dot(\n",
    "            np.linalg.pinv(exposures).dot(scores)\n",
    "        )\n",
    "        return scores / scores.std()\n",
    "\n",
    "    def neutralize_cuda(self, dataf: pd.DataFrame, columns: list, by: list) -> np.ndarray:\n",
    "        \"\"\" Neutralize on GPU. \"\"\"\n",
    "        try:\n",
    "            import cupy\n",
    "        except ImportError:\n",
    "            raise ImportError(\"CuPy not installed. Set cuda=False or install CuPy. Installation docs: docs.cupy.dev/en/stable/install.html\")\n",
    "        scores = cupy.array(dataf[columns].values)\n",
    "        exposures = cupy.array(dataf[by].values)\n",
    "        scores = scores - self.proportion * exposures.dot(\n",
    "            cupy.linalg.pinv(exposures).dot(scores)\n",
    "        )\n",
    "        return cupy.asnumpy(scores / scores.std())\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(dataf: pd.DataFrame) -> np.ndarray:\n",
    "        normalized_ranks = (dataf.rank(method=\"first\") - 0.5) / len(dataf)\n",
    "        return sp.norm.ppf(normalized_ranks)\n",
    "\n",
    "    def normalize_and_neutralize(\n",
    "        self, dataf: pd.DataFrame, columns: list, by: list\n",
    "    ) -> pd.DataFrame:\n",
    "        dataf[columns] = self.normalize(dataf[columns])\n",
    "        neutralization_func = self.neutralize if not self.cuda else self.neutralize_cuda\n",
    "        dataf[columns] = neutralization_func(dataf, columns, by)\n",
    "        return dataf[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testv1_dataf = create_numerframe(\"test_assets/mini_numerai_version_1_data.csv\", metadata={\"era_col\": \"era\"})\n",
    "testv1_dataf.loc[:, \"prediction\"] = np.random.uniform(size=len(testv1_dataf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "NumerFrame must contain either an 'era', 'friday_date' or 'date' column.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/IPython/core/formatters.py:706\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    699\u001b[0m stream \u001b[39m=\u001b[39m StringIO()\n\u001b[1;32m    700\u001b[0m printer \u001b[39m=\u001b[39m pretty\u001b[39m.\u001b[39mRepresentationPrinter(stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnewline,\n\u001b[1;32m    702\u001b[0m     max_seq_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_seq_length,\n\u001b[1;32m    703\u001b[0m     singleton_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msingleton_printers,\n\u001b[1;32m    704\u001b[0m     type_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype_printers,\n\u001b[1;32m    705\u001b[0m     deferred_pprinters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 706\u001b[0m printer\u001b[39m.\u001b[39;49mpretty(obj)\n\u001b[1;32m    707\u001b[0m printer\u001b[39m.\u001b[39mflush()\n\u001b[1;32m    708\u001b[0m \u001b[39mreturn\u001b[39;00m stream\u001b[39m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/IPython/lib/pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m                         \u001b[39mreturn\u001b[39;00m meth(obj, \u001b[39mself\u001b[39m, cycle)\n\u001b[1;32m    408\u001b[0m                 \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mobject\u001b[39m \\\n\u001b[1;32m    409\u001b[0m                         \u001b[39mand\u001b[39;00m callable(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m__repr__\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m--> 410\u001b[0m                     \u001b[39mreturn\u001b[39;00m _repr_pprint(obj, \u001b[39mself\u001b[39;49m, cycle)\n\u001b[1;32m    412\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_pprint(obj, \u001b[39mself\u001b[39m, cycle)\n\u001b[1;32m    413\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/IPython/lib/pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[39m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[39m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39;49m(obj)\n\u001b[1;32m    779\u001b[0m lines \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39msplitlines()\n\u001b[1;32m    780\u001b[0m \u001b[39mwith\u001b[39;00m p\u001b[39m.\u001b[39mgroup():\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/frame.py:1062\u001b[0m, in \u001b[0;36mDataFrame.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[39mreturn\u001b[39;00m buf\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m   1061\u001b[0m repr_params \u001b[39m=\u001b[39m fmt\u001b[39m.\u001b[39mget_dataframe_repr_params()\n\u001b[0;32m-> 1062\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_string(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrepr_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/frame.py:1225\u001b[0m, in \u001b[0;36mDataFrame.to_string\u001b[0;34m(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, justify, max_rows, max_cols, show_dimensions, decimal, line_width, min_rows, max_colwidth, encoding)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m option_context\n\u001b[1;32m   1224\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mdisplay.max_colwidth\u001b[39m\u001b[39m\"\u001b[39m, max_colwidth):\n\u001b[0;32m-> 1225\u001b[0m     formatter \u001b[39m=\u001b[39m fmt\u001b[39m.\u001b[39;49mDataFrameFormatter(\n\u001b[1;32m   1226\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1227\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   1228\u001b[0m         col_space\u001b[39m=\u001b[39;49mcol_space,\n\u001b[1;32m   1229\u001b[0m         na_rep\u001b[39m=\u001b[39;49mna_rep,\n\u001b[1;32m   1230\u001b[0m         formatters\u001b[39m=\u001b[39;49mformatters,\n\u001b[1;32m   1231\u001b[0m         float_format\u001b[39m=\u001b[39;49mfloat_format,\n\u001b[1;32m   1232\u001b[0m         sparsify\u001b[39m=\u001b[39;49msparsify,\n\u001b[1;32m   1233\u001b[0m         justify\u001b[39m=\u001b[39;49mjustify,\n\u001b[1;32m   1234\u001b[0m         index_names\u001b[39m=\u001b[39;49mindex_names,\n\u001b[1;32m   1235\u001b[0m         header\u001b[39m=\u001b[39;49mheader,\n\u001b[1;32m   1236\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   1237\u001b[0m         min_rows\u001b[39m=\u001b[39;49mmin_rows,\n\u001b[1;32m   1238\u001b[0m         max_rows\u001b[39m=\u001b[39;49mmax_rows,\n\u001b[1;32m   1239\u001b[0m         max_cols\u001b[39m=\u001b[39;49mmax_cols,\n\u001b[1;32m   1240\u001b[0m         show_dimensions\u001b[39m=\u001b[39;49mshow_dimensions,\n\u001b[1;32m   1241\u001b[0m         decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[1;32m   1242\u001b[0m     )\n\u001b[1;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m fmt\u001b[39m.\u001b[39mDataFrameRenderer(formatter)\u001b[39m.\u001b[39mto_string(\n\u001b[1;32m   1244\u001b[0m         buf\u001b[39m=\u001b[39mbuf,\n\u001b[1;32m   1245\u001b[0m         encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m   1246\u001b[0m         line_width\u001b[39m=\u001b[39mline_width,\n\u001b[1;32m   1247\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/io/formats/format.py:610\u001b[0m, in \u001b[0;36mDataFrameFormatter.__init__\u001b[0;34m(self, frame, columns, col_space, header, index, na_rep, formatters, justify, float_format, sparsify, index_names, max_rows, min_rows, max_cols, show_dimensions, decimal, bold_rows, escape)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_rows_fitted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calc_max_rows_fitted()\n\u001b[1;32m    609\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtr_frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe\n\u001b[0;32m--> 610\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtruncate()\n\u001b[1;32m    611\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madj \u001b[39m=\u001b[39m get_adjustment()\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/io/formats/format.py:798\u001b[0m, in \u001b[0;36mDataFrameFormatter.truncate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[39mCheck whether the frame should be truncated. If so, slice the frame up.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_truncated_horizontally:\n\u001b[0;32m--> 798\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_truncate_horizontally()\n\u001b[1;32m    800\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_truncated_vertically:\n\u001b[1;32m    801\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncate_vertically()\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/io/formats/format.py:815\u001b[0m, in \u001b[0;36mDataFrameFormatter._truncate_horizontally\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m col_num \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    814\u001b[0m     left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtr_frame\u001b[39m.\u001b[39miloc[:, :col_num]\n\u001b[0;32m--> 815\u001b[0m     right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtr_frame\u001b[39m.\u001b[39;49miloc[:, \u001b[39m-\u001b[39;49mcol_num:]\n\u001b[1;32m    816\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtr_frame \u001b[39m=\u001b[39m concat((left, right), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    818\u001b[0m     \u001b[39m# truncate formatter\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/indexing.py:1567\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1565\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_lowerdim(tup)\n\u001b[0;32m-> 1567\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/indexing.py:924\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[1;32m    922\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m    925\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/indexing.py:1602\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1596\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[1;32m   1597\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDataFrame indexer is not allowed for .iloc\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1598\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using .loc for automatic alignment.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1599\u001b[0m     )\n\u001b[1;32m   1601\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[0;32m-> 1602\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_slice_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1604\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   1605\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/indexing.py:1638\u001b[0m, in \u001b[0;36m_iLocIndexer._get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1636\u001b[0m labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1637\u001b[0m labels\u001b[39m.\u001b[39m_validate_positional_slice(slice_obj)\n\u001b[0;32m-> 1638\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_slice(slice_obj, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/generic.py:4105\u001b[0m, in \u001b[0;36mNDFrame._slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   4103\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(slobj, \u001b[39mslice\u001b[39m), \u001b[39mtype\u001b[39m(slobj)\n\u001b[1;32m   4104\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_block_manager_axis(axis)\n\u001b[0;32m-> 4105\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mget_slice(slobj, axis\u001b[39m=\u001b[39;49maxis))\n\u001b[1;32m   4106\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n\u001b[1;32m   4108\u001b[0m \u001b[39m# this could be a view\u001b[39;00m\n\u001b[1;32m   4109\u001b[0m \u001b[39m# but only in a single-dtyped view sliceable case\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/numerblox/numerblox/numerframe.py:32\u001b[0m, in \u001b[0;36mNumerFrame.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__init_meta_attrs()\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mera_col_verified\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta:\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__set_era_col()\n",
      "File \u001b[0;32m~/projects/numerblox/numerblox/numerframe.py:59\u001b[0m, in \u001b[0;36mNumerFrame.__set_era_col\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mera_col \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNumerFrame must contain either an \u001b[39m\u001b[39m'\u001b[39m\u001b[39mera\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfriday_date\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m\u001b[39m column.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mera_col_verified \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: NumerFrame must contain either an 'era', 'friday_date' or 'date' column."
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "NumerFrame must contain either an 'era', 'friday_date' or 'date' column.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/IPython/core/formatters.py:342\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    340\u001b[0m     method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n\u001b[1;32m    341\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 342\u001b[0m         \u001b[39mreturn\u001b[39;00m method()\n\u001b[1;32m    343\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/frame.py:1084\u001b[0m, in \u001b[0;36mDataFrame._repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     max_cols \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mdisplay.max_columns\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1082\u001b[0m     show_dimensions \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mdisplay.show_dimensions\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1084\u001b[0m     formatter \u001b[39m=\u001b[39m fmt\u001b[39m.\u001b[39;49mDataFrameFormatter(\n\u001b[1;32m   1085\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1086\u001b[0m         columns\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1087\u001b[0m         col_space\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1088\u001b[0m         na_rep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mNaN\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1089\u001b[0m         formatters\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1090\u001b[0m         float_format\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1091\u001b[0m         sparsify\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1092\u001b[0m         justify\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1093\u001b[0m         index_names\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1094\u001b[0m         header\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1095\u001b[0m         index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1096\u001b[0m         bold_rows\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1097\u001b[0m         escape\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1098\u001b[0m         max_rows\u001b[39m=\u001b[39;49mmax_rows,\n\u001b[1;32m   1099\u001b[0m         min_rows\u001b[39m=\u001b[39;49mmin_rows,\n\u001b[1;32m   1100\u001b[0m         max_cols\u001b[39m=\u001b[39;49mmax_cols,\n\u001b[1;32m   1101\u001b[0m         show_dimensions\u001b[39m=\u001b[39;49mshow_dimensions,\n\u001b[1;32m   1102\u001b[0m         decimal\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1103\u001b[0m     )\n\u001b[1;32m   1104\u001b[0m     \u001b[39mreturn\u001b[39;00m fmt\u001b[39m.\u001b[39mDataFrameRenderer(formatter)\u001b[39m.\u001b[39mto_html(notebook\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1105\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/io/formats/format.py:610\u001b[0m, in \u001b[0;36mDataFrameFormatter.__init__\u001b[0;34m(self, frame, columns, col_space, header, index, na_rep, formatters, justify, float_format, sparsify, index_names, max_rows, min_rows, max_cols, show_dimensions, decimal, bold_rows, escape)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_rows_fitted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calc_max_rows_fitted()\n\u001b[1;32m    609\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtr_frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe\n\u001b[0;32m--> 610\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtruncate()\n\u001b[1;32m    611\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madj \u001b[39m=\u001b[39m get_adjustment()\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/io/formats/format.py:798\u001b[0m, in \u001b[0;36mDataFrameFormatter.truncate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[39mCheck whether the frame should be truncated. If so, slice the frame up.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_truncated_horizontally:\n\u001b[0;32m--> 798\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_truncate_horizontally()\n\u001b[1;32m    800\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_truncated_vertically:\n\u001b[1;32m    801\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncate_vertically()\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/io/formats/format.py:815\u001b[0m, in \u001b[0;36mDataFrameFormatter._truncate_horizontally\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m col_num \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    814\u001b[0m     left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtr_frame\u001b[39m.\u001b[39miloc[:, :col_num]\n\u001b[0;32m--> 815\u001b[0m     right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtr_frame\u001b[39m.\u001b[39;49miloc[:, \u001b[39m-\u001b[39;49mcol_num:]\n\u001b[1;32m    816\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtr_frame \u001b[39m=\u001b[39m concat((left, right), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    818\u001b[0m     \u001b[39m# truncate formatter\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/indexing.py:1567\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1565\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_lowerdim(tup)\n\u001b[0;32m-> 1567\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/indexing.py:924\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[1;32m    922\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 924\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m    925\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/indexing.py:1602\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1596\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[1;32m   1597\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDataFrame indexer is not allowed for .iloc\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1598\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using .loc for automatic alignment.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1599\u001b[0m     )\n\u001b[1;32m   1601\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[0;32m-> 1602\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_slice_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1604\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   1605\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/indexing.py:1638\u001b[0m, in \u001b[0;36m_iLocIndexer._get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1636\u001b[0m labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1637\u001b[0m labels\u001b[39m.\u001b[39m_validate_positional_slice(slice_obj)\n\u001b[0;32m-> 1638\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_slice(slice_obj, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/generic.py:4105\u001b[0m, in \u001b[0;36mNDFrame._slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   4103\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(slobj, \u001b[39mslice\u001b[39m), \u001b[39mtype\u001b[39m(slobj)\n\u001b[1;32m   4104\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_block_manager_axis(axis)\n\u001b[0;32m-> 4105\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_constructor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mget_slice(slobj, axis\u001b[39m=\u001b[39;49maxis))\n\u001b[1;32m   4106\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n\u001b[1;32m   4108\u001b[0m \u001b[39m# this could be a view\u001b[39;00m\n\u001b[1;32m   4109\u001b[0m \u001b[39m# but only in a single-dtyped view sliceable case\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/numerblox/numerblox/numerframe.py:32\u001b[0m, in \u001b[0;36mNumerFrame.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__init_meta_attrs()\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mera_col_verified\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta:\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__set_era_col()\n",
      "File \u001b[0;32m~/projects/numerblox/numerblox/numerframe.py:59\u001b[0m, in \u001b[0;36mNumerFrame.__set_era_col\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mera_col \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNumerFrame must contain either an \u001b[39m\u001b[39m'\u001b[39m\u001b[39mera\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfriday_date\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m\u001b[39m column.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mera_col_verified \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: NumerFrame must contain either an 'era', 'friday_date' or 'date' column."
     ]
    }
   ],
   "source": [
    "testv1_dataf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['prediction'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m ft \u001b[39m=\u001b[39m FeatureNeutralizer(\n\u001b[1;32m      2\u001b[0m     feature_names\u001b[39m=\u001b[39mtest_dataf\u001b[39m.\u001b[39mfeature_cols, pred_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m\"\u001b[39m, proportion\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0m new_dataf \u001b[39m=\u001b[39m ft\u001b[39m.\u001b[39;49mtransform(test_dataf)\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[39m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "File \u001b[0;32m~/projects/numerblox/numerblox/preprocessing.py:56\u001b[0m, in \u001b[0;36mdisplay_processor_info.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     55\u001b[0m     tic \u001b[39m=\u001b[39m dt\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m---> 56\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     57\u001b[0m     time_taken \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(dt\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow() \u001b[39m-\u001b[39m tic)\n\u001b[1;32m     58\u001b[0m     class_name \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn [10], line 40\u001b[0m, in \u001b[0;36mFeatureNeutralizer.transform\u001b[0;34m(self, dataf)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39m@display_processor_info\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, dataf: NumerFrame) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NumerFrame:\n\u001b[1;32m     39\u001b[0m     feature_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names \u001b[39melse\u001b[39;00m dataf\u001b[39m.\u001b[39mfeature_cols\n\u001b[0;32m---> 40\u001b[0m     neutralized_preds \u001b[39m=\u001b[39m dataf\u001b[39m.\u001b[39;49mgroupby(dataf\u001b[39m.\u001b[39;49mmeta\u001b[39m.\u001b[39;49mera_col)\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m     41\u001b[0m         \u001b[39mlambda\u001b[39;49;00m x: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize_and_neutralize(x, [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpred_name], feature_names)\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m     dataf\u001b[39m.\u001b[39mloc[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_col_name] \u001b[39m=\u001b[39m MinMaxScaler()\u001b[39m.\u001b[39mfit_transform(\n\u001b[1;32m     44\u001b[0m         neutralized_preds\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m     rich_print(\n\u001b[1;32m     47\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m:robot: Neutralized [bold blue]\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m[bold blue] with proportion [bold]\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproportion\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m[/bold] :robot:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1558\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1557\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1558\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_apply_general(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selected_obj)\n\u001b[1;32m   1559\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m         \u001b[39m# gh-20949\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m         \u001b[39m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1565\u001b[0m         \u001b[39m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m         \u001b[39m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1568\u001b[0m         \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group_selection_context():\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1610\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1574\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_apply_general\u001b[39m(\n\u001b[1;32m   1575\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1580\u001b[0m     is_agg: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1581\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[1;32m   1582\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1583\u001b[0m \u001b[39m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1608\u001b[0m \u001b[39m        data after applying f\u001b[39;00m\n\u001b[1;32m   1609\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1610\u001b[0m     values, mutated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49mapply(f, data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis)\n\u001b[1;32m   1611\u001b[0m     \u001b[39mif\u001b[39;00m not_indexed_same \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1612\u001b[0m         not_indexed_same \u001b[39m=\u001b[39m mutated \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmutated\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/groupby/ops.py:839\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39m# group might be modified\u001b[39;00m\n\u001b[1;32m    838\u001b[0m group_axes \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39maxes\n\u001b[0;32m--> 839\u001b[0m res \u001b[39m=\u001b[39m f(group)\n\u001b[1;32m    840\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mutated \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    841\u001b[0m     mutated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [10], line 41\u001b[0m, in \u001b[0;36mFeatureNeutralizer.transform.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39m@display_processor_info\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, dataf: NumerFrame) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NumerFrame:\n\u001b[1;32m     39\u001b[0m     feature_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names \u001b[39melse\u001b[39;00m dataf\u001b[39m.\u001b[39mfeature_cols\n\u001b[1;32m     40\u001b[0m     neutralized_preds \u001b[39m=\u001b[39m dataf\u001b[39m.\u001b[39mgroupby(dataf\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mera_col)\u001b[39m.\u001b[39mapply(\n\u001b[0;32m---> 41\u001b[0m         \u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize_and_neutralize(x, [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpred_name], feature_names)\n\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m     dataf\u001b[39m.\u001b[39mloc[:, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_col_name] \u001b[39m=\u001b[39m MinMaxScaler()\u001b[39m.\u001b[39mfit_transform(\n\u001b[1;32m     44\u001b[0m         neutralized_preds\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m     rich_print(\n\u001b[1;32m     47\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m:robot: Neutralized [bold blue]\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpred_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m[bold blue] with proportion [bold]\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproportion\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m[/bold] :robot:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/typeguard/__init__.py:1033\u001b[0m, in \u001b[0;36mtypechecked.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m memo \u001b[39m=\u001b[39m _CallMemo(python_func, _localns, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m   1032\u001b[0m check_argument_types(memo)\n\u001b[0;32m-> 1033\u001b[0m retval \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1035\u001b[0m     check_return_type(retval, memo)\n",
      "Cell \u001b[0;32mIn [10], line 84\u001b[0m, in \u001b[0;36mFeatureNeutralizer.normalize_and_neutralize\u001b[0;34m(self, dataf, columns, by)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalize_and_neutralize\u001b[39m(\n\u001b[1;32m     82\u001b[0m     \u001b[39mself\u001b[39m, dataf: pd\u001b[39m.\u001b[39mDataFrame, columns: \u001b[39mlist\u001b[39m, by: \u001b[39mlist\u001b[39m\n\u001b[1;32m     83\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[0;32m---> 84\u001b[0m     dataf[columns] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize(dataf[columns])\n\u001b[1;32m     85\u001b[0m     neutralization_func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneutralize \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcuda \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneutralize_cuda\n\u001b[1;32m     86\u001b[0m     dataf[columns] \u001b[39m=\u001b[39m neutralization_func(dataf, columns, by)\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/frame.py:3810\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3808\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3809\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3810\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3812\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/indexes/base.py:6111\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6109\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6111\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6113\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6115\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/numerblox/lib/python3.9/site-packages/pandas/core/indexes/base.py:6171\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6169\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6170\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 6171\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6173\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   6174\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['prediction'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "ft = FeatureNeutralizer(\n",
    "    feature_names=test_dataf.feature_cols, pred_name=\"prediction\", proportion=0.8\n",
    ")\n",
    "new_dataf = ft.transform(test_dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"prediction_neutralized_0.8\" in new_dataf.prediction_cols\n",
    "assert 0.0 in new_dataf.get_prediction_data[\"prediction_neutralized_0.8\"]\n",
    "assert 1.0 in new_dataf.get_prediction_data[\"prediction_neutralized_0.8\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated columns and data can be easily retrieved for the `NumerFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataf.prediction_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataf.get_prediction_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| cuda_test\n",
    "# ft = FeatureNeutralizer(\n",
    "#     feature_names=test_dataf.feature_cols, pred_name=\"prediction\",\n",
    "#     proportion=0.8, cuda=True\n",
    "# )\n",
    "# new_dataf_cuda = ft.transform(test_dataf)\n",
    "# new_dataf_cuda.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0.3.2. Feature Penalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class FeaturePenalizer(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Feature penalization with TensorFlow.\n",
    "\n",
    "    Source (by jrb): https://github.com/jonrtaylor/twitch/blob/master/FE_Clipping_Script.ipynb\n",
    "\n",
    "    Source of first PyTorch implementation (by Michael Oliver / mdo): https://forum.numer.ai/t/model-diagnostics-feature-exposure/899/12\n",
    "\n",
    "    :param feature_names: List of column names to reduce feature exposure. Uses all feature columns by default. \\n\n",
    "    :param pred_name: Prediction column to neutralize. \\n\n",
    "    :param max_exposure: Number in range [0...1] indicating how much to reduce max feature exposure to.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_exposure: float,\n",
    "        feature_names: list = None,\n",
    "        pred_name: str = \"prediction\",\n",
    "        suffix: str = None,\n",
    "    ):\n",
    "        self.pred_name = pred_name\n",
    "        self.max_exposure = max_exposure\n",
    "        assert (\n",
    "            0.0 <= max_exposure <= 1.0\n",
    "        ), f\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\"\n",
    "        self.new_col_name = (\n",
    "            f\"{self.pred_name}_penalized_{self.max_exposure}_{suffix}\"\n",
    "            if suffix\n",
    "            else f\"{self.pred_name}_penalized_{self.max_exposure}\"\n",
    "        )\n",
    "        super().__init__(final_col_name=self.new_col_name)\n",
    "\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        feature_names = (\n",
    "            dataf.feature_cols if not self.feature_names else self.feature_names\n",
    "        )\n",
    "        penalized_data = self.reduce_all_exposures(\n",
    "            dataf=dataf, column=self.pred_name, neutralizers=feature_names\n",
    "        )\n",
    "        dataf.loc[:, self.new_col_name] = penalized_data[self.pred_name]\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def reduce_all_exposures(\n",
    "        self,\n",
    "        dataf: NumerFrame,\n",
    "        column: str = \"prediction\",\n",
    "        neutralizers: list = None,\n",
    "        normalize=True,\n",
    "        gaussianize=True,\n",
    "    ) -> pd.DataFrame:\n",
    "        if neutralizers is None:\n",
    "            neutralizers = [x for x in dataf.columns if x.startswith(\"feature\")]\n",
    "        neutralized = []\n",
    "\n",
    "        for era in tqdm(dataf[dataf.meta.era_col].unique()):\n",
    "            dataf_era = dataf[dataf[dataf.meta.era_col] == era]\n",
    "            scores = dataf_era[[column]].values\n",
    "            exposure_values = dataf_era[neutralizers].values\n",
    "\n",
    "            if normalize:\n",
    "                scores2 = []\n",
    "                for x in scores.T:\n",
    "                    x = (scipy.stats.rankdata(x, method=\"ordinal\") - 0.5) / len(x)\n",
    "                    if gaussianize:\n",
    "                        x = scipy.stats.norm.ppf(x)\n",
    "                    scores2.append(x)\n",
    "                scores = np.array(scores2)[0]\n",
    "\n",
    "            scores, weights = self._reduce_exposure(\n",
    "                scores, exposure_values, len(neutralizers), None\n",
    "            )\n",
    "\n",
    "            scores /= tf.math.reduce_std(scores)\n",
    "            scores -= tf.reduce_min(scores)\n",
    "            scores /= tf.reduce_max(scores)\n",
    "            neutralized.append(scores.numpy())\n",
    "\n",
    "        predictions = pd.DataFrame(\n",
    "            np.concatenate(neutralized), columns=[column], index=dataf.index\n",
    "        )\n",
    "        return predictions\n",
    "\n",
    "    def _reduce_exposure(self, prediction, features, input_size=50, weights=None):\n",
    "        model = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Input(input_size),\n",
    "                tf.keras.experimental.LinearModel(use_bias=False),\n",
    "            ]\n",
    "        )\n",
    "        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\n",
    "        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\n",
    "        if weights is None:\n",
    "            optimizer = tf.keras.optimizers.Adamax()\n",
    "            start_exp = self.__exposures(feats, pred[:, None])\n",
    "            target_exps = tf.clip_by_value(\n",
    "                start_exp, -self.max_exposure, self.max_exposure\n",
    "            )\n",
    "            self._train_loop(model, optimizer, feats, pred, target_exps)\n",
    "        else:\n",
    "            model.set_weights(weights)\n",
    "        return pred[:, None] - model(feats), model.get_weights()\n",
    "\n",
    "    def _train_loop(self, model, optimizer, feats, pred, target_exps):\n",
    "        for i in range(1000000):\n",
    "            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            if loss < 1e-7:\n",
    "                break\n",
    "\n",
    "    @tf.function(experimental_relax_shapes=True)\n",
    "    def __train_loop_body(self, model, feats, pred, target_exps):\n",
    "        with tf.GradientTape() as tape:\n",
    "            exps = self.__exposures(feats, pred[:, None] - model(feats, training=True))\n",
    "            loss = tf.reduce_sum(\n",
    "                tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps))\n",
    "                + tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps))\n",
    "            )\n",
    "        return loss, tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    @staticmethod\n",
    "    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\n",
    "    def __exposures(x, y):\n",
    "        x = x - tf.math.reduce_mean(x, axis=0)\n",
    "        x = x / tf.norm(x, axis=0)\n",
    "        y = y - tf.math.reduce_mean(y, axis=0)\n",
    "        y = y / tf.norm(y, axis=0)\n",
    "        return tf.matmul(x, y, transpose_a=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "#| cuda_test\n",
    "test_dataf = create_numerframe(\"test_assets/mini_numerai_version_1_data.csv\")\n",
    "test_dataf.loc[:, \"prediction\"] = np.random.uniform(size=len(test_dataf))\n",
    "# ft = FeaturePenalizer(pred_name='prediction', max_exposure=0.8)\n",
    "# new_dataset = ft.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Numerai Classic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postprocessing steps that are specific to Numerai Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1.\n",
    "# No Numerai Classic specific postprocessors implemented yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Numerai Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postprocessors that are specific to Numerai Signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2.\n",
    "# No Numerai Signals specific postprocessors implemented yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom PostProcessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with preprocessors, there are an almost unlimited number of ways to postprocess data. We (once again) invite the Numerai community to develop Numerai Classic and Signals postprocessors.\n",
    "\n",
    "A new Postprocessor should inherit from `BasePostProcessor` and implement a `transform` method. The `transform` method should take a `NumerFrame` as input and return a `NumerFrame` object as output. A template for this is given below.\n",
    "\n",
    "We recommend adding `@typechecked` at the top of a new postprocessor to enforce types and provide useful debugging stacktraces.\n",
    "\n",
    "To enable fancy logging output. Add the `@display_processor_info` decorator to the `transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class AwesomePostProcessor(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    TEMPLATE - Do some awesome postprocessing.\n",
    "\n",
    "    :param final_col_name: Column name to store manipulated or ensembled predictions in.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, final_col_name: str, *args, **kwargs):\n",
    "        super().__init__(final_col_name=final_col_name)\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        # Do processing\n",
    "        ...\n",
    "        # Add new column(s) for manipulated data\n",
    "        dataf.loc[:, self.final_col_name] = ...\n",
    "        ...\n",
    "        # Parse all contents to the next pipeline step\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
