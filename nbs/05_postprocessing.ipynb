{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference between a postprocessing step and a preprocessing step is that preprocessing works on `feature_` columns while postprocessing manipulates `prediction_` columns.\n",
    "\n",
    "Therefore, we also inherit from `BaseProcessor` for postprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sp\n",
    "from rich import print as rich_print\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from numerai_blocks.preprocessing import BaseProcessor, display_processor_info\n",
    "from numerai_blocks.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MeanEnsembler(BaseProcessor):\n",
    "    def __init__(self):\n",
    "        super(MeanEnsembler, self).__init__()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataset: Dataset, cols: list, final_col: str, *args, **kwargs) -> Dataset:\n",
    "        assert final_col.startswith(\"prediction\"), f\"final_col name should start with 'prediction'. Got {final_col}\"\n",
    "        dataset.dataf.loc[:, [cols]][final_col] = dataset.dataf.loc[:, cols].mean(axis=1)\n",
    "        rich_print(f\":stew: Ensembled '{cols}' with simple mean and saved in '{final_col}' :stew:\")\n",
    "        return Dataset(**dataset.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Neutralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FeatureNeutralizer(BaseProcessor):\n",
    "    def __init__(self, proportion=0.5):\n",
    "        super(FeatureNeutralizer, self).__init__()\n",
    "        self.proportion = proportion\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataset: Dataset, feature_names: list, pred_name: str = \"prediction\"):\n",
    "        new_col_name = f\"{pred_name}_neutralized_{self.proportion}\"\n",
    "        neutralized_preds = dataset.dataf.groupby(\"era\").apply(lambda x: self.normalize_and_neutralize(x, [pred_name], feature_names))\n",
    "        min_max_scaled_preds = MinMaxScaler().fit_transform(neutralized_preds)\n",
    "        dataset.dataf.loc[:, new_col_name] = min_max_scaled_preds\n",
    "        rich_print(f\":robot: Neutralized [bold]'{pred_name}'[bold] with proportion [bold]'{self.proportion}'[/bold] :robot:\")\n",
    "        rich_print(f\"New neutralized column is named: [bold green]'{new_col_name}'[/bold green]\")\n",
    "        return Dataset(**dataset.__dict__)\n",
    "\n",
    "    def _neutralize(self, scores, exposures):\n",
    "        neutral_scores = scores - self.proportion * exposures.dot(np.linalg.pinv(exposures).dot(scores))\n",
    "        return neutral_scores / scores.std()\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalize(dataf: pd.DataFrame):\n",
    "        normalized_ranks = (dataf.rank(method=\"first\") - 0.5) / len(dataf)\n",
    "        return sp.norm.ppf(normalized_ranks)\n",
    "\n",
    "    def normalize_and_neutralize(self, dataf: pd.DataFrame, pred_cols, by):\n",
    "        # Convert the scores to a normal distribution\n",
    "        preds, by_matrix = dataf[pred_cols], dataf[by].values\n",
    "        preds = self._normalize(preds)\n",
    "        preds = self._neutralize(preds, by_matrix)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AwesomePostProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    - TEMPLATE -\n",
    "    Do some awesome postprocessing.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AwesomePostProcessor, self).__init__()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n",
    "        # Do processing\n",
    "        ...\n",
    "        # Add new column for manipulated data (optional)\n",
    "        new_column_name = \"NEW_COLUMN_NAME\"\n",
    "        dataset.dataf.loc[:, f\"prediction_{new_column_name}\"] = ...\n",
    "        return Dataset(**dataset.__dict__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
