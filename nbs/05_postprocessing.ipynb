{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Prediction manipulation.\n",
    "output-file: postprocessing.html\n",
    "title: Postprocessing\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"# hide\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_formatted_code = \"# hide\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"# default_exp postprocessing\";\n                var nbb_formatted_code = \"# default_exp postprocessing\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| default_exp postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The postprocessing procedure is similar to preprocessing. Preprocessors manipulate and/or add `feature` columns, while postprocessors manipulate and/or add `prediction` columns.\n",
    "\n",
    "Every postprocessor should inherit from `BasePostProcessor`. A postprocessor should take a `NumerFrame` as input and output a `NumerFrame`. One or more new prediction column(s) with prefix `prediction` are added or manipulated in a postprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_formatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"# export\\nimport scipy\\nimport numpy as np\\nimport pandas as pd\\nimport tensorflow as tf\\nimport scipy.stats as sp\\nfrom tqdm.auto import tqdm\\nfrom typeguard import typechecked\\nfrom rich import print as rich_print\\nfrom scipy.stats.mstats import gmean\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\nfrom numerblox.numerframe import NumerFrame, create_numerframe\\nfrom numerblox.preprocessing import BaseProcessor, display_processor_info\";\n                var nbb_formatted_code = \"# export\\nimport scipy\\nimport numpy as np\\nimport pandas as pd\\nimport tensorflow as tf\\nimport scipy.stats as sp\\nfrom tqdm.auto import tqdm\\nfrom typeguard import typechecked\\nfrom rich import print as rich_print\\nfrom scipy.stats.mstats import gmean\\nfrom sklearn.preprocessing import MinMaxScaler\\n\\nfrom numerblox.numerframe import NumerFrame, create_numerframe\\nfrom numerblox.preprocessing import BaseProcessor, display_processor_info\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import scipy.stats as sp\n",
    "from tqdm.auto import tqdm\n",
    "from typeguard import typechecked\n",
    "from rich import print as rich_print\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from numerblox.numerframe import NumerFrame, create_numerframe\n",
    "from numerblox.preprocessing import BaseProcessor, display_processor_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. BasePostProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some characteristics are particular to Postprocessors, but not suitable to put in the `Processor` base class.\n",
    "This functionality is implemented in `BasePostProcessor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"# export\\nclass BasePostProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Base class for postprocessing objects.\\n\\n    Postprocessors manipulate or introduce new prediction columns in a NumerFrame.\\n    \\\"\\\"\\\"\\n    def __init__(self, final_col_name: str):\\n        super().__init__()\\n        self.final_col_name = final_col_name\\n        if not final_col_name.startswith(\\\"prediction\\\"):\\n            rich_print(f\\\":warning: WARNING: final_col_name should start with 'prediction'. Column output will be: '{final_col_name}'. :warning:\\\")\\n\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        ...\";\n                var nbb_formatted_code = \"# export\\nclass BasePostProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Base class for postprocessing objects.\\n\\n    Postprocessors manipulate or introduce new prediction columns in a NumerFrame.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, final_col_name: str):\\n        super().__init__()\\n        self.final_col_name = final_col_name\\n        if not final_col_name.startswith(\\\"prediction\\\"):\\n            rich_print(\\n                f\\\":warning: WARNING: final_col_name should start with 'prediction'. Column output will be: '{final_col_name}'. :warning:\\\"\\n            )\\n\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        ...\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "class BasePostProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Base class for postprocessing objects.\n",
    "\n",
    "    Postprocessors manipulate or introduce new prediction columns in a NumerFrame.\n",
    "    \"\"\"\n",
    "    def __init__(self, final_col_name: str):\n",
    "        super().__init__()\n",
    "        self.final_col_name = final_col_name\n",
    "        if not final_col_name.startswith(\"prediction\"):\n",
    "            rich_print(f\":warning: WARNING: final_col_name should start with 'prediction'. Column output will be: '{final_col_name}'. :warning:\")\n",
    "\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Common postprocessing steps\n",
    "\n",
    "We invite the Numerai community to develop new postprocessors so that everyone can benefit from new insights and research.\n",
    "This section implements commonly used postprocessing for Numerai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0. Tournament agnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postprocessing that works for both Numerai Classic and Numerai Signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.1. Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing is an essential step in order to reliably combine Numerai predictions. It is a default postprocessor for `ModelPipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass Standardizer(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Uniform standardization of prediction columns.\\n    All values should only contain values in the range [0...1].\\n\\n    :param cols: All prediction columns that should be standardized. Use all prediction columns by default.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, cols: list = None):\\n        super().__init__(final_col_name=\\\"prediction\\\")\\n        self.cols = cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        cols = dataf.prediction_cols if not self.cols else self.cols\\n        dataf.loc[:, cols] = dataf.groupby(dataf.meta.era_col)[cols].rank(pct=True)\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass Standardizer(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Uniform standardization of prediction columns.\\n    All values should only contain values in the range [0...1].\\n\\n    :param cols: All prediction columns that should be standardized. Use all prediction columns by default.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, cols: list = None):\\n        super().__init__(final_col_name=\\\"prediction\\\")\\n        self.cols = cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        cols = dataf.prediction_cols if not self.cols else self.cols\\n        dataf.loc[:, cols] = dataf.groupby(dataf.meta.era_col)[cols].rank(pct=True)\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class Standardizer(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Uniform standardization of prediction columns.\n",
    "    All values should only contain values in the range [0...1].\n",
    "\n",
    "    :param cols: All prediction columns that should be standardized. Use all prediction columns by default.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cols: list = None):\n",
    "        super().__init__(final_col_name=\"prediction\")\n",
    "        self.cols = cols\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        cols = dataf.prediction_cols if not self.cols else self.cols\n",
    "        dataf.loc[:, cols] = dataf.groupby(dataf.meta.era_col)[cols].rank(pct=True)\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"# Random DataFrame\\ntest_features = [f\\\"prediction_{l}\\\" for l in \\\"ABCDE\\\"]\\ndf = pd.DataFrame(np.random.uniform(size=(100, 5)), columns=test_features)\\ndf[\\\"target\\\"] = np.random.normal(size=100)\\ndf[\\\"era\\\"] = [0, 1, 2, 3] * 25\\ntest_dataf = NumerFrame(df)\";\n                var nbb_formatted_code = \"# Random DataFrame\\ntest_features = [f\\\"prediction_{l}\\\" for l in \\\"ABCDE\\\"]\\ndf = pd.DataFrame(np.random.uniform(size=(100, 5)), columns=test_features)\\ndf[\\\"target\\\"] = np.random.normal(size=100)\\ndf[\\\"era\\\"] = [0, 1, 2, 3] * 25\\ntest_dataf = NumerFrame(df)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random DataFrame\n",
    "test_features = [f\"prediction_{l}\" for l in \"ABCDE\"]\n",
    "df = pd.DataFrame(np.random.uniform(size=(100, 5)), columns=test_features)\n",
    "df[\"target\"] = np.random.normal(size=100)\n",
    "df[\"era\"] = [0, 1, 2, 3] * 25\n",
    "test_dataf = NumerFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">Standardizer</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">012889</span>. ✅\n</pre>\n",
      "text/plain": "✅ Finished step \u001b[1mStandardizer\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m7\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \u001b[1;34m0:00:00\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m012889\u001b[0m. ✅\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_A</th>\n      <th>prediction_B</th>\n      <th>prediction_C</th>\n      <th>prediction_D</th>\n      <th>prediction_E</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.32</td>\n      <td>0.20</td>\n      <td>0.08</td>\n      <td>0.68</td>\n      <td>0.40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.16</td>\n      <td>0.88</td>\n      <td>0.20</td>\n      <td>0.08</td>\n      <td>0.88</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   prediction_A  prediction_B  prediction_C  prediction_D  prediction_E\n0          0.32          0.20          0.08          0.68          0.40\n1          0.16          0.88          0.20          0.08          0.88"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"std = Standardizer()\\nstd.transform(test_dataf).get_prediction_data.head(2)\";\n                var nbb_formatted_code = \"std = Standardizer()\\nstd.transform(test_dataf).get_prediction_data.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "std = Standardizer()\n",
    "std.transform(test_dataf).get_prediction_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.2. Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple prediction results can be ensembled in multiple ways. We provide the most common use cases here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0.2.1. Simple Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass MeanEnsembler(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Take simple mean of multiple cols and store in new col.\\n\\n    :param final_col_name: Name of new averaged column.\\n    final_col_name should start with \\\"prediction\\\". \\\\n\\n    :param cols: Column names to average. \\\\n\\n    :param standardize: Whether to standardize by era before averaging. Highly recommended as columns that are averaged may have different distributions.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self, final_col_name: str, cols: list = None, standardize: bool = False\\n    ):\\n        self.cols = cols\\n        self.standardize = standardize\\n        super().__init__(final_col_name=final_col_name)\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        cols = self.cols if self.cols else dataf.prediction_cols\\n        if self.standardize:\\n            to_average = dataf.groupby(dataf.meta.era_col)[cols].rank(pct=True)\\n        else:\\n            to_average = dataf[cols]\\n        dataf.loc[:, self.final_col_name] = to_average.mean(axis=1)\\n        rich_print(\\n            f\\\":stew: Ensembled [blue]'{cols}'[blue] with simple mean and saved in [bold]'{self.final_col_name}'[bold] :stew:\\\"\\n        )\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass MeanEnsembler(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Take simple mean of multiple cols and store in new col.\\n\\n    :param final_col_name: Name of new averaged column.\\n    final_col_name should start with \\\"prediction\\\". \\\\n\\n    :param cols: Column names to average. \\\\n\\n    :param standardize: Whether to standardize by era before averaging. Highly recommended as columns that are averaged may have different distributions.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self, final_col_name: str, cols: list = None, standardize: bool = False\\n    ):\\n        self.cols = cols\\n        self.standardize = standardize\\n        super().__init__(final_col_name=final_col_name)\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        cols = self.cols if self.cols else dataf.prediction_cols\\n        if self.standardize:\\n            to_average = dataf.groupby(dataf.meta.era_col)[cols].rank(pct=True)\\n        else:\\n            to_average = dataf[cols]\\n        dataf.loc[:, self.final_col_name] = to_average.mean(axis=1)\\n        rich_print(\\n            f\\\":stew: Ensembled [blue]'{cols}'[blue] with simple mean and saved in [bold]'{self.final_col_name}'[bold] :stew:\\\"\\n        )\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class MeanEnsembler(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Take simple mean of multiple cols and store in new col.\n",
    "\n",
    "    :param final_col_name: Name of new averaged column.\n",
    "    final_col_name should start with \"prediction\". \\n\n",
    "    :param cols: Column names to average. \\n\n",
    "    :param standardize: Whether to standardize by era before averaging. Highly recommended as columns that are averaged may have different distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, final_col_name: str, cols: list = None, standardize: bool = False\n",
    "    ):\n",
    "        self.cols = cols\n",
    "        self.standardize = standardize\n",
    "        super().__init__(final_col_name=final_col_name)\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        cols = self.cols if self.cols else dataf.prediction_cols\n",
    "        if self.standardize:\n",
    "            to_average = dataf.groupby(dataf.meta.era_col)[cols].rank(pct=True)\n",
    "        else:\n",
    "            to_average = dataf[cols]\n",
    "        dataf.loc[:, self.final_col_name] = to_average.mean(axis=1)\n",
    "        rich_print(\n",
    "            f\":stew: Ensembled [blue]'{cols}'[blue] with simple mean and saved in [bold]'{self.final_col_name}'[bold] :stew:\"\n",
    "        )\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0.2.2. Donate's formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method for weighted averaging is mostly suitable if you have multiple models trained on a time series cross validation scheme. The first models will be trained on less data so we want to give them a lower weighting compared to the later models.\n",
    "\n",
    "Source: [Yirun Zhang in his winning solution for the Jane Street 2021 Kaggle competition](https://www.kaggle.com/gogo827jz/jane-street-supervised-autoencoder-mlp).\n",
    "Based on a [paper by Donate et al.](https://doi.org/10.1016/j.neucom.2012.02.053)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass DonateWeightedEnsembler(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Weighted average as per Donate et al.'s formula\\n    Paper Link: https://doi.org/10.1016/j.neucom.2012.02.053\\n    Code source: https://www.kaggle.com/gogo827jz/jane-street-supervised-autoencoder-mlp\\n\\n    Weightings for 5 folds: [0.0625, 0.0625, 0.125, 0.25, 0.5]\\n\\n    :param cols: Prediction columns to ensemble.\\n    Uses all prediction columns by default. \\\\n\\n    :param final_col_name: New column name for ensembled values.\\n    \\\"\\\"\\\"\\n    def __init__(self, final_col_name: str, cols: list = None):\\n        super().__init__(final_col_name=final_col_name)\\n        self.cols = cols\\n        self.n_cols = len(cols)\\n        self.weights = self._get_weights()\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        cols = self.cols if self.cols else dataf.prediction_cols\\n        dataf.loc[:, self.final_col_name] = np.average(\\n            dataf.loc[:, cols], weights=self.weights, axis=1\\n        )\\n        rich_print(\\n            f\\\":stew: Ensembled [blue]'{cols}'[/blue] with [bold]{self.__class__.__name__}[/bold] and saved in [bold]'{self.final_col_name}'[bold] :stew:\\\"\\n        )\\n        return NumerFrame(dataf)\\n\\n    def _get_weights(self) -> list:\\n        \\\"\\\"\\\"Exponential weights.\\\"\\\"\\\"\\n        weights = []\\n        for j in range(1, self.n_cols + 1):\\n            j = 2 if j == 1 else j\\n            weights.append(1 / (2 ** (self.n_cols + 1 - j)))\\n        return weights\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass DonateWeightedEnsembler(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Weighted average as per Donate et al.'s formula\\n    Paper Link: https://doi.org/10.1016/j.neucom.2012.02.053\\n    Code source: https://www.kaggle.com/gogo827jz/jane-street-supervised-autoencoder-mlp\\n\\n    Weightings for 5 folds: [0.0625, 0.0625, 0.125, 0.25, 0.5]\\n\\n    :param cols: Prediction columns to ensemble.\\n    Uses all prediction columns by default. \\\\n\\n    :param final_col_name: New column name for ensembled values.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, final_col_name: str, cols: list = None):\\n        super().__init__(final_col_name=final_col_name)\\n        self.cols = cols\\n        self.n_cols = len(cols)\\n        self.weights = self._get_weights()\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        cols = self.cols if self.cols else dataf.prediction_cols\\n        dataf.loc[:, self.final_col_name] = np.average(\\n            dataf.loc[:, cols], weights=self.weights, axis=1\\n        )\\n        rich_print(\\n            f\\\":stew: Ensembled [blue]'{cols}'[/blue] with [bold]{self.__class__.__name__}[/bold] and saved in [bold]'{self.final_col_name}'[bold] :stew:\\\"\\n        )\\n        return NumerFrame(dataf)\\n\\n    def _get_weights(self) -> list:\\n        \\\"\\\"\\\"Exponential weights.\\\"\\\"\\\"\\n        weights = []\\n        for j in range(1, self.n_cols + 1):\\n            j = 2 if j == 1 else j\\n            weights.append(1 / (2 ** (self.n_cols + 1 - j)))\\n        return weights\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class DonateWeightedEnsembler(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Weighted average as per Donate et al.'s formula\n",
    "    Paper Link: https://doi.org/10.1016/j.neucom.2012.02.053\n",
    "    Code source: https://www.kaggle.com/gogo827jz/jane-street-supervised-autoencoder-mlp\n",
    "\n",
    "    Weightings for 5 folds: [0.0625, 0.0625, 0.125, 0.25, 0.5]\n",
    "\n",
    "    :param cols: Prediction columns to ensemble.\n",
    "    Uses all prediction columns by default. \\n\n",
    "    :param final_col_name: New column name for ensembled values.\n",
    "    \"\"\"\n",
    "    def __init__(self, final_col_name: str, cols: list = None):\n",
    "        super().__init__(final_col_name=final_col_name)\n",
    "        self.cols = cols\n",
    "        self.n_cols = len(cols)\n",
    "        self.weights = self._get_weights()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        cols = self.cols if self.cols else dataf.prediction_cols\n",
    "        dataf.loc[:, self.final_col_name] = np.average(\n",
    "            dataf.loc[:, cols], weights=self.weights, axis=1\n",
    "        )\n",
    "        rich_print(\n",
    "            f\":stew: Ensembled [blue]'{cols}'[/blue] with [bold]{self.__class__.__name__}[/bold] and saved in [bold]'{self.final_col_name}'[bold] :stew:\"\n",
    "        )\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def _get_weights(self) -> list:\n",
    "        \"\"\"Exponential weights.\"\"\"\n",
    "        weights = []\n",
    "        for j in range(1, self.n_cols + 1):\n",
    "            j = 2 if j == 1 else j\n",
    "            weights.append(1 / (2 ** (self.n_cols + 1 - j)))\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"# Random DataFrame\\n# hide\\ntest_features = [f\\\"prediction_{l}\\\" for l in \\\"ABCDE\\\"]\\ndf = pd.DataFrame(np.random.uniform(size=(100, 5)), columns=test_features)\\ndf[\\\"target\\\"] = np.random.normal(size=100)\\ndf[\\\"era\\\"] = range(100)\\ntest_dataf = NumerFrame(df)\";\n                var nbb_formatted_code = \"# Random DataFrame\\n# hide\\ntest_features = [f\\\"prediction_{l}\\\" for l in \\\"ABCDE\\\"]\\ndf = pd.DataFrame(np.random.uniform(size=(100, 5)), columns=test_features)\\ndf[\\\"target\\\"] = np.random.normal(size=100)\\ndf[\\\"era\\\"] = range(100)\\ntest_dataf = NumerFrame(df)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random DataFrame\n",
    "#| include: false\n",
    "test_features = [f\"prediction_{l}\" for l in \"ABCDE\"]\n",
    "df = pd.DataFrame(np.random.uniform(size=(100, 5)), columns=test_features)\n",
    "df[\"target\"] = np.random.normal(size=100)\n",
    "df[\"era\"] = range(100)\n",
    "test_dataf = NumerFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 5 folds, the weightings are `[0.0625, 0.0625, 0.125, 0.25, 0.5]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍲 Ensembled <span style=\"color: #000080; text-decoration-color: #000080\">'['</span><span style=\"color: #000080; text-decoration-color: #000080\">prediction_A', </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_B'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_C'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_D'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span>\n<span style=\"color: #000080; text-decoration-color: #000080\">'prediction_E'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span><span style=\"color: #000080; text-decoration-color: #000080\">'</span><span style=\"color: #008000; text-decoration-color: #008000\"> with </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">DonateWeightedEnsembler</span><span style=\"color: #008000; text-decoration-color: #008000\"> and saved in </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'</span><span style=\"font-weight: bold\">prediction' 🍲</span>\n</pre>\n",
      "text/plain": "🍲 Ensembled \u001b[34m'\u001b[0m\u001b[34m[\u001b[0m\u001b[34m'\u001b[0m\u001b[34mprediction_A', \u001b[0m\u001b[34m'prediction_B'\u001b[0m\u001b[34m, \u001b[0m\u001b[34m'prediction_C'\u001b[0m\u001b[34m, \u001b[0m\u001b[34m'prediction_D'\u001b[0m\u001b[34m, \u001b[0m\n\u001b[34m'prediction_E'\u001b[0m\u001b[1;34m]\u001b[0m\u001b[34m'\u001b[0m\u001b[32m with \u001b[0m\u001b[1;32mDonateWeightedEnsembler\u001b[0m\u001b[32m and saved in \u001b[0m\u001b[1;32m'\u001b[0m\u001b[1mprediction'\u001b[0m\u001b[1m 🍲\u001b[0m\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">DonateWeightedEnsembler</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">005038</span>. ✅\n</pre>\n",
      "text/plain": "✅ Finished step \u001b[1mDonateWeightedEnsembler\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \n\u001b[1;34m0:00:00\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m005038\u001b[0m. ✅\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_A</th>\n      <th>prediction_B</th>\n      <th>prediction_C</th>\n      <th>prediction_D</th>\n      <th>prediction_E</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.111924</td>\n      <td>0.935528</td>\n      <td>0.853572</td>\n      <td>0.351036</td>\n      <td>0.158973</td>\n      <td>0.339408</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.846985</td>\n      <td>0.748842</td>\n      <td>0.839880</td>\n      <td>0.781556</td>\n      <td>0.354063</td>\n      <td>0.577145</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   prediction_A  prediction_B  prediction_C  prediction_D  prediction_E  \\\n0      0.111924      0.935528      0.853572      0.351036      0.158973   \n1      0.846985      0.748842      0.839880      0.781556      0.354063   \n\n   prediction  \n0    0.339408  \n1    0.577145  "
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"w_5_fold = [0.0625, 0.0625, 0.125, 0.25, 0.5]\\ndonate = DonateWeightedEnsembler(\\n    cols=test_dataf.prediction_cols, final_col_name=\\\"prediction\\\"\\n)\\nensembled = donate(test_dataf).get_prediction_data\\nassert ensembled[\\\"prediction\\\"][0] == np.sum(\\n    [w * elem for w, elem in zip(w_5_fold, ensembled[test_features].iloc[0])]\\n)\\nensembled.head(2)\";\n                var nbb_formatted_code = \"w_5_fold = [0.0625, 0.0625, 0.125, 0.25, 0.5]\\ndonate = DonateWeightedEnsembler(\\n    cols=test_dataf.prediction_cols, final_col_name=\\\"prediction\\\"\\n)\\nensembled = donate(test_dataf).get_prediction_data\\nassert ensembled[\\\"prediction\\\"][0] == np.sum(\\n    [w * elem for w, elem in zip(w_5_fold, ensembled[test_features].iloc[0])]\\n)\\nensembled.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_5_fold = [0.0625, 0.0625, 0.125, 0.25, 0.5]\n",
    "donate = DonateWeightedEnsembler(\n",
    "    cols=test_dataf.prediction_cols, final_col_name=\"prediction\"\n",
    ")\n",
    "ensembled = donate(test_dataf).get_prediction_data\n",
    "assert ensembled[\"prediction\"][0] == np.sum(\n",
    "    [w * elem for w, elem in zip(w_5_fold, ensembled[test_features].iloc[0])]\n",
    ")\n",
    "ensembled.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0.2.3. Geometric Mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the mean of multiple prediction columns using the product of values.\n",
    "\n",
    "**More info on Geometric mean:**\n",
    "- [Wikipedia](https://en.wikipedia.org/wiki/Geometric_mean)\n",
    "- [Investopedia](https://www.investopedia.com/terms/g/geometricmean.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass GeometricMeanEnsembler(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Calculate the weighted Geometric mean.\\n\\n    :param cols: Prediction columns to ensemble.\\n    Uses all prediction columns by default. \\\\n\\n    :param final_col_name: New column name for ensembled values.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, final_col_name: str, cols: list = None):\\n        super().__init__(final_col_name=final_col_name)\\n        self.cols = cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        cols = self.cols if self.cols else dataf.prediction_cols\\n        new_col = dataf.loc[:, cols].apply(gmean, axis=1)\\n        dataf.loc[:, self.final_col_name] = new_col\\n        rich_print(\\n            f\\\":stew: Ensembled [blue]'{cols}'[/blue] with [bold]{self.__class__.__name__}[/bold] and saved in [bold]'{self.final_col_name}'[bold] :stew:\\\"\\n        )\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass GeometricMeanEnsembler(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Calculate the weighted Geometric mean.\\n\\n    :param cols: Prediction columns to ensemble.\\n    Uses all prediction columns by default. \\\\n\\n    :param final_col_name: New column name for ensembled values.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, final_col_name: str, cols: list = None):\\n        super().__init__(final_col_name=final_col_name)\\n        self.cols = cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        cols = self.cols if self.cols else dataf.prediction_cols\\n        new_col = dataf.loc[:, cols].apply(gmean, axis=1)\\n        dataf.loc[:, self.final_col_name] = new_col\\n        rich_print(\\n            f\\\":stew: Ensembled [blue]'{cols}'[/blue] with [bold]{self.__class__.__name__}[/bold] and saved in [bold]'{self.final_col_name}'[bold] :stew:\\\"\\n        )\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class GeometricMeanEnsembler(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Calculate the weighted Geometric mean.\n",
    "\n",
    "    :param cols: Prediction columns to ensemble.\n",
    "    Uses all prediction columns by default. \\n\n",
    "    :param final_col_name: New column name for ensembled values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, final_col_name: str, cols: list = None):\n",
    "        super().__init__(final_col_name=final_col_name)\n",
    "        self.cols = cols\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        cols = self.cols if self.cols else dataf.prediction_cols\n",
    "        new_col = dataf.loc[:, cols].apply(gmean, axis=1)\n",
    "        dataf.loc[:, self.final_col_name] = new_col\n",
    "        rich_print(\n",
    "            f\":stew: Ensembled [blue]'{cols}'[/blue] with [bold]{self.__class__.__name__}[/bold] and saved in [bold]'{self.final_col_name}'[bold] :stew:\"\n",
    "        )\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍲 Ensembled <span style=\"color: #000080; text-decoration-color: #000080\">'['</span><span style=\"color: #000080; text-decoration-color: #000080\">prediction_A', </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_B'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_C'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span><span style=\"color: #000080; text-decoration-color: #000080\">'prediction_D'</span><span style=\"color: #000080; text-decoration-color: #000080\">, </span>\n<span style=\"color: #000080; text-decoration-color: #000080\">'prediction_E'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span><span style=\"color: #000080; text-decoration-color: #000080\">'</span><span style=\"color: #008000; text-decoration-color: #008000\"> with </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">GeometricMeanEnsembler</span><span style=\"color: #008000; text-decoration-color: #008000\"> and saved in </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'</span><span style=\"font-weight: bold\">prediction_geo' 🍲</span>\n</pre>\n",
      "text/plain": "🍲 Ensembled \u001b[34m'\u001b[0m\u001b[34m[\u001b[0m\u001b[34m'\u001b[0m\u001b[34mprediction_A', \u001b[0m\u001b[34m'prediction_B'\u001b[0m\u001b[34m, \u001b[0m\u001b[34m'prediction_C'\u001b[0m\u001b[34m, \u001b[0m\u001b[34m'prediction_D'\u001b[0m\u001b[34m, \u001b[0m\n\u001b[34m'prediction_E'\u001b[0m\u001b[1;34m]\u001b[0m\u001b[34m'\u001b[0m\u001b[32m with \u001b[0m\u001b[1;32mGeometricMeanEnsembler\u001b[0m\u001b[32m and saved in \u001b[0m\u001b[1;32m'\u001b[0m\u001b[1mprediction_geo'\u001b[0m\u001b[1m 🍲\u001b[0m\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">GeometricMeanEnsembler</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">014248</span>. ✅\n</pre>\n",
      "text/plain": "✅ Finished step \u001b[1mGeometricMeanEnsembler\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m9\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \n\u001b[1;34m0:00:00\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m014248\u001b[0m. ✅\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction_A</th>\n      <th>prediction_B</th>\n      <th>prediction_C</th>\n      <th>prediction_D</th>\n      <th>prediction_E</th>\n      <th>prediction</th>\n      <th>prediction_geo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.111924</td>\n      <td>0.935528</td>\n      <td>0.853572</td>\n      <td>0.351036</td>\n      <td>0.158973</td>\n      <td>0.339408</td>\n      <td>0.346401</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.846985</td>\n      <td>0.748842</td>\n      <td>0.839880</td>\n      <td>0.781556</td>\n      <td>0.354063</td>\n      <td>0.577145</td>\n      <td>0.681875</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   prediction_A  prediction_B  prediction_C  prediction_D  prediction_E  \\\n0      0.111924      0.935528      0.853572      0.351036      0.158973   \n1      0.846985      0.748842      0.839880      0.781556      0.354063   \n\n   prediction  prediction_geo  \n0    0.339408        0.346401  \n1    0.577145        0.681875  "
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"geo_mean = GeometricMeanEnsembler(final_col_name=\\\"prediction_geo\\\")\\nensembled = geo_mean(test_dataf).get_prediction_data\\nensembled.head(2)\";\n                var nbb_formatted_code = \"geo_mean = GeometricMeanEnsembler(final_col_name=\\\"prediction_geo\\\")\\nensembled = geo_mean(test_dataf).get_prediction_data\\nensembled.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "geo_mean = GeometricMeanEnsembler(final_col_name=\"prediction_geo\")\n",
    "ensembled = geo_mean(test_dataf).get_prediction_data\n",
    "ensembled.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.3. Neutralization and penalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0.3.1. Feature Neutralization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classic feature neutralization (subtracting linear model from scores).\n",
    "\n",
    "New column name for neutralized values will be `{pred_name}_neutralized_{PROPORTION}`. `pred_name` should start with `'prediction'`.\n",
    "\n",
    "Optionally, you can run feature neutralization on the GPU using [cupy](https://docs.cupy.dev/en/stable/overview.html) by setting `cuda=True`. Make sure you have `cupy` installed with the correct CUDA Toolkit version. More information: [docs.cupy.dev/en/stable/install.html](https://docs.cupy.dev/en/stable/install.html)\n",
    "\n",
    "[Detailed explanation of Feature Neutralization by Katsu1110](https://www.kaggle.com/code1110/janestreet-avoid-overfit-feature-neutralization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 15;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass FeatureNeutralizer(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Classic feature neutralization by subtracting linear model.\\n\\n    :param feature_names: List of column names to neutralize against. Uses all feature columns by default. \\\\n\\n    :param pred_name: Prediction column to neutralize. \\\\n\\n    :param proportion: Number in range [0...1] indicating how much to neutralize. \\\\n\\n    :param suffix: Optional suffix that is added to new column name. \\\\n\\n    :param cuda: Do neutralization on the GPU \\\\n\\n    Make sure you have CuPy installed when setting cuda to True. \\\\n\\n    Installation docs: docs.cupy.dev/en/stable/install.html\\n    \\\"\\\"\\\"\\n    def __init__(\\n        self,\\n        feature_names: list = None,\\n        pred_name: str = \\\"prediction\\\",\\n        proportion: float = 0.5,\\n        suffix: str = None,\\n        cuda = False,\\n    ):\\n        self.pred_name = pred_name\\n        self.proportion = proportion\\n        assert (\\n            0.0 <= proportion <= 1.0\\n        ), f\\\"'proportion' should be a float in range [0...1]. Got '{proportion}'.\\\"\\n        self.new_col_name = (\\n            f\\\"{self.pred_name}_neutralized_{self.proportion}_{suffix}\\\"\\n            if suffix\\n            else f\\\"{self.pred_name}_neutralized_{self.proportion}\\\"\\n        )\\n        super().__init__(final_col_name=self.new_col_name)\\n\\n        self.feature_names = feature_names\\n        self.cuda = cuda\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\\n        neutralized_preds = dataf.groupby(dataf.meta.era_col).apply(\\n            lambda x: self.normalize_and_neutralize(x, [self.pred_name], feature_names)\\n        )\\n        dataf.loc[:, self.new_col_name] = MinMaxScaler().fit_transform(\\n            neutralized_preds\\n        )\\n        rich_print(\\n            f\\\":robot: Neutralized [bold blue]'{self.pred_name}'[bold blue] with proportion [bold]'{self.proportion}'[/bold] :robot:\\\"\\n        )\\n        rich_print(\\n            f\\\"New neutralized column = [bold green]'{self.new_col_name}'[/bold green].\\\"\\n        )\\n        return NumerFrame(dataf)\\n\\n    def neutralize(self, dataf: pd.DataFrame, columns: list, by: list) -> pd.DataFrame:\\n        \\\"\\\"\\\" Neutralize on CPU. \\\"\\\"\\\"\\n        scores = dataf[columns]\\n        exposures = dataf[by].values\\n        scores = scores - self.proportion * exposures.dot(\\n            np.linalg.pinv(exposures).dot(scores)\\n        )\\n        return scores / scores.std()\\n\\n    def neutralize_cuda(self, dataf: pd.DataFrame, columns: list, by: list) -> np.ndarray:\\n        \\\"\\\"\\\" Neutralize on GPU. \\\"\\\"\\\"\\n        try:\\n            import cupy\\n        except ImportError:\\n            raise ImportError(\\\"CuPy not installed. Set cuda=False or install CuPy. Installation docs: docs.cupy.dev/en/stable/install.html\\\")\\n        scores = cupy.array(dataf[columns].values)\\n        exposures = cupy.array(dataf[by].values)\\n        scores = scores - self.proportion * exposures.dot(\\n            cupy.linalg.pinv(exposures).dot(scores)\\n        )\\n        return cupy.asnumpy(scores / scores.std())\\n\\n    @staticmethod\\n    def normalize(dataf: pd.DataFrame) -> np.ndarray:\\n        normalized_ranks = (dataf.rank(method=\\\"first\\\") - 0.5) / len(dataf)\\n        return sp.norm.ppf(normalized_ranks)\\n\\n    def normalize_and_neutralize(\\n        self, dataf: pd.DataFrame, columns: list, by: list\\n    ) -> pd.DataFrame:\\n        dataf[columns] = self.normalize(dataf[columns])\\n        neutralization_func = self.neutralize if not self.cuda else self.neutralize_cuda\\n        dataf[columns] = neutralization_func(dataf, columns, by)\\n        return dataf[columns]\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass FeatureNeutralizer(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Classic feature neutralization by subtracting linear model.\\n\\n    :param feature_names: List of column names to neutralize against. Uses all feature columns by default. \\\\n\\n    :param pred_name: Prediction column to neutralize. \\\\n\\n    :param proportion: Number in range [0...1] indicating how much to neutralize. \\\\n\\n    :param suffix: Optional suffix that is added to new column name. \\\\n\\n    :param cuda: Do neutralization on the GPU \\\\n\\n    Make sure you have CuPy installed when setting cuda to True. \\\\n\\n    Installation docs: docs.cupy.dev/en/stable/install.html\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        feature_names: list = None,\\n        pred_name: str = \\\"prediction\\\",\\n        proportion: float = 0.5,\\n        suffix: str = None,\\n        cuda=False,\\n    ):\\n        self.pred_name = pred_name\\n        self.proportion = proportion\\n        assert (\\n            0.0 <= proportion <= 1.0\\n        ), f\\\"'proportion' should be a float in range [0...1]. Got '{proportion}'.\\\"\\n        self.new_col_name = (\\n            f\\\"{self.pred_name}_neutralized_{self.proportion}_{suffix}\\\"\\n            if suffix\\n            else f\\\"{self.pred_name}_neutralized_{self.proportion}\\\"\\n        )\\n        super().__init__(final_col_name=self.new_col_name)\\n\\n        self.feature_names = feature_names\\n        self.cuda = cuda\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\\n        neutralized_preds = dataf.groupby(dataf.meta.era_col).apply(\\n            lambda x: self.normalize_and_neutralize(x, [self.pred_name], feature_names)\\n        )\\n        dataf.loc[:, self.new_col_name] = MinMaxScaler().fit_transform(\\n            neutralized_preds\\n        )\\n        rich_print(\\n            f\\\":robot: Neutralized [bold blue]'{self.pred_name}'[bold blue] with proportion [bold]'{self.proportion}'[/bold] :robot:\\\"\\n        )\\n        rich_print(\\n            f\\\"New neutralized column = [bold green]'{self.new_col_name}'[/bold green].\\\"\\n        )\\n        return NumerFrame(dataf)\\n\\n    def neutralize(self, dataf: pd.DataFrame, columns: list, by: list) -> pd.DataFrame:\\n        \\\"\\\"\\\"Neutralize on CPU.\\\"\\\"\\\"\\n        scores = dataf[columns]\\n        exposures = dataf[by].values\\n        scores = scores - self.proportion * exposures.dot(\\n            np.linalg.pinv(exposures).dot(scores)\\n        )\\n        return scores / scores.std()\\n\\n    def neutralize_cuda(\\n        self, dataf: pd.DataFrame, columns: list, by: list\\n    ) -> np.ndarray:\\n        \\\"\\\"\\\"Neutralize on GPU.\\\"\\\"\\\"\\n        try:\\n            import cupy\\n        except ImportError:\\n            raise ImportError(\\n                \\\"CuPy not installed. Set cuda=False or install CuPy. Installation docs: docs.cupy.dev/en/stable/install.html\\\"\\n            )\\n        scores = cupy.array(dataf[columns].values)\\n        exposures = cupy.array(dataf[by].values)\\n        scores = scores - self.proportion * exposures.dot(\\n            cupy.linalg.pinv(exposures).dot(scores)\\n        )\\n        return cupy.asnumpy(scores / scores.std())\\n\\n    @staticmethod\\n    def normalize(dataf: pd.DataFrame) -> np.ndarray:\\n        normalized_ranks = (dataf.rank(method=\\\"first\\\") - 0.5) / len(dataf)\\n        return sp.norm.ppf(normalized_ranks)\\n\\n    def normalize_and_neutralize(\\n        self, dataf: pd.DataFrame, columns: list, by: list\\n    ) -> pd.DataFrame:\\n        dataf[columns] = self.normalize(dataf[columns])\\n        neutralization_func = self.neutralize if not self.cuda else self.neutralize_cuda\\n        dataf[columns] = neutralization_func(dataf, columns, by)\\n        return dataf[columns]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class FeatureNeutralizer(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Classic feature neutralization by subtracting linear model.\n",
    "\n",
    "    :param feature_names: List of column names to neutralize against. Uses all feature columns by default. \\n\n",
    "    :param pred_name: Prediction column to neutralize. \\n\n",
    "    :param proportion: Number in range [0...1] indicating how much to neutralize. \\n\n",
    "    :param suffix: Optional suffix that is added to new column name. \\n\n",
    "    :param cuda: Do neutralization on the GPU \\n\n",
    "    Make sure you have CuPy installed when setting cuda to True. \\n\n",
    "    Installation docs: docs.cupy.dev/en/stable/install.html\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_names: list = None,\n",
    "        pred_name: str = \"prediction\",\n",
    "        proportion: float = 0.5,\n",
    "        suffix: str = None,\n",
    "        cuda = False,\n",
    "    ):\n",
    "        self.pred_name = pred_name\n",
    "        self.proportion = proportion\n",
    "        assert (\n",
    "            0.0 <= proportion <= 1.0\n",
    "        ), f\"'proportion' should be a float in range [0...1]. Got '{proportion}'.\"\n",
    "        self.new_col_name = (\n",
    "            f\"{self.pred_name}_neutralized_{self.proportion}_{suffix}\"\n",
    "            if suffix\n",
    "            else f\"{self.pred_name}_neutralized_{self.proportion}\"\n",
    "        )\n",
    "        super().__init__(final_col_name=self.new_col_name)\n",
    "        self.feature_names = feature_names\n",
    "        self.cuda = cuda\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\n",
    "        neutralized_preds = dataf.groupby(dataf.meta.era_col).apply(\n",
    "            lambda x: self.normalize_and_neutralize(x, [self.pred_name], feature_names)\n",
    "        )\n",
    "        dataf.loc[:, self.new_col_name] = MinMaxScaler().fit_transform(\n",
    "            neutralized_preds\n",
    "        )\n",
    "        rich_print(\n",
    "            f\":robot: Neutralized [bold blue]'{self.pred_name}'[bold blue] with proportion [bold]'{self.proportion}'[/bold] :robot:\"\n",
    "        )\n",
    "        rich_print(\n",
    "            f\"New neutralized column = [bold green]'{self.new_col_name}'[/bold green].\"\n",
    "        )\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def neutralize(self, dataf: pd.DataFrame, columns: list, by: list) -> pd.DataFrame:\n",
    "        \"\"\" Neutralize on CPU. \"\"\"\n",
    "        scores = dataf[columns]\n",
    "        exposures = dataf[by].values\n",
    "        scores = scores - self.proportion * exposures.dot(\n",
    "            np.linalg.pinv(exposures).dot(scores)\n",
    "        )\n",
    "        return scores / scores.std()\n",
    "\n",
    "    def neutralize_cuda(self, dataf: pd.DataFrame, columns: list, by: list) -> np.ndarray:\n",
    "        \"\"\" Neutralize on GPU. \"\"\"\n",
    "        try:\n",
    "            import cupy\n",
    "        except ImportError:\n",
    "            raise ImportError(\"CuPy not installed. Set cuda=False or install CuPy. Installation docs: docs.cupy.dev/en/stable/install.html\")\n",
    "        scores = cupy.array(dataf[columns].values)\n",
    "        exposures = cupy.array(dataf[by].values)\n",
    "        scores = scores - self.proportion * exposures.dot(\n",
    "            cupy.linalg.pinv(exposures).dot(scores)\n",
    "        )\n",
    "        return cupy.asnumpy(scores / scores.std())\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize(dataf: pd.DataFrame) -> np.ndarray:\n",
    "        normalized_ranks = (dataf.rank(method=\"first\") - 0.5) / len(dataf)\n",
    "        return sp.norm.ppf(normalized_ranks)\n",
    "\n",
    "    def normalize_and_neutralize(\n",
    "        self, dataf: pd.DataFrame, columns: list, by: list\n",
    "    ) -> pd.DataFrame:\n",
    "        dataf[columns] = self.normalize(dataf[columns])\n",
    "        neutralization_func = self.neutralize if not self.cuda else self.neutralize_cuda\n",
    "        dataf[columns] = neutralization_func(dataf, columns, by)\n",
    "        return dataf[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"test_dataf = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\ntest_dataf.loc[:, \\\"prediction\\\"] = np.random.uniform(size=len(test_dataf))\";\n                var nbb_formatted_code = \"test_dataf = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\ntest_dataf.loc[:, \\\"prediction\\\"] = np.random.uniform(size=len(test_dataf))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataf = create_numerframe(\"test_assets/mini_numerai_version_1_data.csv\")\n",
    "test_dataf.loc[:, \"prediction\"] = np.random.uniform(size=len(test_dataf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🤖 Neutralized <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">'prediction'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> with proportion </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">'0.8'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> 🤖</span>\n</pre>\n",
      "text/plain": "🤖 Neutralized \u001b[1;34m'prediction'\u001b[0m\u001b[1;34m with proportion \u001b[0m\u001b[1;34m'0.8'\u001b[0m\u001b[1;34m 🤖\u001b[0m\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">New neutralized column = <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'prediction_neutralized_0.8'</span>.\n</pre>\n",
      "text/plain": "New neutralized column = \u001b[1;32m'prediction_neutralized_0.8'\u001b[0m.\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">FeatureNeutralizer</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">316</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">048929</span>. ✅\n</pre>\n",
      "text/plain": "✅ Finished step \u001b[1mFeatureNeutralizer\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m316\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \n\u001b[1;34m0:00:00\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m048929\u001b[0m. ✅\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 17;\n                var nbb_unformatted_code = \"ft = FeatureNeutralizer(\\n    feature_names=test_dataf.feature_cols, pred_name=\\\"prediction\\\", proportion=0.8\\n)\\nnew_dataf = ft.transform(test_dataf)\";\n                var nbb_formatted_code = \"ft = FeatureNeutralizer(\\n    feature_names=test_dataf.feature_cols, pred_name=\\\"prediction\\\", proportion=0.8\\n)\\nnew_dataf = ft.transform(test_dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ft = FeatureNeutralizer(\n",
    "    feature_names=test_dataf.feature_cols, pred_name=\"prediction\", proportion=0.8\n",
    ")\n",
    "new_dataf = ft.transform(test_dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"assert \\\"prediction_neutralized_0.8\\\" in new_dataf.prediction_cols\\nassert 0.0 in new_dataf.get_prediction_data[\\\"prediction_neutralized_0.8\\\"]\\nassert 1.0 in new_dataf.get_prediction_data[\\\"prediction_neutralized_0.8\\\"]\";\n                var nbb_formatted_code = \"assert \\\"prediction_neutralized_0.8\\\" in new_dataf.prediction_cols\\nassert 0.0 in new_dataf.get_prediction_data[\\\"prediction_neutralized_0.8\\\"]\\nassert 1.0 in new_dataf.get_prediction_data[\\\"prediction_neutralized_0.8\\\"]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert \"prediction_neutralized_0.8\" in new_dataf.prediction_cols\n",
    "assert 0.0 in new_dataf.get_prediction_data[\"prediction_neutralized_0.8\"]\n",
    "assert 1.0 in new_dataf.get_prediction_data[\"prediction_neutralized_0.8\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated columns and data can be easily retrieved for the `NumerFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['prediction', 'prediction_neutralized_0.8']"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 19;\n                var nbb_unformatted_code = \"new_dataf.prediction_cols\";\n                var nbb_formatted_code = \"new_dataf.prediction_cols\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_dataf.prediction_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction</th>\n      <th>prediction_neutralized_0.8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.516076</td>\n      <td>0.461802</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.356837</td>\n      <td>0.294970</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.283496</td>\n      <td>0.184947</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   prediction  prediction_neutralized_0.8\n0    0.516076                    0.461802\n1    0.356837                    0.294970\n2    0.283496                    0.184947"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 20;\n                var nbb_unformatted_code = \"new_dataf.get_prediction_data.head(3)\";\n                var nbb_formatted_code = \"new_dataf.get_prediction_data.head(3)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_dataf.get_prediction_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 21;\n                var nbb_unformatted_code = \"# hide\\n# cuda_test\\n# ft = FeatureNeutralizer(\\n#     feature_names=test_dataf.feature_cols, pred_name=\\\"prediction\\\",\\n#     proportion=0.8, cuda=True\\n# )\\n# new_dataf_cuda = ft.transform(test_dataf)\\n# new_dataf_cuda.head(2)\";\n                var nbb_formatted_code = \"# hide\\n# cuda_test\\n# ft = FeatureNeutralizer(\\n#     feature_names=test_dataf.feature_cols, pred_name=\\\"prediction\\\",\\n#     proportion=0.8, cuda=True\\n# )\\n# new_dataf_cuda = ft.transform(test_dataf)\\n# new_dataf_cuda.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| include: false\n",
    "#| cuda_test\n",
    "# ft = FeatureNeutralizer(\n",
    "#     feature_names=test_dataf.feature_cols, pred_name=\"prediction\",\n",
    "#     proportion=0.8, cuda=True\n",
    "# )\n",
    "# new_dataf_cuda = ft.transform(test_dataf)\n",
    "# new_dataf_cuda.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0.3.2. Feature Penalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 22;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass FeaturePenalizer(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Feature penalization with TensorFlow.\\n\\n    Source (by jrb): https://github.com/jonrtaylor/twitch/blob/master/FE_Clipping_Script.ipynb\\n\\n    Source of first PyTorch implementation (by Michael Oliver / mdo): https://forum.numer.ai/t/model-diagnostics-feature-exposure/899/12\\n\\n    :param feature_names: List of column names to reduce feature exposure. Uses all feature columns by default. \\\\n\\n    :param pred_name: Prediction column to neutralize. \\\\n\\n    :param max_exposure: Number in range [0...1] indicating how much to reduce max feature exposure to.\\n    \\\"\\\"\\\"\\n    def __init__(\\n        self,\\n        max_exposure: float,\\n        feature_names: list = None,\\n        pred_name: str = \\\"prediction\\\",\\n        suffix: str = None,\\n    ):\\n        self.pred_name = pred_name\\n        self.max_exposure = max_exposure\\n        assert (\\n            0.0 <= max_exposure <= 1.0\\n        ), f\\\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\\\"\\n        self.new_col_name = (\\n            f\\\"{self.pred_name}_penalized_{self.max_exposure}_{suffix}\\\"\\n            if suffix\\n            else f\\\"{self.pred_name}_penalized_{self.max_exposure}\\\"\\n        )\\n        super().__init__(final_col_name=self.new_col_name)\\n\\n        self.feature_names = feature_names\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        feature_names = (\\n            dataf.feature_cols if not self.feature_names else self.feature_names\\n        )\\n        penalized_data = self.reduce_all_exposures(\\n            dataf=dataf, column=self.pred_name, neutralizers=feature_names\\n        )\\n        dataf.loc[:, self.new_col_name] = penalized_data[self.pred_name]\\n        return NumerFrame(dataf)\\n\\n    def reduce_all_exposures(\\n        self,\\n        dataf: NumerFrame,\\n        column: str = \\\"prediction\\\",\\n        neutralizers: list = None,\\n        normalize=True,\\n        gaussianize=True,\\n    ) -> pd.DataFrame:\\n        if neutralizers is None:\\n            neutralizers = [x for x in dataf.columns if x.startswith(\\\"feature\\\")]\\n        neutralized = []\\n\\n        for era in tqdm(dataf[dataf.meta.era_col].unique()):\\n            dataf_era = dataf[dataf[dataf.meta.era_col] == era]\\n            scores = dataf_era[[column]].values\\n            exposure_values = dataf_era[neutralizers].values\\n\\n            if normalize:\\n                scores2 = []\\n                for x in scores.T:\\n                    x = (scipy.stats.rankdata(x, method=\\\"ordinal\\\") - 0.5) / len(x)\\n                    if gaussianize:\\n                        x = scipy.stats.norm.ppf(x)\\n                    scores2.append(x)\\n                scores = np.array(scores2)[0]\\n\\n            scores, weights = self._reduce_exposure(\\n                scores, exposure_values, len(neutralizers), None\\n            )\\n\\n            scores /= tf.math.reduce_std(scores)\\n            scores -= tf.reduce_min(scores)\\n            scores /= tf.reduce_max(scores)\\n            neutralized.append(scores.numpy())\\n\\n        predictions = pd.DataFrame(\\n            np.concatenate(neutralized), columns=[column], index=dataf.index\\n        )\\n        return predictions\\n\\n    def _reduce_exposure(self, prediction, features, input_size=50, weights=None):\\n        model = tf.keras.models.Sequential(\\n            [\\n                tf.keras.layers.Input(input_size),\\n                tf.keras.experimental.LinearModel(use_bias=False),\\n            ]\\n        )\\n        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\\n        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\\n        if weights is None:\\n            optimizer = tf.keras.optimizers.Adamax()\\n            start_exp = self.__exposures(feats, pred[:, None])\\n            target_exps = tf.clip_by_value(\\n                start_exp, -self.max_exposure, self.max_exposure\\n            )\\n            self._train_loop(model, optimizer, feats, pred, target_exps)\\n        else:\\n            model.set_weights(weights)\\n        return pred[:, None] - model(feats), model.get_weights()\\n\\n    def _train_loop(self, model, optimizer, feats, pred, target_exps):\\n        for i in range(1000000):\\n            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\\n            if loss < 1e-7:\\n                break\\n\\n    @tf.function(experimental_relax_shapes=True)\\n    def __train_loop_body(self, model, feats, pred, target_exps):\\n        with tf.GradientTape() as tape:\\n            exps = self.__exposures(feats, pred[:, None] - model(feats, training=True))\\n            loss = tf.reduce_sum(\\n                tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps))\\n                + tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps))\\n            )\\n        return loss, tape.gradient(loss, model.trainable_variables)\\n\\n    @staticmethod\\n    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\\n    def __exposures(x, y):\\n        x = x - tf.math.reduce_mean(x, axis=0)\\n        x = x / tf.norm(x, axis=0)\\n        y = y - tf.math.reduce_mean(y, axis=0)\\n        y = y / tf.norm(y, axis=0)\\n        return tf.matmul(x, y, transpose_a=True)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass FeaturePenalizer(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    Feature penalization with TensorFlow.\\n\\n    Source (by jrb): https://github.com/jonrtaylor/twitch/blob/master/FE_Clipping_Script.ipynb\\n\\n    Source of first PyTorch implementation (by Michael Oliver / mdo): https://forum.numer.ai/t/model-diagnostics-feature-exposure/899/12\\n\\n    :param feature_names: List of column names to reduce feature exposure. Uses all feature columns by default. \\\\n\\n    :param pred_name: Prediction column to neutralize. \\\\n\\n    :param max_exposure: Number in range [0...1] indicating how much to reduce max feature exposure to.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        max_exposure: float,\\n        feature_names: list = None,\\n        pred_name: str = \\\"prediction\\\",\\n        suffix: str = None,\\n    ):\\n        self.pred_name = pred_name\\n        self.max_exposure = max_exposure\\n        assert (\\n            0.0 <= max_exposure <= 1.0\\n        ), f\\\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\\\"\\n        self.new_col_name = (\\n            f\\\"{self.pred_name}_penalized_{self.max_exposure}_{suffix}\\\"\\n            if suffix\\n            else f\\\"{self.pred_name}_penalized_{self.max_exposure}\\\"\\n        )\\n        super().__init__(final_col_name=self.new_col_name)\\n\\n        self.feature_names = feature_names\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        feature_names = (\\n            dataf.feature_cols if not self.feature_names else self.feature_names\\n        )\\n        penalized_data = self.reduce_all_exposures(\\n            dataf=dataf, column=self.pred_name, neutralizers=feature_names\\n        )\\n        dataf.loc[:, self.new_col_name] = penalized_data[self.pred_name]\\n        return NumerFrame(dataf)\\n\\n    def reduce_all_exposures(\\n        self,\\n        dataf: NumerFrame,\\n        column: str = \\\"prediction\\\",\\n        neutralizers: list = None,\\n        normalize=True,\\n        gaussianize=True,\\n    ) -> pd.DataFrame:\\n        if neutralizers is None:\\n            neutralizers = [x for x in dataf.columns if x.startswith(\\\"feature\\\")]\\n        neutralized = []\\n\\n        for era in tqdm(dataf[dataf.meta.era_col].unique()):\\n            dataf_era = dataf[dataf[dataf.meta.era_col] == era]\\n            scores = dataf_era[[column]].values\\n            exposure_values = dataf_era[neutralizers].values\\n\\n            if normalize:\\n                scores2 = []\\n                for x in scores.T:\\n                    x = (scipy.stats.rankdata(x, method=\\\"ordinal\\\") - 0.5) / len(x)\\n                    if gaussianize:\\n                        x = scipy.stats.norm.ppf(x)\\n                    scores2.append(x)\\n                scores = np.array(scores2)[0]\\n\\n            scores, weights = self._reduce_exposure(\\n                scores, exposure_values, len(neutralizers), None\\n            )\\n\\n            scores /= tf.math.reduce_std(scores)\\n            scores -= tf.reduce_min(scores)\\n            scores /= tf.reduce_max(scores)\\n            neutralized.append(scores.numpy())\\n\\n        predictions = pd.DataFrame(\\n            np.concatenate(neutralized), columns=[column], index=dataf.index\\n        )\\n        return predictions\\n\\n    def _reduce_exposure(self, prediction, features, input_size=50, weights=None):\\n        model = tf.keras.models.Sequential(\\n            [\\n                tf.keras.layers.Input(input_size),\\n                tf.keras.experimental.LinearModel(use_bias=False),\\n            ]\\n        )\\n        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\\n        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\\n        if weights is None:\\n            optimizer = tf.keras.optimizers.Adamax()\\n            start_exp = self.__exposures(feats, pred[:, None])\\n            target_exps = tf.clip_by_value(\\n                start_exp, -self.max_exposure, self.max_exposure\\n            )\\n            self._train_loop(model, optimizer, feats, pred, target_exps)\\n        else:\\n            model.set_weights(weights)\\n        return pred[:, None] - model(feats), model.get_weights()\\n\\n    def _train_loop(self, model, optimizer, feats, pred, target_exps):\\n        for i in range(1000000):\\n            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\\n            optimizer.apply_gradients(zip(grads, model.trainable_variables))\\n            if loss < 1e-7:\\n                break\\n\\n    @tf.function(experimental_relax_shapes=True)\\n    def __train_loop_body(self, model, feats, pred, target_exps):\\n        with tf.GradientTape() as tape:\\n            exps = self.__exposures(feats, pred[:, None] - model(feats, training=True))\\n            loss = tf.reduce_sum(\\n                tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps))\\n                + tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps))\\n            )\\n        return loss, tape.gradient(loss, model.trainable_variables)\\n\\n    @staticmethod\\n    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\\n    def __exposures(x, y):\\n        x = x - tf.math.reduce_mean(x, axis=0)\\n        x = x / tf.norm(x, axis=0)\\n        y = y - tf.math.reduce_mean(y, axis=0)\\n        y = y / tf.norm(y, axis=0)\\n        return tf.matmul(x, y, transpose_a=True)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class FeaturePenalizer(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    Feature penalization with TensorFlow.\n",
    "\n",
    "    Source (by jrb): https://github.com/jonrtaylor/twitch/blob/master/FE_Clipping_Script.ipynb\n",
    "\n",
    "    Source of first PyTorch implementation (by Michael Oliver / mdo): https://forum.numer.ai/t/model-diagnostics-feature-exposure/899/12\n",
    "\n",
    "    :param feature_names: List of column names to reduce feature exposure. Uses all feature columns by default. \\n\n",
    "    :param pred_name: Prediction column to neutralize. \\n\n",
    "    :param max_exposure: Number in range [0...1] indicating how much to reduce max feature exposure to.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_exposure: float,\n",
    "        feature_names: list = None,\n",
    "        pred_name: str = \"prediction\",\n",
    "        suffix: str = None,\n",
    "    ):\n",
    "        self.pred_name = pred_name\n",
    "        self.max_exposure = max_exposure\n",
    "        assert (\n",
    "            0.0 <= max_exposure <= 1.0\n",
    "        ), f\"'max_exposure' should be a float in range [0...1]. Got '{max_exposure}'.\"\n",
    "        self.new_col_name = (\n",
    "            f\"{self.pred_name}_penalized_{self.max_exposure}_{suffix}\"\n",
    "            if suffix\n",
    "            else f\"{self.pred_name}_penalized_{self.max_exposure}\"\n",
    "        )\n",
    "        super().__init__(final_col_name=self.new_col_name)\n",
    "\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        feature_names = (\n",
    "            dataf.feature_cols if not self.feature_names else self.feature_names\n",
    "        )\n",
    "        penalized_data = self.reduce_all_exposures(\n",
    "            dataf=dataf, column=self.pred_name, neutralizers=feature_names\n",
    "        )\n",
    "        dataf.loc[:, self.new_col_name] = penalized_data[self.pred_name]\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def reduce_all_exposures(\n",
    "        self,\n",
    "        dataf: NumerFrame,\n",
    "        column: str = \"prediction\",\n",
    "        neutralizers: list = None,\n",
    "        normalize=True,\n",
    "        gaussianize=True,\n",
    "    ) -> pd.DataFrame:\n",
    "        if neutralizers is None:\n",
    "            neutralizers = [x for x in dataf.columns if x.startswith(\"feature\")]\n",
    "        neutralized = []\n",
    "\n",
    "        for era in tqdm(dataf[dataf.meta.era_col].unique()):\n",
    "            dataf_era = dataf[dataf[dataf.meta.era_col] == era]\n",
    "            scores = dataf_era[[column]].values\n",
    "            exposure_values = dataf_era[neutralizers].values\n",
    "\n",
    "            if normalize:\n",
    "                scores2 = []\n",
    "                for x in scores.T:\n",
    "                    x = (scipy.stats.rankdata(x, method=\"ordinal\") - 0.5) / len(x)\n",
    "                    if gaussianize:\n",
    "                        x = scipy.stats.norm.ppf(x)\n",
    "                    scores2.append(x)\n",
    "                scores = np.array(scores2)[0]\n",
    "\n",
    "            scores, weights = self._reduce_exposure(\n",
    "                scores, exposure_values, len(neutralizers), None\n",
    "            )\n",
    "\n",
    "            scores /= tf.math.reduce_std(scores)\n",
    "            scores -= tf.reduce_min(scores)\n",
    "            scores /= tf.reduce_max(scores)\n",
    "            neutralized.append(scores.numpy())\n",
    "\n",
    "        predictions = pd.DataFrame(\n",
    "            np.concatenate(neutralized), columns=[column], index=dataf.index\n",
    "        )\n",
    "        return predictions\n",
    "\n",
    "    def _reduce_exposure(self, prediction, features, input_size=50, weights=None):\n",
    "        model = tf.keras.models.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Input(input_size),\n",
    "                tf.keras.experimental.LinearModel(use_bias=False),\n",
    "            ]\n",
    "        )\n",
    "        feats = tf.convert_to_tensor(features - 0.5, dtype=tf.float32)\n",
    "        pred = tf.convert_to_tensor(prediction, dtype=tf.float32)\n",
    "        if weights is None:\n",
    "            optimizer = tf.keras.optimizers.Adamax()\n",
    "            start_exp = self.__exposures(feats, pred[:, None])\n",
    "            target_exps = tf.clip_by_value(\n",
    "                start_exp, -self.max_exposure, self.max_exposure\n",
    "            )\n",
    "            self._train_loop(model, optimizer, feats, pred, target_exps)\n",
    "        else:\n",
    "            model.set_weights(weights)\n",
    "        return pred[:, None] - model(feats), model.get_weights()\n",
    "\n",
    "    def _train_loop(self, model, optimizer, feats, pred, target_exps):\n",
    "        for i in range(1000000):\n",
    "            loss, grads = self.__train_loop_body(model, feats, pred, target_exps)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            if loss < 1e-7:\n",
    "                break\n",
    "\n",
    "    @tf.function(experimental_relax_shapes=True)\n",
    "    def __train_loop_body(self, model, feats, pred, target_exps):\n",
    "        with tf.GradientTape() as tape:\n",
    "            exps = self.__exposures(feats, pred[:, None] - model(feats, training=True))\n",
    "            loss = tf.reduce_sum(\n",
    "                tf.nn.relu(tf.nn.relu(exps) - tf.nn.relu(target_exps))\n",
    "                + tf.nn.relu(tf.nn.relu(-exps) - tf.nn.relu(-target_exps))\n",
    "            )\n",
    "        return loss, tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    @staticmethod\n",
    "    @tf.function(experimental_relax_shapes=True, experimental_compile=True)\n",
    "    def __exposures(x, y):\n",
    "        x = x - tf.math.reduce_mean(x, axis=0)\n",
    "        x = x / tf.norm(x, axis=0)\n",
    "        y = y - tf.math.reduce_mean(y, axis=0)\n",
    "        y = y / tf.norm(y, axis=0)\n",
    "        return tf.matmul(x, y, transpose_a=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 23;\n                var nbb_unformatted_code = \"# hide\\n# cuda_test\\ntest_dataf = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\ntest_dataf.loc[:, \\\"prediction\\\"] = np.random.uniform(size=len(test_dataf))\\n# ft = FeaturePenalizer(pred_name='prediction', max_exposure=0.8)\\n# new_dataset = ft.transform(test_dataset)\";\n                var nbb_formatted_code = \"# hide\\n# cuda_test\\ntest_dataf = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\ntest_dataf.loc[:, \\\"prediction\\\"] = np.random.uniform(size=len(test_dataf))\\n# ft = FeaturePenalizer(pred_name='prediction', max_exposure=0.8)\\n# new_dataset = ft.transform(test_dataset)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| include: false\n",
    "#| cuda_test\n",
    "test_dataf = create_numerframe(\"test_assets/mini_numerai_version_1_data.csv\")\n",
    "test_dataf.loc[:, \"prediction\"] = np.random.uniform(size=len(test_dataf))\n",
    "# ft = FeaturePenalizer(pred_name='prediction', max_exposure=0.8)\n",
    "# new_dataset = ft.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Numerai Classic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postprocessing steps that are specific to Numerai Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 24;\n                var nbb_unformatted_code = \"# 1.1.\\n# No Numerai Classic specific postprocessors implemented yet.\";\n                var nbb_formatted_code = \"# 1.1.\\n# No Numerai Classic specific postprocessors implemented yet.\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.1.\n",
    "# No Numerai Classic specific postprocessors implemented yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Numerai Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postprocessors that are specific to Numerai Signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 25;\n                var nbb_unformatted_code = \"# 1.2.\\n# No Numerai Signals specific postprocessors implemented yet.\";\n                var nbb_formatted_code = \"# 1.2.\\n# No Numerai Signals specific postprocessors implemented yet.\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.2.\n",
    "# No Numerai Signals specific postprocessors implemented yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom PostProcessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with preprocessors, there are an almost unlimited number of ways to postprocess data. We (once again) invite the Numerai community to develop Numerai Classic and Signals postprocessors.\n",
    "\n",
    "A new Postprocessor should inherit from `BasePostProcessor` and implement a `transform` method. The `transform` method should take a `NumerFrame` as input and return a `NumerFrame` object as output. A template for this is given below.\n",
    "\n",
    "We recommend adding `@typechecked` at the top of a new postprocessor to enforce types and provide useful debugging stacktraces.\n",
    "\n",
    "To enable fancy logging output. Add the `@display_processor_info` decorator to the `transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 26;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass AwesomePostProcessor(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    TEMPLATE - Do some awesome postprocessing.\\n\\n    :param final_col_name: Column name to store manipulated or ensembled predictions in.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, final_col_name: str, *args, **kwargs):\\n        super().__init__(final_col_name=final_col_name)\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        # Do processing\\n        ...\\n        # Add new column(s) for manipulated data\\n        dataf.loc[:, self.final_col_name] = ...\\n        ...\\n        # Parse all contents to the next pipeline step\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass AwesomePostProcessor(BasePostProcessor):\\n    \\\"\\\"\\\"\\n    TEMPLATE - Do some awesome postprocessing.\\n\\n    :param final_col_name: Column name to store manipulated or ensembled predictions in.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, final_col_name: str, *args, **kwargs):\\n        super().__init__(final_col_name=final_col_name)\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        # Do processing\\n        ...\\n        # Add new column(s) for manipulated data\\n        dataf.loc[:, self.final_col_name] = ...\\n        ...\\n        # Parse all contents to the next pipeline step\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": "<IPython.core.display.Javascript object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "@typechecked\n",
    "class AwesomePostProcessor(BasePostProcessor):\n",
    "    \"\"\"\n",
    "    TEMPLATE - Do some awesome postprocessing.\n",
    "\n",
    "    :param final_col_name: Column name to store manipulated or ensembled predictions in.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, final_col_name: str, *args, **kwargs):\n",
    "        super().__init__(final_col_name=final_col_name)\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        # Do processing\n",
    "        ...\n",
    "        # Add new column(s) for manipulated data\n",
    "        dataf.loc[:, self.final_col_name] = ...\n",
    "        ...\n",
    "        # Parse all contents to the next pipeline step\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
