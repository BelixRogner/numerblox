{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: synthetic_data_generation.html\n",
    "title: Synthetic Data Generation with NumerBlox\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "import pandas as pd\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example notebook covers ways to generate synthetic data using `numerblox` components. Synthetic data can be a great way to improve performance simply by having more data to train. We will both cover ways to generate synthetic target variables and features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Download and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numerblox.download import NumeraiClassicDownloader\n",
    "from numerblox.numerframe import create_numerframe, NumerFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = NumeraiClassicDownloader(directory_path=\"synth_test\")\n",
    "dl.download_training_data(version=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = create_numerframe(\"synth_test/numerai_training_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Synthetic target (Bayesian GMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will tackle the problem of creating a synthetic target column to improve model performance. `BayesianGMMTargetProcessor` allows you to generate a new target variable based on a given target. The preprocessor sample the target from a [Bayesian Gaussian Mixture model](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.BayesianGaussianMixture.html) which is fitted on coefficients from a [regularized linear model (Ridge regression)](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html).\n",
    "\n",
    "This implementation is based on a [Github Gist by Michael Oliver (mdo)](https://gist.github.com/the-moliver/dcdd2862dc2c78dda600f1b449071c93)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numerblox.preprocessing import BayesianGMMTargetProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(BayesianGMMTargetProcessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgmm = BayesianGMMTargetProcessor(target_col=\"target_nomi_20\")\n",
    "test_columns = ['era', 'data_type', 'feature_dichasial_hammier_spawner',\n",
    "                'feature_rheumy_epistemic_prancer', 'target',\n",
    "                'target_nomi_20', 'target_paul_20']\n",
    "sample_dataf = NumerFrame(dataf[test_columns].sample(100).fillna(0.5))\n",
    "fake_dataf = bgmm(sample_dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new target will be suffixed by `_fake` to distinguish it from the original targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_dataf.get_target_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can easily generate multiple fake targets in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_col in sample_dataf.target_cols:\n",
    "    bgmm = BayesianGMMTargetProcessor(target_col=target_col)\n",
    "    sample_dataf = bgmm(sample_dataf)\n",
    "sample_dataf.get_target_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DeepDreamGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numerblox.preprocessing import DeepDreamGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DeepDreamGenerator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Simple data generation example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example we will use the model open sourced by [nemethpeti](https://github.com/nemethpeti) which you can download [here](https://github.com/nemethpeti/numerai/blob/main/DeepDream/model.h5). This model works on the v3 medium feature set. We therefore use v3 data in this example. The v3 medium feature set can be easily retrieved using `NumeraiClassicDownloader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "feature_set = dl.get_classic_features(filename=\"v3/features.json\")\n",
    "feature_names = feature_set['feature_sets']['medium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 12:40:43.915881: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "ddg = DeepDreamGenerator(model_path=\"../test_assets/deepdream_model.h5\",\n",
    "                         feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to generate features from a small subset of 100 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataf_2 = NumerFrame(dataf.sample(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45faba4735904e619922e160e16357c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Deepdreaming Synthetic Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">DeepDreamGenerator</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">199</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1073</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">273758</span>. ✅\n</pre>\n",
      "text/plain": "✅ Finished step \u001b[1mDeepDreamGenerator\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m199\u001b[0m, \u001b[1;36m1073\u001b[0m\u001b[1m)\u001b[0m. Time taken for step: \n\u001b[1;34m0:00:00\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m273758\u001b[0m. ✅\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dreamed_dataf = ddg.transform(sample_dataf_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new dreamed `NumerFrame` consists of the original data and 100 new additional rows. Note that targets are the same.\n",
    "\n",
    "Also, `era`, `data_type` and any other columns besides features and targets will be `NaN`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 1073)\n"
     ]
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>era</th>\n      <th>data_type</th>\n      <th>feature_dichasial_hammier_spawner</th>\n      <th>feature_rheumy_epistemic_prancer</th>\n      <th>feature_pert_performative_hormuz</th>\n      <th>feature_hillier_unpitied_theobromine</th>\n      <th>feature_perigean_bewitching_thruster</th>\n      <th>feature_renegade_undomestic_milord</th>\n      <th>feature_koranic_rude_corf</th>\n      <th>feature_demisable_expiring_millepede</th>\n      <th>...</th>\n      <th>target_paul_20</th>\n      <th>target_paul_60</th>\n      <th>target_george_20</th>\n      <th>target_george_60</th>\n      <th>target_william_20</th>\n      <th>target_william_60</th>\n      <th>target_arthur_20</th>\n      <th>target_arthur_60</th>\n      <th>target_thomas_20</th>\n      <th>target_thomas_60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>94</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.926837</td>\n      <td>0.701231</td>\n      <td>0.988952</td>\n      <td>0.195643</td>\n      <td>0.780995</td>\n      <td>0.321617</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.500000</td>\n      <td>0.166667</td>\n      <td>0.500000</td>\n      <td>0.166667</td>\n      <td>0.500000</td>\n      <td>0.166667</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.480184</td>\n      <td>0.427976</td>\n      <td>0.223835</td>\n      <td>0.183721</td>\n      <td>0.761205</td>\n      <td>0.395356</td>\n      <td>0.238707</td>\n      <td>0.997490</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>1.000000</td>\n      <td>0.833333</td>\n      <td>0.833333</td>\n      <td>0.833333</td>\n      <td>0.833333</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.970524</td>\n      <td>0.246957</td>\n      <td>0.463982</td>\n      <td>0.280058</td>\n      <td>1.000000</td>\n      <td>0.766258</td>\n      <td>0.239566</td>\n      <td>0.723194</td>\n      <td>...</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.010460</td>\n      <td>1.000000</td>\n      <td>0.247279</td>\n      <td>0.204357</td>\n      <td>0.757548</td>\n      <td>0.702845</td>\n      <td>1.000000</td>\n      <td>0.468156</td>\n      <td>...</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.736778</td>\n      <td>0.750979</td>\n      <td>0.007622</td>\n      <td>0.220263</td>\n      <td>0.268438</td>\n      <td>0.741399</td>\n      <td>0.044169</td>\n      <td>0.976056</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1073 columns</p>\n</div>",
      "text/plain": "    era data_type  feature_dichasial_hammier_spawner  \\\n94  NaN       NaN                           0.000000   \n95  NaN       NaN                           0.480184   \n96  NaN       NaN                           0.970524   \n97  NaN       NaN                           0.010460   \n98  NaN       NaN                           0.736778   \n\n    feature_rheumy_epistemic_prancer  feature_pert_performative_hormuz  \\\n94                          0.000000                          0.926837   \n95                          0.427976                          0.223835   \n96                          0.246957                          0.463982   \n97                          1.000000                          0.247279   \n98                          0.750979                          0.007622   \n\n    feature_hillier_unpitied_theobromine  \\\n94                              0.701231   \n95                              0.183721   \n96                              0.280058   \n97                              0.204357   \n98                              0.220263   \n\n    feature_perigean_bewitching_thruster  feature_renegade_undomestic_milord  \\\n94                              0.988952                            0.195643   \n95                              0.761205                            0.395356   \n96                              1.000000                            0.766258   \n97                              0.757548                            0.702845   \n98                              0.268438                            0.741399   \n\n    feature_koranic_rude_corf  feature_demisable_expiring_millepede  ...  \\\n94                   0.780995                              0.321617  ...   \n95                   0.238707                              0.997490  ...   \n96                   0.239566                              0.723194  ...   \n97                   1.000000                              0.468156  ...   \n98                   0.044169                              0.976056  ...   \n\n    target_paul_20  target_paul_60  target_george_20  target_george_60  \\\n94            0.50            0.00              0.50              0.25   \n95            1.00            0.75              1.00              0.75   \n96            0.75            0.75              0.50              0.75   \n97            0.25            0.25              0.25              0.25   \n98            0.50            0.50              0.25              0.50   \n\n    target_william_20  target_william_60  target_arthur_20  target_arthur_60  \\\n94           0.500000           0.166667          0.500000          0.166667   \n95           1.000000           0.833333          0.833333          0.833333   \n96           0.666667           0.666667          0.666667          0.666667   \n97           0.333333           0.333333          0.333333          0.333333   \n98           0.500000           0.500000          0.333333          0.333333   \n\n    target_thomas_20  target_thomas_60  \n94          0.500000          0.166667  \n95          0.833333          0.666667  \n96          0.500000          0.666667  \n97          0.333333          0.333333  \n98          0.500000          0.500000  \n\n[5 rows x 1073 columns]"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dreamed_dataf.shape)\n",
    "dreamed_dataf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To only get new synthetic data use `.get_synthetic_batch`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29d725629a34468bf5c626843805213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Deepdreaming Synthetic Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "synth_dataf = ddg.get_synthetic_batch(sample_dataf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 441)\n"
     ]
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_abstersive_emotional_misinterpreter</th>\n      <th>feature_accessorial_aroused_crochet</th>\n      <th>feature_acerb_venusian_piety</th>\n      <th>feature_affricative_bromic_raftsman</th>\n      <th>feature_agile_unrespited_gaucho</th>\n      <th>feature_agronomic_cryptal_advisor</th>\n      <th>feature_alkaline_pistachio_sunstone</th>\n      <th>feature_altern_unnoticed_impregnation</th>\n      <th>feature_ambisexual_boiled_blunderer</th>\n      <th>feature_amoebaean_wolfish_heeler</th>\n      <th>...</th>\n      <th>target_paul_20</th>\n      <th>target_paul_60</th>\n      <th>target_george_20</th>\n      <th>target_george_60</th>\n      <th>target_william_20</th>\n      <th>target_william_60</th>\n      <th>target_arthur_20</th>\n      <th>target_arthur_60</th>\n      <th>target_thomas_20</th>\n      <th>target_thomas_60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.517510</td>\n      <td>0.590794</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.108258</td>\n      <td>0.042904</td>\n      <td>0.531423</td>\n      <td>0.994126</td>\n      <td>0.322113</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.666667</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.007362</td>\n      <td>0.018246</td>\n      <td>0.816708</td>\n      <td>0.000000</td>\n      <td>0.050006</td>\n      <td>0.079645</td>\n      <td>0.055798</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.000000</td>\n      <td>0.731188</td>\n      <td>0.384121</td>\n      <td>0.424877</td>\n      <td>1.000000</td>\n      <td>0.120615</td>\n      <td>0.012530</td>\n      <td>0.010341</td>\n      <td>0.433381</td>\n      <td>0.050186</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.009710</td>\n      <td>0.026749</td>\n      <td>0.858364</td>\n      <td>0.420578</td>\n      <td>0.720584</td>\n      <td>0.041099</td>\n      <td>0.000000</td>\n      <td>0.010843</td>\n      <td>0.733748</td>\n      <td>0.477730</td>\n      <td>...</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.458052</td>\n      <td>0.623646</td>\n      <td>0.371411</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.740971</td>\n      <td>1.000000</td>\n      <td>0.746225</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.666667</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>0.833333</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 441 columns</p>\n</div>",
      "text/plain": "   feature_abstersive_emotional_misinterpreter  \\\n0                                     0.000000   \n1                                     0.007362   \n2                                     1.000000   \n3                                     0.009710   \n4                                     0.458052   \n\n   feature_accessorial_aroused_crochet  feature_acerb_venusian_piety  \\\n0                             0.517510                      0.590794   \n1                             0.018246                      0.816708   \n2                             0.731188                      0.384121   \n3                             0.026749                      0.858364   \n4                             0.623646                      0.371411   \n\n   feature_affricative_bromic_raftsman  feature_agile_unrespited_gaucho  \\\n0                             0.000000                         1.000000   \n1                             0.000000                         0.050006   \n2                             0.424877                         1.000000   \n3                             0.420578                         0.720584   \n4                             0.000000                         0.000000   \n\n   feature_agronomic_cryptal_advisor  feature_alkaline_pistachio_sunstone  \\\n0                           0.108258                             0.042904   \n1                           0.079645                             0.055798   \n2                           0.120615                             0.012530   \n3                           0.041099                             0.000000   \n4                           0.740971                             1.000000   \n\n   feature_altern_unnoticed_impregnation  feature_ambisexual_boiled_blunderer  \\\n0                               0.531423                             0.994126   \n1                               0.000000                             0.000000   \n2                               0.010341                             0.433381   \n3                               0.010843                             0.733748   \n4                               0.746225                             1.000000   \n\n   feature_amoebaean_wolfish_heeler  ...  target_paul_20  target_paul_60  \\\n0                          0.322113  ...            0.50            0.50   \n1                          0.000000  ...            0.50            0.50   \n2                          0.050186  ...            0.50            0.75   \n3                          0.477730  ...            0.75            0.50   \n4                          0.000000  ...            0.75            0.75   \n\n   target_george_20  target_george_60  target_william_20  target_william_60  \\\n0              0.75              0.75           0.666667           0.500000   \n1              0.25              0.25           0.500000           0.500000   \n2              0.75              0.50           0.666667           0.666667   \n3              0.50              0.50           0.500000           0.500000   \n4              0.75              0.75           0.666667           1.000000   \n\n   target_arthur_20  target_arthur_60  target_thomas_20  target_thomas_60  \n0          0.500000          0.500000          0.666667          0.666667  \n1          0.333333          0.333333          0.333333          0.333333  \n2          0.666667          0.666667          0.500000          0.666667  \n3          0.500000          0.333333          0.500000          0.500000  \n4          0.666667          0.833333          0.666667          0.666667  \n\n[5 rows x 441 columns]"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(synth_dataf.shape)\n",
    "synth_dataf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Improve Numerai performance with synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will demonstrate that `DeepDreamGenerator` will actually lead to better validation performance when the synthetic data is mixed with the original Numerai data. We hope to see more experiments by the Numerai community with v4 data, different feature sets, etc. Hope this section makes it easy for participants to get started and to setup up your own experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from numerblox.preprocessing import FeatureSelectionPreProcessor\n",
    "from numerblox.evaluation import NumeraiClassicEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = create_numerframe(\"synth_test/numerai_training_data.parquet\")\n",
    "val_dataf = create_numerframe(\"deepdream_eval_test/numerai_validation_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddg = DeepDreamGenerator(\"../test_assets/deepdream_model.h5\", batch_size=200_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a LightGBM model and evaluate the most common metrics for both original data and original data + ~5% synthetic data (500000 rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(dataf: NumerFrame, val_dataf: NumerFrame, feature_names: list):\n",
    "    \"\"\" Train LightGBM model with proper parameters and evaluate. \"\"\"\n",
    "    X_train, y_train = dataf.get_feature_target_pair(multi_target=False)\n",
    "    X_val, y_val = val_dataf.get_feature_target_pair(multi_target=False)\n",
    "    lgb_model = lgb.LGBMRegressor(random_state=42, n_estimators=2000, max_depth=5,\n",
    "                                  learning_rate=.01, colsample_bytree=.1)\n",
    "    X_train = NumerFrame(X_train[feature_names])\n",
    "    X_val = NumerFrame(X_val[feature_names])\n",
    "    lgb_model.fit(X_train, y_train)\n",
    "\n",
    "    X_val['prediction'] = lgb_model.predict(X_val)\n",
    "    X_val['era'] = val_dataf['era']\n",
    "    X_val['target'] = y_val\n",
    "    X_val['random_pred'] = np.random.uniform(len(y_val))\n",
    "\n",
    "    evaluator = NumeraiClassicEvaluator(fast_mode=True)\n",
    "    results = evaluator.full_evaluation(X_val, example_col=\"random_pred\",\n",
    "                                        target_col='target', pred_cols=['prediction'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As reference, We train a LightGBM model on the medium feature set with no added synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: 'v4/fncv3_features' are not present in the DataFrame. Falling back on 'v3/medium' features.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c0be21074c46ee93dea4f1d580dd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Evaluation:   0%|          | 0/1 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 12:47:03,481 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-05-05 12:47:03,483 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "results = train_and_evaluate(dataf, val_dataf, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`FeatureSelectionPreProcessor` selects features and keep all other columns, like target, era and data type. We will use this to filter on the medium feature set. Then we randomly take 500000 rows to generate synthetic data on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">FeatureSelectionPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2412105</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">443</span><span style=\"font-weight: bold\">)</span>. Time taken for \nstep: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:03</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">329357</span>. ✅\n</pre>\n",
      "text/plain": "✅ Finished step \u001b[1mFeatureSelectionPreProcessor\u001b[0m. Output \u001b[33mshape\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m2412105\u001b[0m, \u001b[1;36m443\u001b[0m\u001b[1m)\u001b[0m. Time taken for \nstep: \u001b[1;34m0:00:03\u001b[0m\u001b[34m.\u001b[0m\u001b[1;34m329357\u001b[0m. ✅\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_dataf_dream = FeatureSelectionPreProcessor(feature_cols=feature_names)(dataf)\n",
    "sample_dataf_dream = sample_dataf_dream.sample(500_000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple call to the `DeepDreamGenerator` will generate a full new dataset from the input DataFrame. In this case, we generate 500000 new rows and add it to our full Numerai v3 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e169d0508b4a5f88b1eed652535173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Deepdreaming Synthetic Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_dream_dataf = ddg.get_synthetic_batch(sample_dataf_dream)\n",
    "dream_dataf = pd.concat([dataf, sample_dream_dataf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train on the full dataset again with 500000 additional synthetic rows and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: 'v4/fncv3_features' are not present in the DataFrame. Falling back on 'v3/medium' features.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b68db8c4fb74497a586f18a77b5bd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Evaluation:   0%|          | 0/1 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dream_results = train_and_evaluate(dream_dataf, val_dataf,\n",
    "                                   feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>sharpe</th>\n      <th>max_drawdown</th>\n      <th>apy</th>\n      <th>mmc_mean</th>\n      <th>mmc_std</th>\n      <th>mmc_sharpe</th>\n      <th>corr_with_example_preds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>prediction</th>\n      <td>target</td>\n      <td>0.020226</td>\n      <td>0.032328</td>\n      <td>0.625658</td>\n      <td>-0.192148</td>\n      <td>155.268204</td>\n      <td>0.015526</td>\n      <td>0.024817</td>\n      <td>0.62565</td>\n      <td>-3.130347e-19</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "            target      mean       std    sharpe  max_drawdown         apy  \\\nprediction  target  0.020226  0.032328  0.625658     -0.192148  155.268204   \n\n            mmc_mean   mmc_std  mmc_sharpe  corr_with_example_preds  \nprediction  0.015526  0.024817     0.62565            -3.130347e-19  "
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>sharpe</th>\n      <th>max_drawdown</th>\n      <th>apy</th>\n      <th>mmc_mean</th>\n      <th>mmc_std</th>\n      <th>mmc_sharpe</th>\n      <th>corr_with_example_preds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>prediction</th>\n      <td>target</td>\n      <td>0.020592</td>\n      <td>0.030987</td>\n      <td>0.664546</td>\n      <td>-0.182301</td>\n      <td>160.191965</td>\n      <td>0.015807</td>\n      <td>0.023788</td>\n      <td>0.664535</td>\n      <td>-3.072266e-18</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "            target      mean       std    sharpe  max_drawdown         apy  \\\nprediction  target  0.020592  0.030987  0.664546     -0.182301  160.191965   \n\n            mmc_mean   mmc_std  mmc_sharpe  corr_with_example_preds  \nprediction  0.015807  0.023788    0.664535            -3.072266e-18  "
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dream_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with the added synthetic data the mean correlation improves, along with a higher Sharpe and lower max. drawdown. There seems to be a sweet spot when mixing in synthetic data. Add too little and no significant improvement occurs, but adding too much synthetic data can also hurt performance. You can play with this for yourself. Also try to adjust the `steps` and `step_size` parameters in `DeepDreamGenerator`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. UMAPFeatureGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP is a feature reduction technique that can be used to generate synthetic features. In other words, we create new representations of the existing features and add them to our dataset.\n",
    "\n",
    "We will perform UMAP on the training and validation data combined. Note that the data created with `DeepDreamGenerator` is included in this dataset. Then, once again we train a model on it and evaluate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numerblox.preprocessing import UMAPFeatureGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`n_components` denotes the amount of additional features we are generating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 3\n",
    "umap_gen = UMAPFeatureGenerator(n_components=n_components, n_neighbors=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = create_numerframe(\"../test_assets/mini_numerai_version_2_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #271: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "test_data = umap_gen(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new features follow the naming convention `f\"feature_umap_{i}\"`. All new components are scaled between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_umap_0</th>\n      <th>feature_umap_1</th>\n      <th>feature_umap_2</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>0.887313</td>\n      <td>0.365509</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>1.000000</td>\n      <td>0.779677</td>\n      <td>0.732083</td>\n    </tr>\n    <tr>\n      <th>nb64f06d3a9fc9f1</th>\n      <td>0.879256</td>\n      <td>0.073302</td>\n      <td>0.174605</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                  feature_umap_0  feature_umap_1  feature_umap_2\nid                                                              \nn559bd06a8861222        0.887313        0.365509        1.000000\nn9d39dea58c9e3cf        1.000000        0.779677        0.732083\nnb64f06d3a9fc9f1        0.879256        0.073302        0.174605"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_features = [f\"feature_umap_{i}\" for i in range(n_components)]\n",
    "test_data[umap_features].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrast this with the deep dream results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you're done all the downloaded files can be cleaned up with `.remove_base_directory()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">⚠ <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'NumeraiClassicDownloader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> ⚠\nPath: \n<span style=\"color: #008000; text-decoration-color: #008000\">'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/edu_nbs/synth_test'</span>\n</pre>\n",
      "text/plain": "⚠ \u001b[31mDeleting directory for \u001b[0m\u001b[31m'NumeraiClassicDownloader\u001b[0m\u001b[32m'\u001b[0m ⚠\nPath: \n\u001b[32m'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/edu_nbs/synth_test'\u001b[0m\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clean up environment\n",
    "dl.remove_base_directory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
