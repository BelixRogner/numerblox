{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"# hide\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_formatted_code = \"# hide\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"# default_exp preprocessing\";\n                var nbb_formatted_code = \"# default_exp preprocessing\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default_exp preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "> Feature/target selection, engineering and manipulation.\n",
    "\n",
    "## Overview\n",
    "This section provides functionality for all data manipulation steps that are needed before data is passed into a model for prediction. We group all these steps under Preprocessing. This includes feature/target selection, feature/target engineering and feature/target manipulation.\n",
    "\n",
    "Some preprocessors work with both Pandas DataFrames and NumerFrames. Most preprocessors use specific `NumerFrame` functionality.\n",
    "\n",
    "In the last section we explain how you can implement your own Preprocessor that integrates well with the rest of this framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_formatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"# export\\nimport os\\nimport time\\nimport warnings\\nimport numpy as np\\nimport pandas as pd\\nimport datetime as dt\\nfrom umap import UMAP\\nimport tensorflow as tf\\nfrom tqdm.auto import tqdm\\nfrom functools import wraps\\nfrom scipy.stats import rankdata\\nfrom typeguard import typechecked\\nfrom abc import ABC, abstractmethod\\nfrom rich import print as rich_print\\nfrom typing import Union, List, Tuple\\nfrom multiprocessing.pool import Pool\\nfrom sklearn.linear_model import Ridge\\nfrom sklearn.mixture import BayesianGaussianMixture\\nfrom sklearn.preprocessing import QuantileTransformer, MinMaxScaler\\n\\nfrom numerblox.download import NumeraiClassicDownloader\\nfrom numerblox.numerframe import NumerFrame, create_numerframe\";\n                var nbb_formatted_code = \"# export\\nimport os\\nimport time\\nimport warnings\\nimport numpy as np\\nimport pandas as pd\\nimport datetime as dt\\nfrom umap import UMAP\\nimport tensorflow as tf\\nfrom tqdm.auto import tqdm\\nfrom functools import wraps\\nfrom scipy.stats import rankdata\\nfrom typeguard import typechecked\\nfrom abc import ABC, abstractmethod\\nfrom rich import print as rich_print\\nfrom typing import Union, List, Tuple\\nfrom multiprocessing.pool import Pool\\nfrom sklearn.linear_model import Ridge\\nfrom sklearn.mixture import BayesianGaussianMixture\\nfrom sklearn.preprocessing import QuantileTransformer, MinMaxScaler\\n\\nfrom numerblox.download import NumeraiClassicDownloader\\nfrom numerblox.numerframe import NumerFrame, create_numerframe\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from umap import UMAP\n",
    "import tensorflow as tf\n",
    "from tqdm.auto import tqdm\n",
    "from functools import wraps\n",
    "from scipy.stats import rankdata\n",
    "from typeguard import typechecked\n",
    "from abc import ABC, abstractmethod\n",
    "from rich import print as rich_print\n",
    "from typing import Union, List, Tuple\n",
    "from multiprocessing.pool import Pool\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.preprocessing import QuantileTransformer, MinMaxScaler\n",
    "\n",
    "from numerblox.download import NumeraiClassicDownloader\n",
    "from numerblox.numerframe import NumerFrame, create_numerframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These objects will provide a base for all pre- and post-processing functionality and log relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. BaseProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BaseProcessor` defines common functionality for `preprocessing` and `postprocessing` (Section 5).\n",
    "\n",
    "Every Preprocessor should inherit from `BaseProcessor` and implement the `.transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"# export\\nclass BaseProcessor(ABC):\\n    \\\"\\\"\\\"Common functionality for preprocessors and postprocessors.\\\"\\\"\\\"\\n\\n    def __init__(self):\\n        ...\\n\\n    @abstractmethod\\n    def transform(\\n        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        ...\\n\\n    def __call__(\\n        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        return self.transform(dataf=dataf, *args, **kwargs)\";\n                var nbb_formatted_code = \"# export\\nclass BaseProcessor(ABC):\\n    \\\"\\\"\\\"Common functionality for preprocessors and postprocessors.\\\"\\\"\\\"\\n\\n    def __init__(self):\\n        ...\\n\\n    @abstractmethod\\n    def transform(\\n        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        ...\\n\\n    def __call__(\\n        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        return self.transform(dataf=dataf, *args, **kwargs)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class BaseProcessor(ABC):\n",
    "    \"\"\"Common functionality for preprocessors and postprocessors.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(\n",
    "        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\n",
    "    ) -> NumerFrame:\n",
    "        ...\n",
    "\n",
    "    def __call__(\n",
    "        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\n",
    "    ) -> NumerFrame:\n",
    "        return self.transform(dataf=dataf, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to keep an overview of which steps are done in a data pipeline and where processing bottlenecks occur.\n",
    "The decorator below will display for a given function/method:\n",
    "1. When it has finished.\n",
    "2. What the output shape of the data is.\n",
    "3. How long it took to finish.\n",
    "\n",
    "To use this functionality, simply add `@display_processor_info` as a decorator to the function/method you want to track.\n",
    "\n",
    "We will use this decorator throughout the pipeline (`preprocessing`, `model` and `postprocessing`).\n",
    "\n",
    "Inspiration for this decorator: [Calmcode Pandas Pipe Logs](https://calmcode.io/pandas-pipe/logs.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"# export\\ndef display_processor_info(func):\\n    \\\"\\\"\\\"Fancy console output for data processing.\\\"\\\"\\\"\\n\\n    @wraps(func)\\n    def wrapper(*args, **kwargs):\\n        tic = dt.datetime.now()\\n        result = func(*args, **kwargs)\\n        time_taken = str(dt.datetime.now() - tic)\\n        class_name = func.__qualname__.split(\\\".\\\")[0]\\n        rich_print(\\n            f\\\":white_check_mark: Finished step [bold]{class_name}[/bold]. Output shape={result.shape}. Time taken for step: [blue]{time_taken}[/blue]. :white_check_mark:\\\"\\n        )\\n        return result\\n\\n    return wrapper\";\n                var nbb_formatted_code = \"# export\\ndef display_processor_info(func):\\n    \\\"\\\"\\\"Fancy console output for data processing.\\\"\\\"\\\"\\n\\n    @wraps(func)\\n    def wrapper(*args, **kwargs):\\n        tic = dt.datetime.now()\\n        result = func(*args, **kwargs)\\n        time_taken = str(dt.datetime.now() - tic)\\n        class_name = func.__qualname__.split(\\\".\\\")[0]\\n        rich_print(\\n            f\\\":white_check_mark: Finished step [bold]{class_name}[/bold]. Output shape={result.shape}. Time taken for step: [blue]{time_taken}[/blue]. :white_check_mark:\\\"\\n        )\\n        return result\\n\\n    return wrapper\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def display_processor_info(func):\n",
    "    \"\"\"Fancy console output for data processing.\"\"\"\n",
    "\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        tic = dt.datetime.now()\n",
    "        result = func(*args, **kwargs)\n",
    "        time_taken = str(dt.datetime.now() - tic)\n",
    "        class_name = func.__qualname__.split(\".\")[0]\n",
    "        rich_print(\n",
    "            f\":white_check_mark: Finished step [bold]{class_name}[/bold]. Output shape={result.shape}. Time taken for step: [blue]{time_taken}[/blue]. :white_check_mark:\"\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mTestDisplay\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m314\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \u001B[1;34m0:00:02\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m000137\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">TestDisplay</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">314</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:02</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">000137</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                 id   era data_type  feature_intelligence1  \\\n0  n000315175b67977  era1     train                   0.00   \n1  n0014af834a96cdd  era1     train                   0.00   \n2  n001c93979ac41d4  era1     train                   0.25   \n3  n0034e4143f22a13  era1     train                   1.00   \n4  n00679d1a636062f  era1     train                   0.25   \n5  n009aa2d32389eca  era1     train                   0.50   \n6  n009ef1a5fe009b6  era1     train                   0.50   \n7  n00ae5d51f55fb0f  era1     train                   0.25   \n8  n00b0ac86d77aed7  era1     train                   0.50   \n9  n00c63366aeaf76a  era1     train                   0.50   \n\n   feature_intelligence2  feature_intelligence3  feature_intelligence4  \\\n0                   0.50                   0.25                   0.00   \n1                   0.00                   0.00                   0.25   \n2                   0.50                   0.25                   0.25   \n3                   0.00                   0.00                   0.50   \n4                   0.25                   0.25                   0.25   \n5                   0.50                   0.25                   0.25   \n6                   0.25                   0.25                   0.75   \n7                   1.00                   1.00                   0.75   \n8                   0.50                   0.50                   1.00   \n9                   1.00                   1.00                   0.25   \n\n   feature_intelligence5  feature_intelligence6  feature_intelligence7  ...  \\\n0                   0.50                   0.25                   0.25  ...   \n1                   0.50                   0.00                   0.00  ...   \n2                   1.00                   0.75                   0.75  ...   \n3                   0.50                   0.25                   0.25  ...   \n4                   0.00                   0.25                   0.50  ...   \n5                   0.75                   0.75                   0.75  ...   \n6                   1.00                   1.00                   1.00  ...   \n7                   1.00                   0.75                   0.75  ...   \n8                   1.00                   0.25                   0.50  ...   \n9                   0.75                   0.25                   0.25  ...   \n\n   feature_wisdom38  feature_wisdom39  feature_wisdom40  feature_wisdom41  \\\n0              1.00              1.00              0.75              0.50   \n1              1.00              1.00              0.00              0.00   \n2              0.25              0.50              0.00              0.00   \n3              1.00              1.00              0.75              0.75   \n4              0.75              0.75              0.25              0.50   \n5              0.75              0.75              0.00              0.00   \n6              1.00              1.00              0.50              0.50   \n7              0.50              0.25              0.75              0.75   \n8              0.00              0.00              0.00              0.00   \n9              0.00              0.00              1.00              1.00   \n\n   feature_wisdom42  feature_wisdom43  feature_wisdom44  feature_wisdom45  \\\n0              0.75              0.50              1.00              0.50   \n1              0.75              0.25              0.00              0.25   \n2              0.50              1.00              0.00              0.25   \n3              1.00              1.00              0.75              1.00   \n4              0.75              0.00              0.50              0.25   \n5              0.75              0.50              0.00              0.25   \n6              0.75              0.50              0.50              0.50   \n7              0.00              0.25              0.75              0.50   \n8              0.00              1.00              0.00              0.00   \n9              0.75              0.50              1.00              1.00   \n\n   feature_wisdom46  target  \n0              0.75    0.50  \n1              1.00    0.25  \n2              0.75    0.25  \n3              1.00    0.25  \n4              0.75    0.75  \n5              0.00    0.50  \n6              1.00    0.25  \n7              0.25    0.25  \n8              0.00    0.50  \n9              0.75    0.75  \n\n[10 rows x 314 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>era</th>\n      <th>data_type</th>\n      <th>feature_intelligence1</th>\n      <th>feature_intelligence2</th>\n      <th>feature_intelligence3</th>\n      <th>feature_intelligence4</th>\n      <th>feature_intelligence5</th>\n      <th>feature_intelligence6</th>\n      <th>feature_intelligence7</th>\n      <th>...</th>\n      <th>feature_wisdom38</th>\n      <th>feature_wisdom39</th>\n      <th>feature_wisdom40</th>\n      <th>feature_wisdom41</th>\n      <th>feature_wisdom42</th>\n      <th>feature_wisdom43</th>\n      <th>feature_wisdom44</th>\n      <th>feature_wisdom45</th>\n      <th>feature_wisdom46</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n000315175b67977</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n0014af834a96cdd</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>1.00</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>n001c93979ac41d4</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>...</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>n0034e4143f22a13</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n00679d1a636062f</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>n009aa2d32389eca</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>...</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>n009ef1a5fe009b6</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>n00ae5d51f55fb0f</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.25</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>n00b0ac86d77aed7</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>n00c63366aeaf76a</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.75</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 314 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"# hide_input\\nclass TestDisplay:\\n    \\\"\\\"\\\"\\n    Small test for logging.\\n    Output should mention 'TestDisplay',\\n    Return output shape of (10, 314) and\\n    time taken for step should be close to 2 seconds.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, dataf: NumerFrame):\\n        self.dataf = dataf\\n\\n    @display_processor_info\\n    def test(self) -> NumerFrame:\\n        time.sleep(2)\\n        return self.dataf\\n\\n\\ndataf = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\nTestDisplay(dataf).test()\";\n                var nbb_formatted_code = \"# hide_input\\nclass TestDisplay:\\n    \\\"\\\"\\\"\\n    Small test for logging.\\n    Output should mention 'TestDisplay',\\n    Return output shape of (10, 314) and\\n    time taken for step should be close to 2 seconds.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, dataf: NumerFrame):\\n        self.dataf = dataf\\n\\n    @display_processor_info\\n    def test(self) -> NumerFrame:\\n        time.sleep(2)\\n        return self.dataf\\n\\n\\ndataf = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\nTestDisplay(dataf).test()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_input\n",
    "class TestDisplay:\n",
    "    \"\"\"\n",
    "    Small test for logging.\n",
    "    Output should mention 'TestDisplay',\n",
    "    Return output shape of (10, 314) and\n",
    "    time taken for step should be close to 2 seconds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataf: NumerFrame):\n",
    "        self.dataf = dataf\n",
    "\n",
    "    @display_processor_info\n",
    "    def test(self) -> NumerFrame:\n",
    "        time.sleep(2)\n",
    "        return self.dataf\n",
    "\n",
    "\n",
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_1_data.csv\")\n",
    "TestDisplay(dataf).test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Common preprocessing steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section implements commonly used preprocessing for Numerai. We invite the Numerai community to develop new preprocessors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Tournament agnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessors that can be applied for both Numerai Classic and Numerai Signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.1. CopyPreProcessor\n",
    "\n",
    "The first and obvious preprocessor is copying, which is implemented as a default in `ModelPipeline` (Section 4) to avoid manipulation of the original DataFrame or `NumerFrame` that you load in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass CopyPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"Copy DataFrame to avoid manipulation of original DataFrame.\\\"\\\"\\\"\\n\\n    def __init__(self):\\n        super().__init__()\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        return NumerFrame(dataf.copy())\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass CopyPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"Copy DataFrame to avoid manipulation of original DataFrame.\\\"\\\"\\\"\\n\\n    def __init__(self):\\n        super().__init__()\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        return NumerFrame(dataf.copy())\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class CopyPreProcessor(BaseProcessor):\n",
    "    \"\"\"Copy DataFrame to avoid manipulation of original DataFrame.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        return NumerFrame(dataf.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mCopyPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m314\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m003063\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">CopyPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">314</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">003063</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"dataset = create_numerframe(\\n    \\\"test_assets/mini_numerai_version_1_data.csv\\\", metadata={\\\"version\\\": 1}\\n)\\ncopied_dataset = CopyPreProcessor().transform(dataset)\\nassert np.array_equal(copied_dataset.values, dataset.values)\\nassert dataset.meta == copied_dataset.meta\";\n                var nbb_formatted_code = \"dataset = create_numerframe(\\n    \\\"test_assets/mini_numerai_version_1_data.csv\\\", metadata={\\\"version\\\": 1}\\n)\\ncopied_dataset = CopyPreProcessor().transform(dataset)\\nassert np.array_equal(copied_dataset.values, dataset.values)\\nassert dataset.meta == copied_dataset.meta\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = create_numerframe(\n",
    "    \"test_assets/mini_numerai_version_1_data.csv\", metadata={\"version\": 1}\n",
    ")\n",
    "copied_dataset = CopyPreProcessor().transform(dataset)\n",
    "assert np.array_equal(copied_dataset.values, dataset.values)\n",
    "assert dataset.meta == copied_dataset.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.2. FeatureSelectionPreProcessor\n",
    "\n",
    "`FeatureSelectionPreProcessor` will keep all features that you pass + keeps all other columns that are not features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass FeatureSelectionPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Keep only features given + all target, predictions and aux columns.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, feature_cols: Union[str, list]):\\n        super().__init__()\\n        self.feature_cols = feature_cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        keep_cols = (\\n            self.feature_cols\\n            + dataf.target_cols\\n            + dataf.prediction_cols\\n            + dataf.aux_cols\\n        )\\n        dataf = dataf.loc[:, keep_cols]\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass FeatureSelectionPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Keep only features given + all target, predictions and aux columns.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, feature_cols: Union[str, list]):\\n        super().__init__()\\n        self.feature_cols = feature_cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        keep_cols = (\\n            self.feature_cols\\n            + dataf.target_cols\\n            + dataf.prediction_cols\\n            + dataf.aux_cols\\n        )\\n        dataf = dataf.loc[:, keep_cols]\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class FeatureSelectionPreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Keep only features given + all target, predictions and aux columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_cols: Union[str, list]):\n",
    "        super().__init__()\n",
    "        self.feature_cols = feature_cols\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        keep_cols = (\n",
    "            self.feature_cols\n",
    "            + dataf.target_cols\n",
    "            + dataf.prediction_cols\n",
    "            + dataf.aux_cols\n",
    "        )\n",
    "        dataf = dataf.loc[:, keep_cols]\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mFeatureSelectionPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m5\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m001201\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">FeatureSelectionPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">001201</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"selected_dataset = FeatureSelectionPreProcessor(\\n    feature_cols=[\\\"feature_wisdom1\\\"]\\n).transform(dataset)\\n\\nassert selected_dataset.get_feature_data.shape[1] == 1\\nassert dataset.meta == selected_dataset.meta\";\n                var nbb_formatted_code = \"selected_dataset = FeatureSelectionPreProcessor(\\n    feature_cols=[\\\"feature_wisdom1\\\"]\\n).transform(dataset)\\n\\nassert selected_dataset.get_feature_data.shape[1] == 1\\nassert dataset.meta == selected_dataset.meta\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_dataset = FeatureSelectionPreProcessor(\n",
    "    feature_cols=[\"feature_wisdom1\"]\n",
    ").transform(dataset)\n",
    "\n",
    "assert selected_dataset.get_feature_data.shape[1] == 1\n",
    "assert dataset.meta == selected_dataset.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   feature_wisdom1  target                id   era data_type\n0             0.25    0.50  n000315175b67977  era1     train\n1             0.50    0.25  n0014af834a96cdd  era1     train",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_wisdom1</th>\n      <th>target</th>\n      <th>id</th>\n      <th>era</th>\n      <th>data_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>n000315175b67977</td>\n      <td>era1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>n0014af834a96cdd</td>\n      <td>era1</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"selected_dataset.head(2)\";\n                var nbb_formatted_code = \"selected_dataset.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.3. TargetSelectionPreProcessor\n",
    "\n",
    "`TargetSelectionPreProcessor` will keep all targets that you pass + all other columns that are not targets.\n",
    "\n",
    "Not relevant for an inference pipeline, but especially convenient for Numerai Classic training if you train on a subset of the available targets. Can also be applied to Signals if you are using engineered targets in your pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass TargetSelectionPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Keep only features given + all target, predictions and aux columns.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, target_cols: Union[str, list]):\\n        super().__init__()\\n        self.target_cols = target_cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        keep_cols = (\\n            self.target_cols\\n            + dataf.feature_cols\\n            + dataf.prediction_cols\\n            + dataf.aux_cols\\n        )\\n        dataf = dataf.loc[:, keep_cols]\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass TargetSelectionPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Keep only features given + all target, predictions and aux columns.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, target_cols: Union[str, list]):\\n        super().__init__()\\n        self.target_cols = target_cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        keep_cols = (\\n            self.target_cols\\n            + dataf.feature_cols\\n            + dataf.prediction_cols\\n            + dataf.aux_cols\\n        )\\n        dataf = dataf.loc[:, keep_cols]\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class TargetSelectionPreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Keep only features given + all target, predictions and aux columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, target_cols: Union[str, list]):\n",
    "        super().__init__()\n",
    "        self.target_cols = target_cols\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        keep_cols = (\n",
    "            self.target_cols\n",
    "            + dataf.feature_cols\n",
    "            + dataf.prediction_cols\n",
    "            + dataf.aux_cols\n",
    "        )\n",
    "        dataf = dataf.loc[:, keep_cols]\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mTargetSelectionPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m1055\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m025614\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">TargetSelectionPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1055</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">025614</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                  target  target_nomi_20  target_nomi_60  \\\nid                                                         \nn559bd06a8861222    0.25            0.25            0.50   \nn9d39dea58c9e3cf    0.50            0.50            0.75   \n\n                  feature_dichasial_hammier_spawner  \\\nid                                                    \nn559bd06a8861222                               0.25   \nn9d39dea58c9e3cf                               0.75   \n\n                  feature_rheumy_epistemic_prancer  \\\nid                                                   \nn559bd06a8861222                              0.75   \nn9d39dea58c9e3cf                              0.50   \n\n                  feature_pert_performative_hormuz  \\\nid                                                   \nn559bd06a8861222                              0.25   \nn9d39dea58c9e3cf                              0.75   \n\n                  feature_hillier_unpitied_theobromine  \\\nid                                                       \nn559bd06a8861222                                  0.75   \nn9d39dea58c9e3cf                                  1.00   \n\n                  feature_perigean_bewitching_thruster  \\\nid                                                       \nn559bd06a8861222                                  0.25   \nn9d39dea58c9e3cf                                  0.50   \n\n                  feature_renegade_undomestic_milord  \\\nid                                                     \nn559bd06a8861222                                0.50   \nn9d39dea58c9e3cf                                0.25   \n\n                  feature_koranic_rude_corf  ...  \\\nid                                           ...   \nn559bd06a8861222                        1.0  ...   \nn9d39dea58c9e3cf                        0.5  ...   \n\n                  feature_drawable_exhortative_dispersant  \\\nid                                                          \nn559bd06a8861222                                     1.00   \nn9d39dea58c9e3cf                                     0.25   \n\n                  feature_metabolic_minded_armorist  \\\nid                                                    \nn559bd06a8861222                                0.0   \nn9d39dea58c9e3cf                                0.5   \n\n                  feature_investigatory_inerasable_circumvallation  \\\nid                                                                   \nn559bd06a8861222                                               0.0   \nn9d39dea58c9e3cf                                               0.0   \n\n                  feature_centroclinal_incentive_lancelet  \\\nid                                                          \nn559bd06a8861222                                     0.25   \nn9d39dea58c9e3cf                                     0.25   \n\n                  feature_unemotional_quietistic_chirper  \\\nid                                                         \nn559bd06a8861222                                    0.00   \nn9d39dea58c9e3cf                                    0.75   \n\n                  feature_behaviorist_microbiological_farina  \\\nid                                                             \nn559bd06a8861222                                         0.0   \nn9d39dea58c9e3cf                                         1.0   \n\n                  feature_lofty_acceptable_challenge  \\\nid                                                     \nn559bd06a8861222                                1.00   \nn9d39dea58c9e3cf                                0.75   \n\n                  feature_coactive_prefatorial_lucy   era  data_type  \nid                                                                    \nn559bd06a8861222                               0.25  0297      train  \nn9d39dea58c9e3cf                               1.00  0003      train  \n\n[2 rows x 1055 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>target_nomi_20</th>\n      <th>target_nomi_60</th>\n      <th>feature_dichasial_hammier_spawner</th>\n      <th>feature_rheumy_epistemic_prancer</th>\n      <th>feature_pert_performative_hormuz</th>\n      <th>feature_hillier_unpitied_theobromine</th>\n      <th>feature_perigean_bewitching_thruster</th>\n      <th>feature_renegade_undomestic_milord</th>\n      <th>feature_koranic_rude_corf</th>\n      <th>...</th>\n      <th>feature_drawable_exhortative_dispersant</th>\n      <th>feature_metabolic_minded_armorist</th>\n      <th>feature_investigatory_inerasable_circumvallation</th>\n      <th>feature_centroclinal_incentive_lancelet</th>\n      <th>feature_unemotional_quietistic_chirper</th>\n      <th>feature_behaviorist_microbiological_farina</th>\n      <th>feature_lofty_acceptable_challenge</th>\n      <th>feature_coactive_prefatorial_lucy</th>\n      <th>era</th>\n      <th>data_type</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>0.25</td>\n      <td>0297</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0003</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 1055 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"dataset = create_numerframe(\\n    \\\"test_assets/mini_numerai_version_2_data.parquet\\\", metadata={\\\"version\\\": 2}\\n)\\ntarget_cols = [\\\"target\\\", \\\"target_nomi_20\\\", \\\"target_nomi_60\\\"]\\nselected_dataset = TargetSelectionPreProcessor(target_cols=target_cols).transform(\\n    dataset\\n)\\nassert selected_dataset.get_target_data.shape[1] == len(target_cols)\\nselected_dataset.head(2)\";\n                var nbb_formatted_code = \"dataset = create_numerframe(\\n    \\\"test_assets/mini_numerai_version_2_data.parquet\\\", metadata={\\\"version\\\": 2}\\n)\\ntarget_cols = [\\\"target\\\", \\\"target_nomi_20\\\", \\\"target_nomi_60\\\"]\\nselected_dataset = TargetSelectionPreProcessor(target_cols=target_cols).transform(\\n    dataset\\n)\\nassert selected_dataset.get_target_data.shape[1] == len(target_cols)\\nselected_dataset.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = create_numerframe(\n",
    "    \"test_assets/mini_numerai_version_2_data.parquet\", metadata={\"version\": 2}\n",
    ")\n",
    "target_cols = [\"target\", \"target_nomi_20\", \"target_nomi_60\"]\n",
    "selected_dataset = TargetSelectionPreProcessor(target_cols=target_cols).transform(\n",
    "    dataset\n",
    ")\n",
    "assert selected_dataset.get_target_data.shape[1] == len(target_cols)\n",
    "selected_dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.4. ReduceMemoryProcessor\n",
    "\n",
    "Numerai datasets can take up a lot of RAM and may put a strain on your compute environment.\n",
    "\n",
    "For Numerai Classic, many of the feature and target columns can be downscaled to `float16`. `int8` if you are using the Numerai int8 datasets. For Signals it depends on the features you are generating.\n",
    "\n",
    "`ReduceMemoryProcessor` downscales the type of your numeric columns to reduce the memory footprint as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 15;\n                var nbb_unformatted_code = \"# export\\nclass ReduceMemoryProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Reduce memory usage as much as possible.\\n\\n    Credits to kainsama and others for writing about memory usage reduction for Numerai data:\\n    https://forum.numer.ai/t/reducing-memory/313\\n\\n    :param deep_mem_inspect: Introspect the data deeply by interrogating object dtypes.\\n    Yields a more accurate representation of memory usage if you have complex object columns.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, deep_mem_inspect=False):\\n        super().__init__()\\n        self.deep_mem_inspect = deep_mem_inspect\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        dataf = self._reduce_mem_usage(dataf)\\n        return NumerFrame(dataf)\\n\\n    def _reduce_mem_usage(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Iterate through all columns and modify the numeric column types\\n        to reduce memory usage.\\n        \\\"\\\"\\\"\\n        start_memory_usage = (\\n            dataf.memory_usage(deep=self.deep_mem_inspect).sum() / 1024**2\\n        )\\n        rich_print(\\n            f\\\"Memory usage of DataFrame is [bold]{round(start_memory_usage, 2)} MB[/bold]\\\"\\n        )\\n\\n        for col in dataf.columns:\\n            col_type = dataf[col].dtype.name\\n\\n            if col_type not in [\\n                \\\"object\\\",\\n                \\\"category\\\",\\n                \\\"datetime64[ns, UTC]\\\",\\n                \\\"datetime64[ns]\\\",\\n            ]:\\n                c_min = dataf[col].min()\\n                c_max = dataf[col].max()\\n                if str(col_type)[:3] == \\\"int\\\":\\n                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\\n                        dataf[col] = dataf[col].astype(np.int16)\\n                    elif (\\n                        c_min > np.iinfo(np.int16).min\\n                        and c_max < np.iinfo(np.int16).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.int16)\\n                    elif (\\n                        c_min > np.iinfo(np.int32).min\\n                        and c_max < np.iinfo(np.int32).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.int32)\\n                    elif (\\n                        c_min > np.iinfo(np.int64).min\\n                        and c_max < np.iinfo(np.int64).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.int64)\\n                else:\\n                    if (\\n                        c_min > np.finfo(np.float16).min\\n                        and c_max < np.finfo(np.float16).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.float16)\\n                    elif (\\n                        c_min > np.finfo(np.float32).min\\n                        and c_max < np.finfo(np.float32).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.float32)\\n                    else:\\n                        dataf[col] = dataf[col].astype(np.float64)\\n\\n        end_memory_usage = (\\n            dataf.memory_usage(deep=self.deep_mem_inspect).sum() / 1024**2\\n        )\\n        rich_print(\\n            f\\\"Memory usage after optimization is: [bold]{round(end_memory_usage, 2)} MB[/bold]\\\"\\n        )\\n        rich_print(\\n            f\\\"[green] Usage decreased by [bold]{round(100 * (start_memory_usage - end_memory_usage) / start_memory_usage, 2)}%[/bold][/green]\\\"\\n        )\\n        return dataf\";\n                var nbb_formatted_code = \"# export\\nclass ReduceMemoryProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Reduce memory usage as much as possible.\\n\\n    Credits to kainsama and others for writing about memory usage reduction for Numerai data:\\n    https://forum.numer.ai/t/reducing-memory/313\\n\\n    :param deep_mem_inspect: Introspect the data deeply by interrogating object dtypes.\\n    Yields a more accurate representation of memory usage if you have complex object columns.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, deep_mem_inspect=False):\\n        super().__init__()\\n        self.deep_mem_inspect = deep_mem_inspect\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        dataf = self._reduce_mem_usage(dataf)\\n        return NumerFrame(dataf)\\n\\n    def _reduce_mem_usage(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Iterate through all columns and modify the numeric column types\\n        to reduce memory usage.\\n        \\\"\\\"\\\"\\n        start_memory_usage = (\\n            dataf.memory_usage(deep=self.deep_mem_inspect).sum() / 1024 ** 2\\n        )\\n        rich_print(\\n            f\\\"Memory usage of DataFrame is [bold]{round(start_memory_usage, 2)} MB[/bold]\\\"\\n        )\\n\\n        for col in dataf.columns:\\n            col_type = dataf[col].dtype.name\\n\\n            if col_type not in [\\n                \\\"object\\\",\\n                \\\"category\\\",\\n                \\\"datetime64[ns, UTC]\\\",\\n                \\\"datetime64[ns]\\\",\\n            ]:\\n                c_min = dataf[col].min()\\n                c_max = dataf[col].max()\\n                if str(col_type)[:3] == \\\"int\\\":\\n                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\\n                        dataf[col] = dataf[col].astype(np.int16)\\n                    elif (\\n                        c_min > np.iinfo(np.int16).min\\n                        and c_max < np.iinfo(np.int16).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.int16)\\n                    elif (\\n                        c_min > np.iinfo(np.int32).min\\n                        and c_max < np.iinfo(np.int32).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.int32)\\n                    elif (\\n                        c_min > np.iinfo(np.int64).min\\n                        and c_max < np.iinfo(np.int64).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.int64)\\n                else:\\n                    if (\\n                        c_min > np.finfo(np.float16).min\\n                        and c_max < np.finfo(np.float16).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.float16)\\n                    elif (\\n                        c_min > np.finfo(np.float32).min\\n                        and c_max < np.finfo(np.float32).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.float32)\\n                    else:\\n                        dataf[col] = dataf[col].astype(np.float64)\\n\\n        end_memory_usage = (\\n            dataf.memory_usage(deep=self.deep_mem_inspect).sum() / 1024 ** 2\\n        )\\n        rich_print(\\n            f\\\"Memory usage after optimization is: [bold]{round(end_memory_usage, 2)} MB[/bold]\\\"\\n        )\\n        rich_print(\\n            f\\\"[green] Usage decreased by [bold]{round(100 * (start_memory_usage - end_memory_usage) / start_memory_usage, 2)}%[/bold][/green]\\\"\\n        )\\n        return dataf\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class ReduceMemoryProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Reduce memory usage as much as possible.\n",
    "\n",
    "    Credits to kainsama and others for writing about memory usage reduction for Numerai data:\n",
    "    https://forum.numer.ai/t/reducing-memory/313\n",
    "\n",
    "    :param deep_mem_inspect: Introspect the data deeply by interrogating object dtypes.\n",
    "    Yields a more accurate representation of memory usage if you have complex object columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, deep_mem_inspect=False):\n",
    "        super().__init__()\n",
    "        self.deep_mem_inspect = deep_mem_inspect\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        dataf = self._reduce_mem_usage(dataf)\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def _reduce_mem_usage(self, dataf: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Iterate through all columns and modify the numeric column types\n",
    "        to reduce memory usage.\n",
    "        \"\"\"\n",
    "        start_memory_usage = (\n",
    "            dataf.memory_usage(deep=self.deep_mem_inspect).sum() / 1024**2\n",
    "        )\n",
    "        rich_print(\n",
    "            f\"Memory usage of DataFrame is [bold]{round(start_memory_usage, 2)} MB[/bold]\"\n",
    "        )\n",
    "\n",
    "        for col in dataf.columns:\n",
    "            col_type = dataf[col].dtype.name\n",
    "\n",
    "            if col_type not in [\n",
    "                \"object\",\n",
    "                \"category\",\n",
    "                \"datetime64[ns, UTC]\",\n",
    "                \"datetime64[ns]\",\n",
    "            ]:\n",
    "                c_min = dataf[col].min()\n",
    "                c_max = dataf[col].max()\n",
    "                if str(col_type)[:3] == \"int\":\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        dataf[col] = dataf[col].astype(np.int16)\n",
    "                    elif (\n",
    "                        c_min > np.iinfo(np.int16).min\n",
    "                        and c_max < np.iinfo(np.int16).max\n",
    "                    ):\n",
    "                        dataf[col] = dataf[col].astype(np.int16)\n",
    "                    elif (\n",
    "                        c_min > np.iinfo(np.int32).min\n",
    "                        and c_max < np.iinfo(np.int32).max\n",
    "                    ):\n",
    "                        dataf[col] = dataf[col].astype(np.int32)\n",
    "                    elif (\n",
    "                        c_min > np.iinfo(np.int64).min\n",
    "                        and c_max < np.iinfo(np.int64).max\n",
    "                    ):\n",
    "                        dataf[col] = dataf[col].astype(np.int64)\n",
    "                else:\n",
    "                    if (\n",
    "                        c_min > np.finfo(np.float16).min\n",
    "                        and c_max < np.finfo(np.float16).max\n",
    "                    ):\n",
    "                        dataf[col] = dataf[col].astype(np.float16)\n",
    "                    elif (\n",
    "                        c_min > np.finfo(np.float32).min\n",
    "                        and c_max < np.finfo(np.float32).max\n",
    "                    ):\n",
    "                        dataf[col] = dataf[col].astype(np.float32)\n",
    "                    else:\n",
    "                        dataf[col] = dataf[col].astype(np.float64)\n",
    "\n",
    "        end_memory_usage = (\n",
    "            dataf.memory_usage(deep=self.deep_mem_inspect).sum() / 1024**2\n",
    "        )\n",
    "        rich_print(\n",
    "            f\"Memory usage after optimization is: [bold]{round(end_memory_usage, 2)} MB[/bold]\"\n",
    "        )\n",
    "        rich_print(\n",
    "            f\"[green] Usage decreased by [bold]{round(100 * (start_memory_usage - end_memory_usage) / start_memory_usage, 2)}%[/bold][/green]\"\n",
    "        )\n",
    "        return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Memory usage of DataFrame is \u001B[1;36m0.04\u001B[0m\u001B[1m MB\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory usage of DataFrame is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.04</span><span style=\"font-weight: bold\"> MB</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Memory usage after optimization is: \u001B[1;36m0.02\u001B[0m\u001B[1m MB\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory usage after optimization is: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span><span style=\"font-weight: bold\"> MB</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[32m Usage decreased by \u001B[0m\u001B[1;32m49.72\u001B[0m\u001B[1;32m%\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\"> Usage decreased by </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">49.72</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">%</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mReduceMemoryProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m1073\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m782609\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">ReduceMemoryProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1073</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">782609</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"dataf = create_numerframe(\\\"test_assets/mini_numerai_version_2_data.parquet\\\")\\nrmp = ReduceMemoryProcessor()\\ndataf = rmp.transform(dataf)\";\n                var nbb_formatted_code = \"dataf = create_numerframe(\\\"test_assets/mini_numerai_version_2_data.parquet\\\")\\nrmp = ReduceMemoryProcessor()\\ndataf = rmp.transform(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_2_data.parquet\")\n",
    "rmp = ReduceMemoryProcessor()\n",
    "dataf = rmp.transform(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                   era data_type  feature_dichasial_hammier_spawner  \\\nid                                                                    \nn559bd06a8861222  0297     train                               0.25   \nn9d39dea58c9e3cf  0003     train                               0.75   \n\n                  feature_rheumy_epistemic_prancer  \\\nid                                                   \nn559bd06a8861222                              0.75   \nn9d39dea58c9e3cf                              0.50   \n\n                  feature_pert_performative_hormuz  \\\nid                                                   \nn559bd06a8861222                              0.25   \nn9d39dea58c9e3cf                              0.75   \n\n                  feature_hillier_unpitied_theobromine  \\\nid                                                       \nn559bd06a8861222                                  0.75   \nn9d39dea58c9e3cf                                  1.00   \n\n                  feature_perigean_bewitching_thruster  \\\nid                                                       \nn559bd06a8861222                                  0.25   \nn9d39dea58c9e3cf                                  0.50   \n\n                  feature_renegade_undomestic_milord  \\\nid                                                     \nn559bd06a8861222                                0.50   \nn9d39dea58c9e3cf                                0.25   \n\n                  feature_koranic_rude_corf  \\\nid                                            \nn559bd06a8861222                        1.0   \nn9d39dea58c9e3cf                        0.5   \n\n                  feature_demisable_expiring_millepede  ...  target_paul_20  \\\nid                                                      ...                   \nn559bd06a8861222                                  0.25  ...             0.0   \nn9d39dea58c9e3cf                                  0.00  ...             0.5   \n\n                  target_paul_60  target_george_20  target_george_60  \\\nid                                                                     \nn559bd06a8861222            0.50              0.25               0.5   \nn9d39dea58c9e3cf            0.75              0.50               0.5   \n\n                  target_william_20  target_william_60  target_arthur_20  \\\nid                                                                         \nn559bd06a8861222           0.000000           0.500000          0.166626   \nn9d39dea58c9e3cf           0.666504           0.666504          0.500000   \n\n                  target_arthur_60  target_thomas_20  target_thomas_60  \nid                                                                      \nn559bd06a8861222          0.500000          0.333252          0.500000  \nn9d39dea58c9e3cf          0.666504          0.500000          0.666504  \n\n[2 rows x 1073 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>era</th>\n      <th>data_type</th>\n      <th>feature_dichasial_hammier_spawner</th>\n      <th>feature_rheumy_epistemic_prancer</th>\n      <th>feature_pert_performative_hormuz</th>\n      <th>feature_hillier_unpitied_theobromine</th>\n      <th>feature_perigean_bewitching_thruster</th>\n      <th>feature_renegade_undomestic_milord</th>\n      <th>feature_koranic_rude_corf</th>\n      <th>feature_demisable_expiring_millepede</th>\n      <th>...</th>\n      <th>target_paul_20</th>\n      <th>target_paul_60</th>\n      <th>target_george_20</th>\n      <th>target_george_60</th>\n      <th>target_william_20</th>\n      <th>target_william_60</th>\n      <th>target_arthur_20</th>\n      <th>target_arthur_60</th>\n      <th>target_thomas_20</th>\n      <th>target_thomas_60</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>0297</td>\n      <td>train</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>1.0</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.166626</td>\n      <td>0.500000</td>\n      <td>0.333252</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>0003</td>\n      <td>train</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.5</td>\n      <td>0.666504</td>\n      <td>0.666504</td>\n      <td>0.500000</td>\n      <td>0.666504</td>\n      <td>0.500000</td>\n      <td>0.666504</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 1073 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 17;\n                var nbb_unformatted_code = \"# hide\\ndataf.head(2)\";\n                var nbb_formatted_code = \"# hide\\ndataf.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "dataf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.5. DeepDreamDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best known for its computer vision applications, DeepDream excites activations in a trained model to augment original input. It uses sevral steps of gradient ascent to achieve this. Numerai participant [nyuton (nemethpeti on Github)](https://github.com/nemethpeti/numerai/blob/main/DeepDream/deepdream.py) implemented a way to apply this technique on Numerai data. Therefore, it allows us to generate synthetic training data. Check out `nbs/edu_nbs/synthetic_data_generation.ipynb` for experiments that demonstrate the effectiveness of using this additional data for training Numerai models.\n",
    "\n",
    "![](https://b2h3x3f6.stackpathcdn.com/assets/landing/img/gallery/4.jpg)\n",
    "Source: Example of image generated with DeepDream (deepdreamgenerator.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"# export\\nclass DeepDreamGenerator(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Generate synthetic eras using DeepDream technique. \\\\n\\n    Based on implementation by nemethpeti: \\\\n\\n    https://github.com/nemethpeti/numerai/blob/main/DeepDream/deepdream.py\\n\\n    :param model_path: Path to trained DeepDream model. Example can be downloaded from \\\\n\\n    https://github.com/nemethpeti/numerai/blob/main/DeepDream/model.h5 \\\\n\\n    :param batch_size: How much synthetic data to process in each batch. \\\\n\\n    :param steps: Number of gradient ascent steps to perform. More steps will lead to more augmentation. \\\\n\\n    :param step_size: How much to augment the batch based on computed gradients. \\\\n\\n    Like with the number of steps, a larger step size will lead to more dramatic changes to the input features. \\\\n\\n    The default parameters are found to work well in practice, but could be further optimized.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        model_path: str,\\n        batch_size: int = 200_000,\\n        steps: int = 5,\\n        step_size: float = 0.01,\\n        feature_names: list = None,\\n    ):\\n        super().__init__()\\n        tf.config.run_functions_eagerly(True)\\n        self.model_path = model_path\\n        self.model = self.__load_model(self.model_path)\\n\\n        self.batch_size = batch_size\\n        self.steps = steps\\n        self.step_size = step_size\\n\\n        self.feature_names = feature_names\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        dream_dataf = self.get_synthetic_batch(dataf)\\n        dataf = pd.concat([dataf, dream_dataf])\\n        return NumerFrame(dataf)\\n\\n    def get_synthetic_batch(self, dataf: NumerFrame) -> NumerFrame:\\n        \\\"\\\"\\\"\\n        Produce a synthetic version of the full input dataset.\\n        Target features will stay the same as in the original input data.\\n        \\\"\\\"\\\"\\n        features = self.feature_names if self.feature_names else dataf.feature_cols\\n        targets = dataf.target_cols\\n\\n        dream_dataf = pd.DataFrame(columns=features)\\n        for i in tqdm(\\n            np.arange(0, len(dataf), self.batch_size),\\n            desc=\\\"Deepdreaming Synthetic Batches\\\",\\n        ):\\n            start = i\\n            end = np.minimum(i + self.batch_size - 1, len(dataf) - 1)\\n            sub_dataf = dataf.reset_index(drop=False).iloc[start:end]\\n            batch = tf.convert_to_tensor(\\n                sub_dataf.loc[:, features].astype(np.float32).values\\n            )\\n\\n            dream_arr = self._dream(batch)\\n            batch_dataf = pd.DataFrame(dream_arr, columns=features)\\n            batch_dataf[targets] = sub_dataf[targets]\\n\\n            dream_dataf = pd.concat([dream_dataf, batch_dataf])\\n        return NumerFrame(dream_dataf)\\n\\n    def _dream(self, batch: tf.Tensor) -> np.ndarray:\\n        \\\"\\\"\\\"\\n        Perform gradient ascent on batch of data.\\n        This loop perturbs the original features to create synthetic data.\\n        \\\"\\\"\\\"\\n        for _ in tf.range(self.steps):\\n            with tf.GradientTape() as tape:\\n                tape.watch(batch)\\n                layer_activations = self.model(batch)\\n                loss = tf.math.reduce_mean(layer_activations, -1)\\n\\n            gradients = tape.gradient(loss, batch)\\n            gradients /= tf.expand_dims(tf.math.reduce_std(gradients, -1), 1) + 1e-8\\n\\n            # In gradient ascent, the \\\"loss\\\" is maximized so that the input row increasingly \\\"excites\\\" the layers.\\n            batch = batch + gradients * self.step_size\\n        batch = tf.clip_by_value(batch, 0, 1)\\n        return batch.numpy()\\n\\n    @staticmethod\\n    def __load_model(\\n        model_path: str, output_layer_name: str = \\\"concat\\\"\\n    ) -> tf.keras.Model:\\n        \\\"\\\"\\\"\\n        Load in Keras model from given path.\\n        output_layer_name will be the layer used to augment data.\\n        \\\"\\\"\\\"\\n        base_model = tf.keras.models.load_model(model_path)\\n        base_model.compile(run_eagerly=True)\\n        # Maximize the activations of these layers\\n        layers = base_model.get_layer(output_layer_name).output\\n        # Create the feature extraction model\\n        dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)\\n        return dream_model\";\n                var nbb_formatted_code = \"# export\\nclass DeepDreamGenerator(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Generate synthetic eras using DeepDream technique. \\\\n\\n    Based on implementation by nemethpeti: \\\\n\\n    https://github.com/nemethpeti/numerai/blob/main/DeepDream/deepdream.py\\n\\n    :param model_path: Path to trained DeepDream model. Example can be downloaded from \\\\n\\n    https://github.com/nemethpeti/numerai/blob/main/DeepDream/model.h5 \\\\n\\n    :param batch_size: How much synthetic data to process in each batch. \\\\n\\n    :param steps: Number of gradient ascent steps to perform. More steps will lead to more augmentation. \\\\n\\n    :param step_size: How much to augment the batch based on computed gradients. \\\\n\\n    Like with the number of steps, a larger step size will lead to more dramatic changes to the input features. \\\\n\\n    The default parameters are found to work well in practice, but could be further optimized.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        model_path: str,\\n        batch_size: int = 200_000,\\n        steps: int = 5,\\n        step_size: float = 0.01,\\n        feature_names: list = None,\\n    ):\\n        super().__init__()\\n        tf.config.run_functions_eagerly(True)\\n        self.model_path = model_path\\n        self.model = self.__load_model(self.model_path)\\n\\n        self.batch_size = batch_size\\n        self.steps = steps\\n        self.step_size = step_size\\n\\n        self.feature_names = feature_names\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        dream_dataf = self.get_synthetic_batch(dataf)\\n        dataf = pd.concat([dataf, dream_dataf])\\n        return NumerFrame(dataf)\\n\\n    def get_synthetic_batch(self, dataf: NumerFrame) -> NumerFrame:\\n        \\\"\\\"\\\"\\n        Produce a synthetic version of the full input dataset.\\n        Target features will stay the same as in the original input data.\\n        \\\"\\\"\\\"\\n        features = self.feature_names if self.feature_names else dataf.feature_cols\\n        targets = dataf.target_cols\\n\\n        dream_dataf = pd.DataFrame(columns=features)\\n        for i in tqdm(\\n            np.arange(0, len(dataf), self.batch_size),\\n            desc=\\\"Deepdreaming Synthetic Batches\\\",\\n        ):\\n            start = i\\n            end = np.minimum(i + self.batch_size - 1, len(dataf) - 1)\\n            sub_dataf = dataf.reset_index(drop=False).iloc[start:end]\\n            batch = tf.convert_to_tensor(\\n                sub_dataf.loc[:, features].astype(np.float32).values\\n            )\\n\\n            dream_arr = self._dream(batch)\\n            batch_dataf = pd.DataFrame(dream_arr, columns=features)\\n            batch_dataf[targets] = sub_dataf[targets]\\n\\n            dream_dataf = pd.concat([dream_dataf, batch_dataf])\\n        return NumerFrame(dream_dataf)\\n\\n    def _dream(self, batch: tf.Tensor) -> np.ndarray:\\n        \\\"\\\"\\\"\\n        Perform gradient ascent on batch of data.\\n        This loop perturbs the original features to create synthetic data.\\n        \\\"\\\"\\\"\\n        for _ in tf.range(self.steps):\\n            with tf.GradientTape() as tape:\\n                tape.watch(batch)\\n                layer_activations = self.model(batch)\\n                loss = tf.math.reduce_mean(layer_activations, -1)\\n\\n            gradients = tape.gradient(loss, batch)\\n            gradients /= tf.expand_dims(tf.math.reduce_std(gradients, -1), 1) + 1e-8\\n\\n            # In gradient ascent, the \\\"loss\\\" is maximized so that the input row increasingly \\\"excites\\\" the layers.\\n            batch = batch + gradients * self.step_size\\n        batch = tf.clip_by_value(batch, 0, 1)\\n        return batch.numpy()\\n\\n    @staticmethod\\n    def __load_model(\\n        model_path: str, output_layer_name: str = \\\"concat\\\"\\n    ) -> tf.keras.Model:\\n        \\\"\\\"\\\"\\n        Load in Keras model from given path.\\n        output_layer_name will be the layer used to augment data.\\n        \\\"\\\"\\\"\\n        base_model = tf.keras.models.load_model(model_path)\\n        base_model.compile(run_eagerly=True)\\n        # Maximize the activations of these layers\\n        layers = base_model.get_layer(output_layer_name).output\\n        # Create the feature extraction model\\n        dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)\\n        return dream_model\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class DeepDreamGenerator(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Generate synthetic eras using DeepDream technique. \\n\n",
    "    Based on implementation by nemethpeti: \\n\n",
    "    https://github.com/nemethpeti/numerai/blob/main/DeepDream/deepdream.py\n",
    "\n",
    "    :param model_path: Path to trained DeepDream model. Example can be downloaded from \\n\n",
    "    https://github.com/nemethpeti/numerai/blob/main/DeepDream/model.h5 \\n\n",
    "    :param batch_size: How much synthetic data to process in each batch. \\n\n",
    "    :param steps: Number of gradient ascent steps to perform. More steps will lead to more augmentation. \\n\n",
    "    :param step_size: How much to augment the batch based on computed gradients. \\n\n",
    "    Like with the number of steps, a larger step size will lead to more dramatic changes to the input features. \\n\n",
    "    The default parameters are found to work well in practice, but could be further optimized.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path: str,\n",
    "        batch_size: int = 200_000,\n",
    "        steps: int = 5,\n",
    "        step_size: float = 0.01,\n",
    "        feature_names: list = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        tf.config.run_functions_eagerly(True)\n",
    "        self.model_path = model_path\n",
    "        self.model = self.__load_model(self.model_path)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.steps = steps\n",
    "        self.step_size = step_size\n",
    "\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        dream_dataf = self.get_synthetic_batch(dataf)\n",
    "        dataf = pd.concat([dataf, dream_dataf])\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def get_synthetic_batch(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        \"\"\"\n",
    "        Produce a synthetic version of the full input dataset.\n",
    "        Target features will stay the same as in the original input data.\n",
    "        \"\"\"\n",
    "        features = self.feature_names if self.feature_names else dataf.feature_cols\n",
    "        targets = dataf.target_cols\n",
    "\n",
    "        dream_dataf = pd.DataFrame(columns=features)\n",
    "        for i in tqdm(\n",
    "            np.arange(0, len(dataf), self.batch_size),\n",
    "            desc=\"Deepdreaming Synthetic Batches\",\n",
    "        ):\n",
    "            start = i\n",
    "            end = np.minimum(i + self.batch_size - 1, len(dataf) - 1)\n",
    "            sub_dataf = dataf.reset_index(drop=False).iloc[start:end]\n",
    "            batch = tf.convert_to_tensor(\n",
    "                sub_dataf.loc[:, features].astype(np.float32).values\n",
    "            )\n",
    "\n",
    "            dream_arr = self._dream(batch)\n",
    "            batch_dataf = pd.DataFrame(dream_arr, columns=features)\n",
    "            batch_dataf[targets] = sub_dataf[targets]\n",
    "\n",
    "            dream_dataf = pd.concat([dream_dataf, batch_dataf])\n",
    "        return NumerFrame(dream_dataf)\n",
    "\n",
    "    def _dream(self, batch: tf.Tensor) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Perform gradient ascent on batch of data.\n",
    "        This loop perturbs the original features to create synthetic data.\n",
    "        \"\"\"\n",
    "        for _ in tf.range(self.steps):\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(batch)\n",
    "                layer_activations = self.model(batch)\n",
    "                loss = tf.math.reduce_mean(layer_activations, -1)\n",
    "\n",
    "            gradients = tape.gradient(loss, batch)\n",
    "            gradients /= tf.expand_dims(tf.math.reduce_std(gradients, -1), 1) + 1e-8\n",
    "\n",
    "            # In gradient ascent, the \"loss\" is maximized so that the input row increasingly \"excites\" the layers.\n",
    "            batch = batch + gradients * self.step_size\n",
    "        batch = tf.clip_by_value(batch, 0, 1)\n",
    "        return batch.numpy()\n",
    "\n",
    "    @staticmethod\n",
    "    def __load_model(\n",
    "        model_path: str, output_layer_name: str = \"concat\"\n",
    "    ) -> tf.keras.Model:\n",
    "        \"\"\"\n",
    "        Load in Keras model from given path.\n",
    "        output_layer_name will be the layer used to augment data.\n",
    "        \"\"\"\n",
    "        base_model = tf.keras.models.load_model(model_path)\n",
    "        base_model.compile(run_eagerly=True)\n",
    "        # Maximize the activations of these layers\n",
    "        layers = base_model.get_layer(output_layer_name).output\n",
    "        # Create the feature extraction model\n",
    "        dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "        return dream_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "No existing directory found at \u001B[32m'\u001B[0m\u001B[34mdeepdream_test\u001B[0m\u001B[32m'\u001B[0m. Creating directory\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">deepdream_test</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "📁 \u001B[32mDownloading\u001B[0m \u001B[32m'numerai_validation_data.parquet'\u001B[0m 📁\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">📁 <span style=\"color: #008000; text-decoration-color: #008000\">Downloading</span> <span style=\"color: #008000; text-decoration-color: #008000\">'numerai_validation_data.parquet'</span> 📁\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 18:31:27,863 INFO numerapi.utils: starting download\n",
      "deepdream_test/numerai_validation_data.parquet: 228MB [00:46, 4.87MB/s]                            \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 19;\n                var nbb_unformatted_code = \"# hide\\ndirectory = \\\"deepdream_test/\\\"\\ndownloader = NumeraiClassicDownloader(directory_path=directory)\\ndownloader.download_single_dataset(\\n    filename=\\\"numerai_validation_data.parquet\\\",\\n    dest_path=directory + \\\"numerai_validation_data.parquet\\\",\\n)\\nval_dataf = create_numerframe(f\\\"{directory}numerai_validation_data.parquet\\\")\";\n                var nbb_formatted_code = \"# hide\\ndirectory = \\\"deepdream_test/\\\"\\ndownloader = NumeraiClassicDownloader(directory_path=directory)\\ndownloader.download_single_dataset(\\n    filename=\\\"numerai_validation_data.parquet\\\",\\n    dest_path=directory + \\\"numerai_validation_data.parquet\\\",\\n)\\nval_dataf = create_numerframe(f\\\"{directory}numerai_validation_data.parquet\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "directory = \"deepdream_test/\"\n",
    "downloader = NumeraiClassicDownloader(directory_path=directory)\n",
    "downloader.download_single_dataset(\n",
    "    filename=\"numerai_validation_data.parquet\",\n",
    "    dest_path=directory + \"numerai_validation_data.parquet\",\n",
    ")\n",
    "val_dataf = create_numerframe(f\"{directory}numerai_validation_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example we will use the model open sourced by [nemethpeti](https://github.com/nemethpeti) which you can download [here](https://github.com/nemethpeti/numerai/blob/main/DeepDream/model.h5). This model works on the v3 medium feature set. We therefore use v3 data in this example. The v3 medium feature set can be easily retrieved using `NumeraiClassicDownloader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "📁 \u001B[32mDownloading\u001B[0m \u001B[32m'v3/features.json'\u001B[0m 📁\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">📁 <span style=\"color: #008000; text-decoration-color: #008000\">Downloading</span> <span style=\"color: #008000; text-decoration-color: #008000\">'v3/features.json'</span> 📁\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 18:32:18,129 INFO numerapi.utils: starting download\n",
      "deepdream_test/features.json: 441kB [00:00, 721kB/s]                            \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 20;\n                var nbb_unformatted_code = \"# hide_output\\nfeature_set = downloader.get_classic_features(filename=\\\"v3/features.json\\\")\\nfeature_names = feature_set[\\\"feature_sets\\\"][\\\"medium\\\"]\";\n                var nbb_formatted_code = \"# hide_output\\nfeature_set = downloader.get_classic_features(filename=\\\"v3/features.json\\\")\\nfeature_names = feature_set[\\\"feature_sets\\\"][\\\"medium\\\"]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_output\n",
    "feature_set = downloader.get_classic_features(filename=\"v3/features.json\")\n",
    "feature_names = feature_set[\"feature_sets\"][\"medium\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Download link to deepdream_model.h5 used here (Github).](https://github.com/nemethpeti/numerai/blob/main/DeepDream/model.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 18:32:18.872832: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 21;\n                var nbb_unformatted_code = \"ddg = DeepDreamGenerator(\\n    model_path=\\\"test_assets/deepdream_model.h5\\\", feature_names=feature_names\\n)\";\n                var nbb_formatted_code = \"ddg = DeepDreamGenerator(\\n    model_path=\\\"test_assets/deepdream_model.h5\\\", feature_names=feature_names\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ddg = DeepDreamGenerator(\n",
    "    model_path=\"test_assets/deepdream_model.h5\", feature_names=feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 22;\n                var nbb_unformatted_code = \"sample_dataf = NumerFrame(val_dataf.sample(100))\";\n                var nbb_formatted_code = \"sample_dataf = NumerFrame(val_dataf.sample(100))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_dataf = NumerFrame(val_dataf.sample(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Deepdreaming Synthetic Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c11bdb644af4aa8a488292de1b937df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mDeepDreamGenerator\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m199\u001B[0m, \u001B[1;36m1073\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m235036\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">DeepDreamGenerator</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">199</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1073</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">235036</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 23;\n                var nbb_unformatted_code = \"dreamed_dataf = ddg.transform(sample_dataf)\";\n                var nbb_formatted_code = \"dreamed_dataf = ddg.transform(sample_dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dreamed_dataf = ddg.transform(sample_dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new dreamed `NumerFrame` consists of the original data and 100 new additional rows. Note that targets are the same.\n",
    "\n",
    "Also, `era`, `data_type` and any other columns besides features and targets will be `NaN`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 1073)\n"
     ]
    },
    {
     "data": {
      "text/plain": "    era data_type  feature_dichasial_hammier_spawner  \\\n94  NaN       NaN                           0.006177   \n95  NaN       NaN                           0.229461   \n96  NaN       NaN                           0.525625   \n97  NaN       NaN                           0.783618   \n98  NaN       NaN                           0.000000   \n\n    feature_rheumy_epistemic_prancer  feature_pert_performative_hormuz  \\\n94                          0.253282                          0.562395   \n95                          0.275013                          0.211137   \n96                          0.794636                          0.224619   \n97                          0.000000                          0.992784   \n98                          0.072171                          0.748574   \n\n    feature_hillier_unpitied_theobromine  \\\n94                              0.000000   \n95                              0.278999   \n96                              0.529903   \n97                              0.000000   \n98                              0.036015   \n\n    feature_perigean_bewitching_thruster  feature_renegade_undomestic_milord  \\\n94                              0.521255                            0.496594   \n95                              0.040938                            0.747025   \n96                              0.220084                            1.000000   \n97                              0.000000                            0.000000   \n98                              0.801692                            0.481805   \n\n    feature_koranic_rude_corf  feature_demisable_expiring_millepede  ...  \\\n94                   0.742214                              0.000000  ...   \n95                   0.254441                              0.740341  ...   \n96                   0.747399                              0.131461  ...   \n97                   0.566844                              0.955341  ...   \n98                   0.248885                              0.202161  ...   \n\n    target_paul_20  target_paul_60  target_george_20  target_george_60  \\\n94            0.75            1.00              0.50              1.00   \n95            0.50            0.75              0.50              0.50   \n96            1.00            1.00              0.50              0.75   \n97            0.50            0.50              0.50              0.50   \n98            0.25            0.25              0.25              0.25   \n\n    target_william_20  target_william_60  target_arthur_20  target_arthur_60  \\\n94           0.666667           0.833333          0.666667          0.833333   \n95           0.500000           0.500000          0.500000          0.500000   \n96           0.666667           0.500000          0.666667          0.500000   \n97           0.500000           0.500000          0.333333          0.500000   \n98           0.333333           0.333333          0.333333          0.333333   \n\n    target_thomas_20  target_thomas_60  \n94          0.666667          0.833333  \n95          0.500000          0.500000  \n96          1.000000          0.500000  \n97          0.333333          0.500000  \n98          0.333333          0.333333  \n\n[5 rows x 1073 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>era</th>\n      <th>data_type</th>\n      <th>feature_dichasial_hammier_spawner</th>\n      <th>feature_rheumy_epistemic_prancer</th>\n      <th>feature_pert_performative_hormuz</th>\n      <th>feature_hillier_unpitied_theobromine</th>\n      <th>feature_perigean_bewitching_thruster</th>\n      <th>feature_renegade_undomestic_milord</th>\n      <th>feature_koranic_rude_corf</th>\n      <th>feature_demisable_expiring_millepede</th>\n      <th>...</th>\n      <th>target_paul_20</th>\n      <th>target_paul_60</th>\n      <th>target_george_20</th>\n      <th>target_george_60</th>\n      <th>target_william_20</th>\n      <th>target_william_60</th>\n      <th>target_arthur_20</th>\n      <th>target_arthur_60</th>\n      <th>target_thomas_20</th>\n      <th>target_thomas_60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>94</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.006177</td>\n      <td>0.253282</td>\n      <td>0.562395</td>\n      <td>0.000000</td>\n      <td>0.521255</td>\n      <td>0.496594</td>\n      <td>0.742214</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>0.666667</td>\n      <td>0.833333</td>\n      <td>0.666667</td>\n      <td>0.833333</td>\n      <td>0.666667</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.229461</td>\n      <td>0.275013</td>\n      <td>0.211137</td>\n      <td>0.278999</td>\n      <td>0.040938</td>\n      <td>0.747025</td>\n      <td>0.254441</td>\n      <td>0.740341</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.525625</td>\n      <td>0.794636</td>\n      <td>0.224619</td>\n      <td>0.529903</td>\n      <td>0.220084</td>\n      <td>1.000000</td>\n      <td>0.747399</td>\n      <td>0.131461</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.666667</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.500000</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.783618</td>\n      <td>0.000000</td>\n      <td>0.992784</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.566844</td>\n      <td>0.955341</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.072171</td>\n      <td>0.748574</td>\n      <td>0.036015</td>\n      <td>0.801692</td>\n      <td>0.481805</td>\n      <td>0.248885</td>\n      <td>0.202161</td>\n      <td>...</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1073 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 24;\n                var nbb_unformatted_code = \"print(dreamed_dataf.shape)\\ndreamed_dataf.tail()\";\n                var nbb_formatted_code = \"print(dreamed_dataf.shape)\\ndreamed_dataf.tail()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dreamed_dataf.shape)\n",
    "dreamed_dataf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To only keep new synthetic data use `.get_synthetic_batch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Deepdreaming Synthetic Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5b566b6f45e4fa38628b6097660a1cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 25;\n                var nbb_unformatted_code = \"synth_dataf = ddg.get_synthetic_batch(sample_dataf)\";\n                var nbb_formatted_code = \"synth_dataf = ddg.get_synthetic_batch(sample_dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "synth_dataf = ddg.get_synthetic_batch(sample_dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 441)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   feature_abstersive_emotional_misinterpreter  \\\n0                                     1.000000   \n1                                     0.953419   \n2                                     0.488666   \n3                                     0.712898   \n4                                     0.789400   \n\n   feature_accessorial_aroused_crochet  feature_acerb_venusian_piety  \\\n0                             0.202469                      0.215039   \n1                             0.500796                      0.779212   \n2                             0.479599                      0.954576   \n3                             0.732197                      0.029215   \n4                             0.286655                      0.034882   \n\n   feature_affricative_bromic_raftsman  feature_agile_unrespited_gaucho  \\\n0                             1.000000                         0.805737   \n1                             1.000000                         0.744971   \n2                             0.450511                         0.741274   \n3                             0.000000                         0.765652   \n4                             0.746666                         0.537442   \n\n   feature_agronomic_cryptal_advisor  feature_alkaline_pistachio_sunstone  \\\n0                           0.760920                             0.759131   \n1                           0.508278                             0.703535   \n2                           1.000000                             1.000000   \n3                           0.265160                             0.273366   \n4                           0.574934                             0.573383   \n\n   feature_altern_unnoticed_impregnation  feature_ambisexual_boiled_blunderer  \\\n0                               0.506008                             0.503724   \n1                               0.504623                             0.717189   \n2                               0.722007                             0.456649   \n3                               0.506347                             0.884447   \n4                               0.223768                             0.000000   \n\n   feature_amoebaean_wolfish_heeler  ...  target_paul_20  target_paul_60  \\\n0                          0.414889  ...            0.75            0.75   \n1                          0.197521  ...            0.25            0.50   \n2                          0.676140  ...            0.50            0.50   \n3                          0.181741  ...            0.25            0.50   \n4                          0.000000  ...            0.50            0.50   \n\n   target_george_20  target_george_60  target_william_20  target_william_60  \\\n0               1.0              0.75           0.666667           0.500000   \n1               0.5              0.50           0.333333           0.500000   \n2               0.5              0.50           0.500000           0.500000   \n3               0.5              0.50           0.333333           0.500000   \n4               0.5              0.75           0.833333           0.666667   \n\n   target_arthur_20  target_arthur_60  target_thomas_20  target_thomas_60  \n0          0.666667          0.500000          0.833333          0.666667  \n1          0.333333          0.333333          0.333333          0.333333  \n2          0.500000          0.500000          0.500000          0.500000  \n3          0.333333          0.500000          0.500000          0.666667  \n4          0.833333          0.666667          1.000000          1.000000  \n\n[5 rows x 441 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_abstersive_emotional_misinterpreter</th>\n      <th>feature_accessorial_aroused_crochet</th>\n      <th>feature_acerb_venusian_piety</th>\n      <th>feature_affricative_bromic_raftsman</th>\n      <th>feature_agile_unrespited_gaucho</th>\n      <th>feature_agronomic_cryptal_advisor</th>\n      <th>feature_alkaline_pistachio_sunstone</th>\n      <th>feature_altern_unnoticed_impregnation</th>\n      <th>feature_ambisexual_boiled_blunderer</th>\n      <th>feature_amoebaean_wolfish_heeler</th>\n      <th>...</th>\n      <th>target_paul_20</th>\n      <th>target_paul_60</th>\n      <th>target_george_20</th>\n      <th>target_george_60</th>\n      <th>target_william_20</th>\n      <th>target_william_60</th>\n      <th>target_arthur_20</th>\n      <th>target_arthur_60</th>\n      <th>target_thomas_20</th>\n      <th>target_thomas_60</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.000000</td>\n      <td>0.202469</td>\n      <td>0.215039</td>\n      <td>1.000000</td>\n      <td>0.805737</td>\n      <td>0.760920</td>\n      <td>0.759131</td>\n      <td>0.506008</td>\n      <td>0.503724</td>\n      <td>0.414889</td>\n      <td>...</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0.75</td>\n      <td>0.666667</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n      <td>0.500000</td>\n      <td>0.833333</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.953419</td>\n      <td>0.500796</td>\n      <td>0.779212</td>\n      <td>1.000000</td>\n      <td>0.744971</td>\n      <td>0.508278</td>\n      <td>0.703535</td>\n      <td>0.504623</td>\n      <td>0.717189</td>\n      <td>0.197521</td>\n      <td>...</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.5</td>\n      <td>0.50</td>\n      <td>0.333333</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.488666</td>\n      <td>0.479599</td>\n      <td>0.954576</td>\n      <td>0.450511</td>\n      <td>0.741274</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.722007</td>\n      <td>0.456649</td>\n      <td>0.676140</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.5</td>\n      <td>0.50</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.712898</td>\n      <td>0.732197</td>\n      <td>0.029215</td>\n      <td>0.000000</td>\n      <td>0.765652</td>\n      <td>0.265160</td>\n      <td>0.273366</td>\n      <td>0.506347</td>\n      <td>0.884447</td>\n      <td>0.181741</td>\n      <td>...</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.5</td>\n      <td>0.50</td>\n      <td>0.333333</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.789400</td>\n      <td>0.286655</td>\n      <td>0.034882</td>\n      <td>0.746666</td>\n      <td>0.537442</td>\n      <td>0.574934</td>\n      <td>0.573383</td>\n      <td>0.223768</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.5</td>\n      <td>0.75</td>\n      <td>0.833333</td>\n      <td>0.666667</td>\n      <td>0.833333</td>\n      <td>0.666667</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 441 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 26;\n                var nbb_unformatted_code = \"print(synth_dataf.shape)\\nsynth_dataf.head()\";\n                var nbb_formatted_code = \"print(synth_dataf.shape)\\nsynth_dataf.head()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(synth_dataf.shape)\n",
    "synth_dataf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.6. UMAPFeatureGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniform Manifold Approximation and Projection (UMAP) is a dimensionality reduction technique that we can utilize to generate new Numerai features. This processor uses [umap-learn](https://pypi.org/project/umap-learn) under the hood to model the manifold. The dimension of the input data will be reduced to `n_components` number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 27;\n                var nbb_unformatted_code = \"# export\\nclass UMAPFeatureGenerator(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Generate new Numerai features using UMAP. Uses umap-learn under the hood: \\\\n\\n    https://pypi.org/project/umap-learn/\\n    :param n_components: How many new features to generate.\\n    :param n_neighbors: Number of neighboring points used in local approximations of manifold structure.\\n    :param min_dist: How tightly the embedding is allows to compress points together.\\n    :param metric: Metric to measure distance in input space. Correlation by default.\\n    :param feature_names: Selection of features used to perform UMAP on. All features by default.\\n    *args, **kwargs will be passed to initialization of UMAP.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        n_components: int = 5,\\n        n_neighbors: int = 15,\\n        min_dist: float = 0.0,\\n        metric: str = \\\"correlation\\\",\\n        feature_names: list = None,\\n        *args,\\n        **kwargs,\\n    ):\\n        super().__init__()\\n        self.n_components = n_components\\n        self.n_neighbors = n_neighbors\\n        self.min_dist = min_dist\\n        self.feature_names = feature_names\\n        self.metric = metric\\n        self.umap = UMAP(\\n            n_components=self.n_components,\\n            n_neighbors=self.n_neighbors,\\n            min_dist=self.min_dist,\\n            metric=self.metric,\\n            *args,\\n            **kwargs,\\n        )\\n\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\\n        new_feature_data = self.umap.fit_transform(dataf[feature_names])\\n        umap_feature_names = [f\\\"feature_umap_{i}\\\" for i in range(self.n_components)]\\n        norm_new_feature_data = MinMaxScaler().fit_transform(new_feature_data)\\n        dataf.loc[:, umap_feature_names] = norm_new_feature_data\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\nclass UMAPFeatureGenerator(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Generate new Numerai features using UMAP. Uses umap-learn under the hood: \\\\n\\n    https://pypi.org/project/umap-learn/\\n    :param n_components: How many new features to generate.\\n    :param n_neighbors: Number of neighboring points used in local approximations of manifold structure.\\n    :param min_dist: How tightly the embedding is allows to compress points together.\\n    :param metric: Metric to measure distance in input space. Correlation by default.\\n    :param feature_names: Selection of features used to perform UMAP on. All features by default.\\n    *args, **kwargs will be passed to initialization of UMAP.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        n_components: int = 5,\\n        n_neighbors: int = 15,\\n        min_dist: float = 0.0,\\n        metric: str = \\\"correlation\\\",\\n        feature_names: list = None,\\n        *args,\\n        **kwargs,\\n    ):\\n        super().__init__()\\n        self.n_components = n_components\\n        self.n_neighbors = n_neighbors\\n        self.min_dist = min_dist\\n        self.feature_names = feature_names\\n        self.metric = metric\\n        self.umap = UMAP(\\n            n_components=self.n_components,\\n            n_neighbors=self.n_neighbors,\\n            min_dist=self.min_dist,\\n            metric=self.metric,\\n            *args,\\n            **kwargs,\\n        )\\n\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\\n        new_feature_data = self.umap.fit_transform(dataf[feature_names])\\n        umap_feature_names = [f\\\"feature_umap_{i}\\\" for i in range(self.n_components)]\\n        norm_new_feature_data = MinMaxScaler().fit_transform(new_feature_data)\\n        dataf.loc[:, umap_feature_names] = norm_new_feature_data\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class UMAPFeatureGenerator(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Generate new Numerai features using UMAP. Uses umap-learn under the hood: \\n\n",
    "    https://pypi.org/project/umap-learn/\n",
    "    :param n_components: How many new features to generate.\n",
    "    :param n_neighbors: Number of neighboring points used in local approximations of manifold structure.\n",
    "    :param min_dist: How tightly the embedding is allows to compress points together.\n",
    "    :param metric: Metric to measure distance in input space. Correlation by default.\n",
    "    :param feature_names: Selection of features used to perform UMAP on. All features by default.\n",
    "    *args, **kwargs will be passed to initialization of UMAP.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_components: int = 5,\n",
    "        n_neighbors: int = 15,\n",
    "        min_dist: float = 0.0,\n",
    "        metric: str = \"correlation\",\n",
    "        feature_names: list = None,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_components = n_components\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.min_dist = min_dist\n",
    "        self.feature_names = feature_names\n",
    "        self.metric = metric\n",
    "        self.umap = UMAP(\n",
    "            n_components=self.n_components,\n",
    "            n_neighbors=self.n_neighbors,\n",
    "            min_dist=self.min_dist,\n",
    "            metric=self.metric,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\n",
    "        new_feature_data = self.umap.fit_transform(dataf[feature_names])\n",
    "        umap_feature_names = [f\"feature_umap_{i}\" for i in range(self.n_components)]\n",
    "        norm_new_feature_data = MinMaxScaler().fit_transform(new_feature_data)\n",
    "        dataf.loc[:, umap_feature_names] = norm_new_feature_data\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #271: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 28;\n                var nbb_unformatted_code = \"n_components = 3\\numap_gen = UMAPFeatureGenerator(n_components=n_components, n_neighbors=9)\\ndataf = create_numerframe(\\\"test_assets/mini_numerai_version_2_data.parquet\\\")\\ndataf = umap_gen(dataf)\";\n                var nbb_formatted_code = \"n_components = 3\\numap_gen = UMAPFeatureGenerator(n_components=n_components, n_neighbors=9)\\ndataf = create_numerframe(\\\"test_assets/mini_numerai_version_2_data.parquet\\\")\\ndataf = umap_gen(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_components = 3\n",
    "umap_gen = UMAPFeatureGenerator(n_components=n_components, n_neighbors=9)\n",
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_2_data.parquet\")\n",
    "dataf = umap_gen(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new features will be names with the convention `f\"feature_umap_{i}\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                  feature_umap_0  feature_umap_1  feature_umap_2\nid                                                              \nn559bd06a8861222        1.000000        0.467906        0.160752\nn9d39dea58c9e3cf        0.689324        0.283587        0.000000\nnb64f06d3a9fc9f1        0.400365        1.000000        0.388111",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_umap_0</th>\n      <th>feature_umap_1</th>\n      <th>feature_umap_2</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>1.000000</td>\n      <td>0.467906</td>\n      <td>0.160752</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>0.689324</td>\n      <td>0.283587</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>nb64f06d3a9fc9f1</th>\n      <td>0.400365</td>\n      <td>1.000000</td>\n      <td>0.388111</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 29;\n                var nbb_unformatted_code = \"umap_features = [f\\\"feature_umap_{i}\\\" for i in range(n_components)]\\ndataf[umap_features].head(3)\";\n                var nbb_formatted_code = \"umap_features = [f\\\"feature_umap_{i}\\\" for i in range(n_components)]\\ndataf[umap_features].head(3)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "umap_features = [f\"feature_umap_{i}\" for i in range(n_components)]\n",
    "dataf[umap_features].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Numerai Classic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Numerai Classic dataset has a certain structure that you may not encounter in the Numerai Signals tournament.\n",
    "Therefore, this section has all preprocessors that can only be applied to Numerai Classic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.0 Numerai Classic: Version agnostic\n",
    "\n",
    "Preprocessors that work for all Numerai Classic versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.0.1. BayesianGMMTargetProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 30;\n                var nbb_unformatted_code = \"# export\\nclass BayesianGMMTargetProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Generate synthetic (fake) target using a Bayesian Gaussian Mixture model. \\\\n\\n    Based on Michael Oliver's GitHub Gist implementation: \\\\n\\n    https://gist.github.com/the-moliver/dcdd2862dc2c78dda600f1b449071c93\\n\\n    :param target_col: Column from which to create fake target. \\\\n\\n    :param feature_names: Selection of features used for Bayesian GMM. All features by default.\\n    :param n_components: Number of components for fitting Bayesian Gaussian Mixture Model.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        target_col: str = \\\"target\\\",\\n        feature_names: list = None,\\n        n_components: int = 6,\\n    ):\\n        super().__init__()\\n        self.target_col = target_col\\n        self.feature_names = feature_names\\n        self.n_components = n_components\\n        self.ridge = Ridge(fit_intercept=False)\\n        self.bins = [0, 0.05, 0.25, 0.75, 0.95, 1]\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        all_eras = dataf[dataf.meta.era_col].unique()\\n        coefs = self._get_coefs(dataf=dataf, all_eras=all_eras)\\n        bgmm = self._fit_bgmm(coefs=coefs)\\n        fake_target = self._generate_target(dataf=dataf, bgmm=bgmm, all_eras=all_eras)\\n        dataf[f\\\"{self.target_col}_fake\\\"] = fake_target\\n        return NumerFrame(dataf)\\n\\n    def _get_coefs(self, dataf: NumerFrame, all_eras: list) -> np.ndarray:\\n        \\\"\\\"\\\"\\n        Generate coefficients for BGMM.\\n        Data should already be scaled between 0 and 1\\n        (Already done with Numerai Classic data)\\n        \\\"\\\"\\\"\\n        coefs = []\\n        for era in all_eras:\\n            features, target = self.__get_features_target(dataf=dataf, era=era)\\n            self.ridge.fit(features, target)\\n            coefs.append(self.ridge.coef_)\\n        stacked_coefs = np.vstack(coefs)\\n        return stacked_coefs\\n\\n    def _fit_bgmm(self, coefs: np.ndarray) -> BayesianGaussianMixture:\\n        \\\"\\\"\\\"\\n        Fit Bayesian Gaussian Mixture model on coefficients and normalize.\\n        \\\"\\\"\\\"\\n        bgmm = BayesianGaussianMixture(n_components=self.n_components)\\n        bgmm.fit(coefs)\\n        # make probability of sampling each component equal to better balance rare regimes\\n        bgmm.weights_[:] = 1 / self.n_components\\n        return bgmm\\n\\n    def _generate_target(\\n        self, dataf: NumerFrame, bgmm: BayesianGaussianMixture, all_eras: list\\n    ) -> np.ndarray:\\n        \\\"\\\"\\\"Generate fake target using Bayesian Gaussian Mixture model.\\\"\\\"\\\"\\n        fake_target = []\\n        for era in tqdm(all_eras, desc=\\\"Generating fake target\\\"):\\n            features, _ = self.__get_features_target(dataf=dataf, era=era)\\n            # Sample a set of weights from GMM\\n            beta, _ = bgmm.sample(1)\\n            # Create fake continuous target\\n            fake_targ = features @ beta[0]\\n            # Bin fake target like real target\\n            fake_targ = (rankdata(fake_targ) - 0.5) / len(fake_targ)\\n            fake_targ = (np.digitize(fake_targ, self.bins) - 1) / 4\\n            fake_target.append(fake_targ)\\n        return np.concatenate(fake_target)\\n\\n    def __get_features_target(self, dataf: NumerFrame, era) -> tuple:\\n        \\\"\\\"\\\"Get features and target for one era and center data.\\\"\\\"\\\"\\n        sub_df = dataf[dataf[dataf.meta.era_col] == era]\\n        features = self.feature_names if self.feature_names else sub_df.get_feature_data\\n        target = sub_df[self.target_col]\\n        features = features.values - 0.5\\n        target = target.values - 0.5\\n        return features, target\";\n                var nbb_formatted_code = \"# export\\nclass BayesianGMMTargetProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Generate synthetic (fake) target using a Bayesian Gaussian Mixture model. \\\\n\\n    Based on Michael Oliver's GitHub Gist implementation: \\\\n\\n    https://gist.github.com/the-moliver/dcdd2862dc2c78dda600f1b449071c93\\n\\n    :param target_col: Column from which to create fake target. \\\\n\\n    :param feature_names: Selection of features used for Bayesian GMM. All features by default.\\n    :param n_components: Number of components for fitting Bayesian Gaussian Mixture Model.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        target_col: str = \\\"target\\\",\\n        feature_names: list = None,\\n        n_components: int = 6,\\n    ):\\n        super().__init__()\\n        self.target_col = target_col\\n        self.feature_names = feature_names\\n        self.n_components = n_components\\n        self.ridge = Ridge(fit_intercept=False)\\n        self.bins = [0, 0.05, 0.25, 0.75, 0.95, 1]\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        all_eras = dataf[dataf.meta.era_col].unique()\\n        coefs = self._get_coefs(dataf=dataf, all_eras=all_eras)\\n        bgmm = self._fit_bgmm(coefs=coefs)\\n        fake_target = self._generate_target(dataf=dataf, bgmm=bgmm, all_eras=all_eras)\\n        dataf[f\\\"{self.target_col}_fake\\\"] = fake_target\\n        return NumerFrame(dataf)\\n\\n    def _get_coefs(self, dataf: NumerFrame, all_eras: list) -> np.ndarray:\\n        \\\"\\\"\\\"\\n        Generate coefficients for BGMM.\\n        Data should already be scaled between 0 and 1\\n        (Already done with Numerai Classic data)\\n        \\\"\\\"\\\"\\n        coefs = []\\n        for era in all_eras:\\n            features, target = self.__get_features_target(dataf=dataf, era=era)\\n            self.ridge.fit(features, target)\\n            coefs.append(self.ridge.coef_)\\n        stacked_coefs = np.vstack(coefs)\\n        return stacked_coefs\\n\\n    def _fit_bgmm(self, coefs: np.ndarray) -> BayesianGaussianMixture:\\n        \\\"\\\"\\\"\\n        Fit Bayesian Gaussian Mixture model on coefficients and normalize.\\n        \\\"\\\"\\\"\\n        bgmm = BayesianGaussianMixture(n_components=self.n_components)\\n        bgmm.fit(coefs)\\n        # make probability of sampling each component equal to better balance rare regimes\\n        bgmm.weights_[:] = 1 / self.n_components\\n        return bgmm\\n\\n    def _generate_target(\\n        self, dataf: NumerFrame, bgmm: BayesianGaussianMixture, all_eras: list\\n    ) -> np.ndarray:\\n        \\\"\\\"\\\"Generate fake target using Bayesian Gaussian Mixture model.\\\"\\\"\\\"\\n        fake_target = []\\n        for era in tqdm(all_eras, desc=\\\"Generating fake target\\\"):\\n            features, _ = self.__get_features_target(dataf=dataf, era=era)\\n            # Sample a set of weights from GMM\\n            beta, _ = bgmm.sample(1)\\n            # Create fake continuous target\\n            fake_targ = features @ beta[0]\\n            # Bin fake target like real target\\n            fake_targ = (rankdata(fake_targ) - 0.5) / len(fake_targ)\\n            fake_targ = (np.digitize(fake_targ, self.bins) - 1) / 4\\n            fake_target.append(fake_targ)\\n        return np.concatenate(fake_target)\\n\\n    def __get_features_target(self, dataf: NumerFrame, era) -> tuple:\\n        \\\"\\\"\\\"Get features and target for one era and center data.\\\"\\\"\\\"\\n        sub_df = dataf[dataf[dataf.meta.era_col] == era]\\n        features = self.feature_names if self.feature_names else sub_df.get_feature_data\\n        target = sub_df[self.target_col]\\n        features = features.values - 0.5\\n        target = target.values - 0.5\\n        return features, target\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class BayesianGMMTargetProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Generate synthetic (fake) target using a Bayesian Gaussian Mixture model. \\n\n",
    "    Based on Michael Oliver's GitHub Gist implementation: \\n\n",
    "    https://gist.github.com/the-moliver/dcdd2862dc2c78dda600f1b449071c93\n",
    "\n",
    "    :param target_col: Column from which to create fake target. \\n\n",
    "    :param feature_names: Selection of features used for Bayesian GMM. All features by default.\n",
    "    :param n_components: Number of components for fitting Bayesian Gaussian Mixture Model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_col: str = \"target\",\n",
    "        feature_names: list = None,\n",
    "        n_components: int = 6,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.target_col = target_col\n",
    "        self.feature_names = feature_names\n",
    "        self.n_components = n_components\n",
    "        self.ridge = Ridge(fit_intercept=False)\n",
    "        self.bins = [0, 0.05, 0.25, 0.75, 0.95, 1]\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        all_eras = dataf[dataf.meta.era_col].unique()\n",
    "        coefs = self._get_coefs(dataf=dataf, all_eras=all_eras)\n",
    "        bgmm = self._fit_bgmm(coefs=coefs)\n",
    "        fake_target = self._generate_target(dataf=dataf, bgmm=bgmm, all_eras=all_eras)\n",
    "        dataf[f\"{self.target_col}_fake\"] = fake_target\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def _get_coefs(self, dataf: NumerFrame, all_eras: list) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate coefficients for BGMM.\n",
    "        Data should already be scaled between 0 and 1\n",
    "        (Already done with Numerai Classic data)\n",
    "        \"\"\"\n",
    "        coefs = []\n",
    "        for era in all_eras:\n",
    "            features, target = self.__get_features_target(dataf=dataf, era=era)\n",
    "            self.ridge.fit(features, target)\n",
    "            coefs.append(self.ridge.coef_)\n",
    "        stacked_coefs = np.vstack(coefs)\n",
    "        return stacked_coefs\n",
    "\n",
    "    def _fit_bgmm(self, coefs: np.ndarray) -> BayesianGaussianMixture:\n",
    "        \"\"\"\n",
    "        Fit Bayesian Gaussian Mixture model on coefficients and normalize.\n",
    "        \"\"\"\n",
    "        bgmm = BayesianGaussianMixture(n_components=self.n_components)\n",
    "        bgmm.fit(coefs)\n",
    "        # make probability of sampling each component equal to better balance rare regimes\n",
    "        bgmm.weights_[:] = 1 / self.n_components\n",
    "        return bgmm\n",
    "\n",
    "    def _generate_target(\n",
    "        self, dataf: NumerFrame, bgmm: BayesianGaussianMixture, all_eras: list\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Generate fake target using Bayesian Gaussian Mixture model.\"\"\"\n",
    "        fake_target = []\n",
    "        for era in tqdm(all_eras, desc=\"Generating fake target\"):\n",
    "            features, _ = self.__get_features_target(dataf=dataf, era=era)\n",
    "            # Sample a set of weights from GMM\n",
    "            beta, _ = bgmm.sample(1)\n",
    "            # Create fake continuous target\n",
    "            fake_targ = features @ beta[0]\n",
    "            # Bin fake target like real target\n",
    "            fake_targ = (rankdata(fake_targ) - 0.5) / len(fake_targ)\n",
    "            fake_targ = (np.digitize(fake_targ, self.bins) - 1) / 4\n",
    "            fake_target.append(fake_targ)\n",
    "        return np.concatenate(fake_target)\n",
    "\n",
    "    def __get_features_target(self, dataf: NumerFrame, era) -> tuple:\n",
    "        \"\"\"Get features and target for one era and center data.\"\"\"\n",
    "        sub_df = dataf[dataf[dataf.meta.era_col] == era]\n",
    "        features = self.feature_names if self.feature_names else sub_df.get_feature_data\n",
    "        target = sub_df[self.target_col]\n",
    "        features = features.values - 0.5\n",
    "        target = target.values - 0.5\n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/numerai-blocks37/lib/python3.7/site-packages/sklearn/mixture/_base.py:282: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating fake target:   0%|          | 0/60 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cfe60d4fadeb42f1a87d68b074a0f10f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mBayesianGMMTargetProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m100\u001B[0m, \u001B[1;36m1074\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:02:36\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m402163\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">BayesianGMMTargetProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1074</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:02:36</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">402163</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                  target  target_fake\nid                                   \nned455e047de7e97    0.75          0.5\nn6abb0e68edd1571    0.25          0.5\nn7e76644dbadbd6b    0.50          0.5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>target_fake</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ned455e047de7e97</th>\n      <td>0.75</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>n6abb0e68edd1571</th>\n      <td>0.25</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>n7e76644dbadbd6b</th>\n      <td>0.50</td>\n      <td>0.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 31;\n                var nbb_unformatted_code = \"bgmm = BayesianGMMTargetProcessor()\\nsample_dataf = bgmm(sample_dataf)\\nsample_dataf[[\\\"target\\\", \\\"target_fake\\\"]].head(3)\";\n                var nbb_formatted_code = \"bgmm = BayesianGMMTargetProcessor()\\nsample_dataf = bgmm(sample_dataf)\\nsample_dataf[[\\\"target\\\", \\\"target_fake\\\"]].head(3)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bgmm = BayesianGMMTargetProcessor()\n",
    "sample_dataf = bgmm(sample_dataf)\n",
    "sample_dataf[[\"target\", \"target_fake\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "⚠ \u001B[31mDeleting directory for \u001B[0m\u001B[31m'NumeraiClassicDownloader\u001B[0m\u001B[32m'\u001B[0m ⚠\nPath: \u001B[32m'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/deepdream_test'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">⚠ <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'NumeraiClassicDownloader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> ⚠\nPath: <span style=\"color: #008000; text-decoration-color: #008000\">'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/deepdream_test'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 32;\n                var nbb_unformatted_code = \"# hide\\ndownloader.remove_base_directory()\";\n                var nbb_formatted_code = \"# hide\\ndownloader.remove_base_directory()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "downloader.remove_base_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Numerai Classic: Version 1 specific\n",
    "\n",
    "Preprocessors that only work for version 1 (legacy data).\n",
    "When using version 1 preprocessor it is recommended that the input `NumerFrame` has `version` in its metadata.\n",
    "This avoids using version 1 preprocessors on version 2 data and encountering confusing error messages.\n",
    "\n",
    "As a new user we recommend to start modeling the version 2 data and avoid version 1.\n",
    "The preprocessors below are only there for legacy and compatibility reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1.1. GroupStatsPreProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The version 1 legacy data has 6 groups of features which allows us to calculate aggregate features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 33;\n                var nbb_unformatted_code = \"# export\\nclass GroupStatsPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    WARNING: Only supported for Version 1 (legacy) data. \\\\n\\n    Calculate group statistics for all data groups. \\\\n\\n    | :param groups: Groups to create features for. All groups by default.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, groups: list = None):\\n        super().__init__()\\n        self.all_groups = [\\n            \\\"intelligence\\\",\\n            \\\"wisdom\\\",\\n            \\\"charisma\\\",\\n            \\\"dexterity\\\",\\n            \\\"strength\\\",\\n            \\\"constitution\\\",\\n        ]\\n        self.group_names = groups if groups else self.all_groups\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        \\\"\\\"\\\"Check validity and add group features.\\\"\\\"\\\"\\n        self._check_data_validity(dataf=dataf)\\n        dataf = dataf.pipe(self._add_group_features)\\n        return NumerFrame(dataf)\\n\\n    def _add_group_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"Mean, standard deviation and skew for each group.\\\"\\\"\\\"\\n        for group in self.group_names:\\n            cols = [col for col in dataf.columns if group in col]\\n            dataf[f\\\"feature_{group}_mean\\\"] = dataf[cols].mean(axis=1)\\n            dataf[f\\\"feature_{group}_std\\\"] = dataf[cols].std(axis=1)\\n            dataf[f\\\"feature_{group}_skew\\\"] = dataf[cols].skew(axis=1)\\n        return dataf\\n\\n    def _check_data_validity(self, dataf: NumerFrame):\\n        \\\"\\\"\\\"Make sure this is only used for version 1 data.\\\"\\\"\\\"\\n        assert hasattr(\\n            dataf.meta, \\\"version\\\"\\n        ), f\\\"Version should be specified for '{self.__class__.__name__}' This Preprocessor will only work on version 1 data.\\\"\\n        assert (\\n            getattr(dataf.meta, \\\"version\\\") == 1\\n        ), f\\\"'{self.__class__.__name__}' only works on version 1 data. Got version: '{getattr(dataf.meta, 'version')}'.\\\"\";\n                var nbb_formatted_code = \"# export\\nclass GroupStatsPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    WARNING: Only supported for Version 1 (legacy) data. \\\\n\\n    Calculate group statistics for all data groups. \\\\n\\n    | :param groups: Groups to create features for. All groups by default.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, groups: list = None):\\n        super().__init__()\\n        self.all_groups = [\\n            \\\"intelligence\\\",\\n            \\\"wisdom\\\",\\n            \\\"charisma\\\",\\n            \\\"dexterity\\\",\\n            \\\"strength\\\",\\n            \\\"constitution\\\",\\n        ]\\n        self.group_names = groups if groups else self.all_groups\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        \\\"\\\"\\\"Check validity and add group features.\\\"\\\"\\\"\\n        self._check_data_validity(dataf=dataf)\\n        dataf = dataf.pipe(self._add_group_features)\\n        return NumerFrame(dataf)\\n\\n    def _add_group_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"Mean, standard deviation and skew for each group.\\\"\\\"\\\"\\n        for group in self.group_names:\\n            cols = [col for col in dataf.columns if group in col]\\n            dataf[f\\\"feature_{group}_mean\\\"] = dataf[cols].mean(axis=1)\\n            dataf[f\\\"feature_{group}_std\\\"] = dataf[cols].std(axis=1)\\n            dataf[f\\\"feature_{group}_skew\\\"] = dataf[cols].skew(axis=1)\\n        return dataf\\n\\n    def _check_data_validity(self, dataf: NumerFrame):\\n        \\\"\\\"\\\"Make sure this is only used for version 1 data.\\\"\\\"\\\"\\n        assert hasattr(\\n            dataf.meta, \\\"version\\\"\\n        ), f\\\"Version should be specified for '{self.__class__.__name__}' This Preprocessor will only work on version 1 data.\\\"\\n        assert (\\n            getattr(dataf.meta, \\\"version\\\") == 1\\n        ), f\\\"'{self.__class__.__name__}' only works on version 1 data. Got version: '{getattr(dataf.meta, 'version')}'.\\\"\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class GroupStatsPreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    WARNING: Only supported for Version 1 (legacy) data. \\n\n",
    "    Calculate group statistics for all data groups. \\n\n",
    "    | :param groups: Groups to create features for. All groups by default.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, groups: list = None):\n",
    "        super().__init__()\n",
    "        self.all_groups = [\n",
    "            \"intelligence\",\n",
    "            \"wisdom\",\n",
    "            \"charisma\",\n",
    "            \"dexterity\",\n",
    "            \"strength\",\n",
    "            \"constitution\",\n",
    "        ]\n",
    "        self.group_names = groups if groups else self.all_groups\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        \"\"\"Check validity and add group features.\"\"\"\n",
    "        self._check_data_validity(dataf=dataf)\n",
    "        dataf = dataf.pipe(self._add_group_features)\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def _add_group_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Mean, standard deviation and skew for each group.\"\"\"\n",
    "        for group in self.group_names:\n",
    "            cols = [col for col in dataf.columns if group in col]\n",
    "            dataf[f\"feature_{group}_mean\"] = dataf[cols].mean(axis=1)\n",
    "            dataf[f\"feature_{group}_std\"] = dataf[cols].std(axis=1)\n",
    "            dataf[f\"feature_{group}_skew\"] = dataf[cols].skew(axis=1)\n",
    "        return dataf\n",
    "\n",
    "    def _check_data_validity(self, dataf: NumerFrame):\n",
    "        \"\"\"Make sure this is only used for version 1 data.\"\"\"\n",
    "        assert hasattr(\n",
    "            dataf.meta, \"version\"\n",
    "        ), f\"Version should be specified for '{self.__class__.__name__}' This Preprocessor will only work on version 1 data.\"\n",
    "        assert (\n",
    "            getattr(dataf.meta, \"version\") == 1\n",
    "        ), f\"'{self.__class__.__name__}' only works on version 1 data. Got version: '{getattr(dataf.meta, 'version')}'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mGroupStatsPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m332\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m064127\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">GroupStatsPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">332</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">064127</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 34;\n                var nbb_unformatted_code = \"dataf = create_numerframe(\\n    \\\"test_assets/mini_numerai_version_1_data.csv\\\", metadata={\\\"version\\\": 1}\\n)\\ngroup_features_dataf = GroupStatsPreProcessor().transform(dataf)\\ngroup_features_dataf.head(2)\\nassert group_features_dataf.meta.version == 1\";\n                var nbb_formatted_code = \"dataf = create_numerframe(\\n    \\\"test_assets/mini_numerai_version_1_data.csv\\\", metadata={\\\"version\\\": 1}\\n)\\ngroup_features_dataf = GroupStatsPreProcessor().transform(dataf)\\ngroup_features_dataf.head(2)\\nassert group_features_dataf.meta.version == 1\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataf = create_numerframe(\n",
    "    \"test_assets/mini_numerai_version_1_data.csv\", metadata={\"version\": 1}\n",
    ")\n",
    "group_features_dataf = GroupStatsPreProcessor().transform(dataf)\n",
    "group_features_dataf.head(2)\n",
    "assert group_features_dataf.meta.version == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   feature_intelligence_mean  feature_intelligence_std  \\\n0                   0.333333                  0.246183   \n1                   0.208333                  0.234359   \n\n   feature_intelligence_skew  feature_wisdom_mean  feature_wisdom_std  \\\n0                   0.558528             0.668478            0.236022   \n1                   0.382554             0.559783            0.358177   \n\n   feature_wisdom_skew  feature_charisma_mean  feature_charisma_std  \\\n0            -0.115082               0.438953              0.259910   \n1            -0.062362               0.485465              0.252501   \n\n   feature_charisma_skew  feature_dexterity_mean  feature_dexterity_std  \\\n0              -0.004783                0.696429               0.200446   \n1              -0.021737                0.267857               0.249312   \n\n   feature_dexterity_skew  feature_strength_mean  feature_strength_std  \\\n0               -0.607620               0.480263              0.292829   \n1                0.382267               0.407895              0.309866   \n\n   feature_strength_skew  feature_constitution_mean  feature_constitution_std  \\\n0              -0.372064                   0.427632                   0.27572   \n1               0.220625                   0.644737                   0.33408   \n\n   feature_constitution_skew  \n0                   0.276155  \n1                  -0.794938  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_intelligence_mean</th>\n      <th>feature_intelligence_std</th>\n      <th>feature_intelligence_skew</th>\n      <th>feature_wisdom_mean</th>\n      <th>feature_wisdom_std</th>\n      <th>feature_wisdom_skew</th>\n      <th>feature_charisma_mean</th>\n      <th>feature_charisma_std</th>\n      <th>feature_charisma_skew</th>\n      <th>feature_dexterity_mean</th>\n      <th>feature_dexterity_std</th>\n      <th>feature_dexterity_skew</th>\n      <th>feature_strength_mean</th>\n      <th>feature_strength_std</th>\n      <th>feature_strength_skew</th>\n      <th>feature_constitution_mean</th>\n      <th>feature_constitution_std</th>\n      <th>feature_constitution_skew</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.333333</td>\n      <td>0.246183</td>\n      <td>0.558528</td>\n      <td>0.668478</td>\n      <td>0.236022</td>\n      <td>-0.115082</td>\n      <td>0.438953</td>\n      <td>0.259910</td>\n      <td>-0.004783</td>\n      <td>0.696429</td>\n      <td>0.200446</td>\n      <td>-0.607620</td>\n      <td>0.480263</td>\n      <td>0.292829</td>\n      <td>-0.372064</td>\n      <td>0.427632</td>\n      <td>0.27572</td>\n      <td>0.276155</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.208333</td>\n      <td>0.234359</td>\n      <td>0.382554</td>\n      <td>0.559783</td>\n      <td>0.358177</td>\n      <td>-0.062362</td>\n      <td>0.485465</td>\n      <td>0.252501</td>\n      <td>-0.021737</td>\n      <td>0.267857</td>\n      <td>0.249312</td>\n      <td>0.382267</td>\n      <td>0.407895</td>\n      <td>0.309866</td>\n      <td>0.220625</td>\n      <td>0.644737</td>\n      <td>0.33408</td>\n      <td>-0.794938</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 35;\n                var nbb_unformatted_code = \"# hide\\nnew_cols = [\\n    \\\"feature_intelligence_mean\\\",\\n    \\\"feature_intelligence_std\\\",\\n    \\\"feature_intelligence_skew\\\",\\n    \\\"feature_wisdom_mean\\\",\\n    \\\"feature_wisdom_std\\\",\\n    \\\"feature_wisdom_skew\\\",\\n    \\\"feature_charisma_mean\\\",\\n    \\\"feature_charisma_std\\\",\\n    \\\"feature_charisma_skew\\\",\\n    \\\"feature_dexterity_mean\\\",\\n    \\\"feature_dexterity_std\\\",\\n    \\\"feature_dexterity_skew\\\",\\n    \\\"feature_strength_mean\\\",\\n    \\\"feature_strength_std\\\",\\n    \\\"feature_strength_skew\\\",\\n    \\\"feature_constitution_mean\\\",\\n    \\\"feature_constitution_std\\\",\\n    \\\"feature_constitution_skew\\\",\\n]\\nassert set(group_features_dataf.columns).intersection(new_cols)\\ngroup_features_dataf.get_feature_data[new_cols].head(2)\";\n                var nbb_formatted_code = \"# hide\\nnew_cols = [\\n    \\\"feature_intelligence_mean\\\",\\n    \\\"feature_intelligence_std\\\",\\n    \\\"feature_intelligence_skew\\\",\\n    \\\"feature_wisdom_mean\\\",\\n    \\\"feature_wisdom_std\\\",\\n    \\\"feature_wisdom_skew\\\",\\n    \\\"feature_charisma_mean\\\",\\n    \\\"feature_charisma_std\\\",\\n    \\\"feature_charisma_skew\\\",\\n    \\\"feature_dexterity_mean\\\",\\n    \\\"feature_dexterity_std\\\",\\n    \\\"feature_dexterity_skew\\\",\\n    \\\"feature_strength_mean\\\",\\n    \\\"feature_strength_std\\\",\\n    \\\"feature_strength_skew\\\",\\n    \\\"feature_constitution_mean\\\",\\n    \\\"feature_constitution_std\\\",\\n    \\\"feature_constitution_skew\\\",\\n]\\nassert set(group_features_dataf.columns).intersection(new_cols)\\ngroup_features_dataf.get_feature_data[new_cols].head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "new_cols = [\n",
    "    \"feature_intelligence_mean\",\n",
    "    \"feature_intelligence_std\",\n",
    "    \"feature_intelligence_skew\",\n",
    "    \"feature_wisdom_mean\",\n",
    "    \"feature_wisdom_std\",\n",
    "    \"feature_wisdom_skew\",\n",
    "    \"feature_charisma_mean\",\n",
    "    \"feature_charisma_std\",\n",
    "    \"feature_charisma_skew\",\n",
    "    \"feature_dexterity_mean\",\n",
    "    \"feature_dexterity_std\",\n",
    "    \"feature_dexterity_skew\",\n",
    "    \"feature_strength_mean\",\n",
    "    \"feature_strength_std\",\n",
    "    \"feature_strength_skew\",\n",
    "    \"feature_constitution_mean\",\n",
    "    \"feature_constitution_std\",\n",
    "    \"feature_constitution_skew\",\n",
    "]\n",
    "assert set(group_features_dataf.columns).intersection(new_cols)\n",
    "group_features_dataf.get_feature_data[new_cols].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GroupStatsPreProcessor` should break if `version != 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mGroupStatsPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m332\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m049607\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">GroupStatsPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">332</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">049607</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 36;\n                var nbb_unformatted_code = \"# hide\\ndef test_invalid_version(dataf: NumerFrame):\\n    copied_dataf = dataf.copy()\\n    copied_dataf.version = 2\\n    try:\\n        GroupStatsPreProcessor().transform(copied_dataf)\\n    except AssertionError:\\n        return True\\n    return False\\n\\n\\ntest_invalid_version(dataf)\";\n                var nbb_formatted_code = \"# hide\\ndef test_invalid_version(dataf: NumerFrame):\\n    copied_dataf = dataf.copy()\\n    copied_dataf.version = 2\\n    try:\\n        GroupStatsPreProcessor().transform(copied_dataf)\\n    except AssertionError:\\n        return True\\n    return False\\n\\n\\ntest_invalid_version(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "def test_invalid_version(dataf: NumerFrame):\n",
    "    copied_dataf = dataf.copy()\n",
    "    copied_dataf.version = 2\n",
    "    try:\n",
    "        GroupStatsPreProcessor().transform(copied_dataf)\n",
    "    except AssertionError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "test_invalid_version(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Numerai Classic: Version 2 specific\n",
    "\n",
    "Preprocessors that are only compatible with version 2 data. If the preprocessor is agnostic to Numerai Classic version implement under heading 1.1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 37;\n                var nbb_unformatted_code = \"# 1.1.2\\n# No version 2 specific Numerai Classic preprocessors implemented yet.\";\n                var nbb_formatted_code = \"# 1.1.2\\n# No version 2 specific Numerai Classic preprocessors implemented yet.\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.1.2\n",
    "# No version 2 specific Numerai Classic preprocessors implemented yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Numerai Signals\n",
    "\n",
    "Preprocessors that are specific to Numerai Signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. TA-Lib Features (TalibFeatureGenerator)\n",
    "\n",
    "[TA-Lib](https://mrjbq7.github.io/ta-lib) is an optimized technical analysis library. It is based on Cython and includes 150+ indicators. We have selected features based on feature importances, SHAP and correlation with the Numerai Signals target. If you want to implement other features check out the [TA-Lib documentation](https://mrjbq7.github.io/ta-lib/index.html).\n",
    "\n",
    "Installation of TA-Lib is a bit more involved than just a pip install and is an optional dependency for this library. Visit the [installation documentation](https://mrjbq7.github.io/ta-lib/install.html) for instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 38;\n                var nbb_unformatted_code = \"# export\\nclass TalibFeatureGenerator(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Generate relevant features available in TA-Lib. \\\\n\\n    More info: https://mrjbq7.github.io/ta-lib \\\\n\\n    Input DataFrames for these functions should have the following columns defined:\\n    ['open', 'high', 'low', 'close', 'volume'] \\\\n\\n    Make sure that all values are sorted in chronological order (by ticker). \\\\n\\n    :param windows: List of ranges for window features.\\n    Windows will be applied for all features specified in self.window_features. \\\\n\\n    :param ticker_col: Which column to groupby for feature generation.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, windows: List[int], ticker_col: str = \\\"bloomberg_ticker\\\"):\\n        self.__check_talib_import()\\n        super().__init__()\\n\\n        self.windows = windows\\n        self.ticker_col = ticker_col\\n        self.window_features = [\\n            \\\"NATR\\\",\\n            \\\"ADXR\\\",\\n            \\\"AROONOSC\\\",\\n            \\\"DX\\\",\\n            \\\"MFI\\\",\\n            \\\"MINUS_DI\\\",\\n            \\\"MINUS_DM\\\",\\n            \\\"MOM\\\",\\n            \\\"ROCP\\\",\\n            \\\"ROCR100\\\",\\n            \\\"PLUS_DI\\\",\\n            \\\"PLUS_DM\\\",\\n            \\\"BETA\\\",\\n            \\\"RSI\\\",\\n            \\\"ULTOSC\\\",\\n            \\\"TRIX\\\",\\n            \\\"ADXR\\\",\\n            \\\"CCI\\\",\\n            \\\"CMO\\\",\\n            \\\"WILLR\\\",\\n        ]\\n        self.no_window_features = [\\\"AD\\\", \\\"OBV\\\", \\\"APO\\\", \\\"MACD\\\", \\\"PPO\\\"]\\n        self.hlocv_cols = [\\\"open\\\", \\\"high\\\", \\\"low\\\", \\\"close\\\", \\\"volume\\\"]\\n\\n    def get_no_window_features(self, dataf: pd.DataFrame):\\n        for func in tqdm(self.no_window_features, desc=\\\"No window features\\\"):\\n            dataf.loc[:, f\\\"feature_{func}\\\"] = (\\n                dataf.groupby(self.ticker_col)\\n                .apply(lambda x: pd.Series(self._no_window(x, func)).bfill())\\n                .values.astype(np.float32)\\n            )\\n        return dataf\\n\\n    def get_window_features(self, dataf: pd.DataFrame):\\n        for win in tqdm(self.windows, position=0, desc=\\\"Window features\\\"):\\n            for func in tqdm(self.window_features, position=1):\\n                dataf.loc[:, f\\\"feature_{func}_{win}\\\"] = (\\n                    dataf.groupby(self.ticker_col)\\n                    .apply(lambda x: pd.Series(self._window(x, func, win)).bfill())\\n                    .values.astype(np.float32)\\n                )\\n        return dataf\\n\\n    def get_all_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        dataf = self.get_no_window_features(dataf)\\n        dataf = self.get_window_features(dataf)\\n        return dataf\\n\\n    def transform(self, dataf: pd.DataFrame, *args, **kwargs) -> NumerFrame:\\n        return NumerFrame(self.get_all_features(dataf=dataf))\\n\\n    def _no_window(self, dataf: pd.DataFrame, func) -> pd.Series:\\n        from talib import abstract as tab\\n\\n        inputs = self.__get_inputs(dataf)\\n        if func in [\\\"MACD\\\"]:\\n            # MACD outputs tuple of 3 elements (value, signal and hist)\\n            return tab.Function(func)(inputs[\\\"close\\\"])[0]\\n        else:\\n            return tab.Function(func)(inputs)\\n\\n    def _window(self, dataf: pd.DataFrame, func, window: int) -> pd.Series:\\n        from talib import abstract as tab\\n\\n        inputs = self.__get_inputs(dataf)\\n        if func in [\\\"ULTOSC\\\"]:\\n            # ULTOSC requires 3 timeperiods as input\\n            return tab.Function(func)(\\n                inputs[\\\"high\\\"],\\n                inputs[\\\"low\\\"],\\n                inputs[\\\"close\\\"],\\n                timeperiod1=window,\\n                timeperiod2=window * 2,\\n                timeperiod3=window * 4,\\n            )\\n        else:\\n            return tab.Function(func)(inputs, timeperiod=window)\\n\\n    def __get_inputs(self, dataf: pd.DataFrame) -> dict:\\n        return {col: dataf[col].values.astype(np.float64) for col in self.hlocv_cols}\\n\\n    @staticmethod\\n    def __check_talib_import():\\n        try:\\n            from talib import abstract as tab\\n        except ImportError:\\n            raise ImportError(\\n                \\\"TA-Lib is not installed for this environment. If you are using this class make sure to have TA-Lib installed. check https://mrjbq7.github.io/ta-lib/install.html for instructions on installation.\\\"\\n            )\";\n                var nbb_formatted_code = \"# export\\nclass TalibFeatureGenerator(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Generate relevant features available in TA-Lib. \\\\n\\n    More info: https://mrjbq7.github.io/ta-lib \\\\n\\n    Input DataFrames for these functions should have the following columns defined:\\n    ['open', 'high', 'low', 'close', 'volume'] \\\\n\\n    Make sure that all values are sorted in chronological order (by ticker). \\\\n\\n    :param windows: List of ranges for window features.\\n    Windows will be applied for all features specified in self.window_features. \\\\n\\n    :param ticker_col: Which column to groupby for feature generation.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, windows: List[int], ticker_col: str = \\\"bloomberg_ticker\\\"):\\n        self.__check_talib_import()\\n        super().__init__()\\n\\n        self.windows = windows\\n        self.ticker_col = ticker_col\\n        self.window_features = [\\n            \\\"NATR\\\",\\n            \\\"ADXR\\\",\\n            \\\"AROONOSC\\\",\\n            \\\"DX\\\",\\n            \\\"MFI\\\",\\n            \\\"MINUS_DI\\\",\\n            \\\"MINUS_DM\\\",\\n            \\\"MOM\\\",\\n            \\\"ROCP\\\",\\n            \\\"ROCR100\\\",\\n            \\\"PLUS_DI\\\",\\n            \\\"PLUS_DM\\\",\\n            \\\"BETA\\\",\\n            \\\"RSI\\\",\\n            \\\"ULTOSC\\\",\\n            \\\"TRIX\\\",\\n            \\\"ADXR\\\",\\n            \\\"CCI\\\",\\n            \\\"CMO\\\",\\n            \\\"WILLR\\\",\\n        ]\\n        self.no_window_features = [\\\"AD\\\", \\\"OBV\\\", \\\"APO\\\", \\\"MACD\\\", \\\"PPO\\\"]\\n        self.hlocv_cols = [\\\"open\\\", \\\"high\\\", \\\"low\\\", \\\"close\\\", \\\"volume\\\"]\\n\\n    def get_no_window_features(self, dataf: pd.DataFrame):\\n        for func in tqdm(self.no_window_features, desc=\\\"No window features\\\"):\\n            dataf.loc[:, f\\\"feature_{func}\\\"] = (\\n                dataf.groupby(self.ticker_col)\\n                .apply(lambda x: pd.Series(self._no_window(x, func)).bfill())\\n                .values.astype(np.float32)\\n            )\\n        return dataf\\n\\n    def get_window_features(self, dataf: pd.DataFrame):\\n        for win in tqdm(self.windows, position=0, desc=\\\"Window features\\\"):\\n            for func in tqdm(self.window_features, position=1):\\n                dataf.loc[:, f\\\"feature_{func}_{win}\\\"] = (\\n                    dataf.groupby(self.ticker_col)\\n                    .apply(lambda x: pd.Series(self._window(x, func, win)).bfill())\\n                    .values.astype(np.float32)\\n                )\\n        return dataf\\n\\n    def get_all_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        dataf = self.get_no_window_features(dataf)\\n        dataf = self.get_window_features(dataf)\\n        return dataf\\n\\n    def transform(self, dataf: pd.DataFrame, *args, **kwargs) -> NumerFrame:\\n        return NumerFrame(self.get_all_features(dataf=dataf))\\n\\n    def _no_window(self, dataf: pd.DataFrame, func) -> pd.Series:\\n        from talib import abstract as tab\\n\\n        inputs = self.__get_inputs(dataf)\\n        if func in [\\\"MACD\\\"]:\\n            # MACD outputs tuple of 3 elements (value, signal and hist)\\n            return tab.Function(func)(inputs[\\\"close\\\"])[0]\\n        else:\\n            return tab.Function(func)(inputs)\\n\\n    def _window(self, dataf: pd.DataFrame, func, window: int) -> pd.Series:\\n        from talib import abstract as tab\\n\\n        inputs = self.__get_inputs(dataf)\\n        if func in [\\\"ULTOSC\\\"]:\\n            # ULTOSC requires 3 timeperiods as input\\n            return tab.Function(func)(\\n                inputs[\\\"high\\\"],\\n                inputs[\\\"low\\\"],\\n                inputs[\\\"close\\\"],\\n                timeperiod1=window,\\n                timeperiod2=window * 2,\\n                timeperiod3=window * 4,\\n            )\\n        else:\\n            return tab.Function(func)(inputs, timeperiod=window)\\n\\n    def __get_inputs(self, dataf: pd.DataFrame) -> dict:\\n        return {col: dataf[col].values.astype(np.float64) for col in self.hlocv_cols}\\n\\n    @staticmethod\\n    def __check_talib_import():\\n        try:\\n            from talib import abstract as tab\\n        except ImportError:\\n            raise ImportError(\\n                \\\"TA-Lib is not installed for this environment. If you are using this class make sure to have TA-Lib installed. check https://mrjbq7.github.io/ta-lib/install.html for instructions on installation.\\\"\\n            )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class TalibFeatureGenerator(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Generate relevant features available in TA-Lib. \\n\n",
    "    More info: https://mrjbq7.github.io/ta-lib \\n\n",
    "    Input DataFrames for these functions should have the following columns defined:\n",
    "    ['open', 'high', 'low', 'close', 'volume'] \\n\n",
    "    Make sure that all values are sorted in chronological order (by ticker). \\n\n",
    "    :param windows: List of ranges for window features.\n",
    "    Windows will be applied for all features specified in self.window_features. \\n\n",
    "    :param ticker_col: Which column to groupby for feature generation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, windows: List[int], ticker_col: str = \"bloomberg_ticker\"):\n",
    "        self.__check_talib_import()\n",
    "        super().__init__()\n",
    "\n",
    "        self.windows = windows\n",
    "        self.ticker_col = ticker_col\n",
    "        self.window_features = [\n",
    "            \"NATR\",\n",
    "            \"ADXR\",\n",
    "            \"AROONOSC\",\n",
    "            \"DX\",\n",
    "            \"MFI\",\n",
    "            \"MINUS_DI\",\n",
    "            \"MINUS_DM\",\n",
    "            \"MOM\",\n",
    "            \"ROCP\",\n",
    "            \"ROCR100\",\n",
    "            \"PLUS_DI\",\n",
    "            \"PLUS_DM\",\n",
    "            \"BETA\",\n",
    "            \"RSI\",\n",
    "            \"ULTOSC\",\n",
    "            \"TRIX\",\n",
    "            \"ADXR\",\n",
    "            \"CCI\",\n",
    "            \"CMO\",\n",
    "            \"WILLR\",\n",
    "        ]\n",
    "        self.no_window_features = [\"AD\", \"OBV\", \"APO\", \"MACD\", \"PPO\"]\n",
    "        self.hlocv_cols = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "\n",
    "    def get_no_window_features(self, dataf: pd.DataFrame):\n",
    "        for func in tqdm(self.no_window_features, desc=\"No window features\"):\n",
    "            dataf.loc[:, f\"feature_{func}\"] = (\n",
    "                dataf.groupby(self.ticker_col)\n",
    "                .apply(lambda x: pd.Series(self._no_window(x, func)).bfill())\n",
    "                .values.astype(np.float32)\n",
    "            )\n",
    "        return dataf\n",
    "\n",
    "    def get_window_features(self, dataf: pd.DataFrame):\n",
    "        for win in tqdm(self.windows, position=0, desc=\"Window features\"):\n",
    "            for func in tqdm(self.window_features, position=1):\n",
    "                dataf.loc[:, f\"feature_{func}_{win}\"] = (\n",
    "                    dataf.groupby(self.ticker_col)\n",
    "                    .apply(lambda x: pd.Series(self._window(x, func, win)).bfill())\n",
    "                    .values.astype(np.float32)\n",
    "                )\n",
    "        return dataf\n",
    "\n",
    "    def get_all_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\n",
    "        dataf = self.get_no_window_features(dataf)\n",
    "        dataf = self.get_window_features(dataf)\n",
    "        return dataf\n",
    "\n",
    "    def transform(self, dataf: pd.DataFrame, *args, **kwargs) -> NumerFrame:\n",
    "        return NumerFrame(self.get_all_features(dataf=dataf))\n",
    "\n",
    "    def _no_window(self, dataf: pd.DataFrame, func) -> pd.Series:\n",
    "        from talib import abstract as tab\n",
    "\n",
    "        inputs = self.__get_inputs(dataf)\n",
    "        if func in [\"MACD\"]:\n",
    "            # MACD outputs tuple of 3 elements (value, signal and hist)\n",
    "            return tab.Function(func)(inputs[\"close\"])[0]\n",
    "        else:\n",
    "            return tab.Function(func)(inputs)\n",
    "\n",
    "    def _window(self, dataf: pd.DataFrame, func, window: int) -> pd.Series:\n",
    "        from talib import abstract as tab\n",
    "\n",
    "        inputs = self.__get_inputs(dataf)\n",
    "        if func in [\"ULTOSC\"]:\n",
    "            # ULTOSC requires 3 timeperiods as input\n",
    "            return tab.Function(func)(\n",
    "                inputs[\"high\"],\n",
    "                inputs[\"low\"],\n",
    "                inputs[\"close\"],\n",
    "                timeperiod1=window,\n",
    "                timeperiod2=window * 2,\n",
    "                timeperiod3=window * 4,\n",
    "            )\n",
    "        else:\n",
    "            return tab.Function(func)(inputs, timeperiod=window)\n",
    "\n",
    "    def __get_inputs(self, dataf: pd.DataFrame) -> dict:\n",
    "        return {col: dataf[col].values.astype(np.float64) for col in self.hlocv_cols}\n",
    "\n",
    "    @staticmethod\n",
    "    def __check_talib_import():\n",
    "        try:\n",
    "            from talib import abstract as tab\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"TA-Lib is not installed for this environment. If you are using this class make sure to have TA-Lib installed. check https://mrjbq7.github.io/ta-lib/install.html for instructions on installation.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 39;\n                var nbb_unformatted_code = \"# hide\\n# Example usage\\n# dataf = pd.DataFrame() # Your Signals DataFrame here.\\n# tfg = TalibFeatureGenerator(windows=[10, 20, 40], ticker_col=\\\"bloomberg_ticker\\\")\\n# ta_dataf = tfg.transform(dataf=dataf)\\n# ta_dataf.head(2)\";\n                var nbb_formatted_code = \"# hide\\n# Example usage\\n# dataf = pd.DataFrame() # Your Signals DataFrame here.\\n# tfg = TalibFeatureGenerator(windows=[10, 20, 40], ticker_col=\\\"bloomberg_ticker\\\")\\n# ta_dataf = tfg.transform(dataf=dataf)\\n# ta_dataf.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# Example usage\n",
    "# dataf = pd.DataFrame() # Your Signals DataFrame here.\n",
    "# tfg = TalibFeatureGenerator(windows=[10, 20, 40], ticker_col=\"bloomberg_ticker\")\n",
    "# ta_dataf = tfg.transform(dataf=dataf)\n",
    "# ta_dataf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. KatsuFeatureGenerator\n",
    "\n",
    "[Katsu1110](https://www.kaggle.com/code1110) provides an excellent and fast feature engineering scheme in his [Kaggle notebook on starting with Numerai Signals](https://www.kaggle.com/code1110/numeraisignals-starter-for-beginners). It is surprisingly effective, fast and works well for modeling. This preprocessor is based on his feature engineering setup in that notebook.\n",
    "\n",
    "Features generated:\n",
    "1. MACD and MACD signal\n",
    "2. RSI\n",
    "3. Percentage rate of return\n",
    "4. Volatility\n",
    "5. MA (moving average) gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 40;\n                var nbb_unformatted_code = \"# export\\nclass KatsuFeatureGenerator(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Effective feature engineering setup based on Katsu's starter notebook.\\n    Based on source by Katsu1110: https://www.kaggle.com/code1110/numeraisignals-starter-for-beginners\\n\\n    :param windows: Time interval to apply for window features: \\\\n\\n    1. Percentage Rate of change \\\\n\\n    2. Volatility \\\\n\\n    3. Moving Average gap \\\\n\\n    :param ticker_col: Columns with tickers to iterate over. \\\\n\\n    :param close_col: Column name where you have closing price stored.\\n    \\\"\\\"\\\"\\n\\n    warnings.filterwarnings(\\\"ignore\\\")\\n\\n    def __init__(\\n        self,\\n        windows: list,\\n        ticker_col: str = \\\"ticker\\\",\\n        close_col: str = \\\"close\\\",\\n        num_cores: int = None,\\n    ):\\n        super().__init__()\\n        self.windows = windows\\n        self.ticker_col = ticker_col\\n        self.close_col = close_col\\n        self.num_cores = num_cores if num_cores else os.cpu_count()\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        \\\"\\\"\\\"Multiprocessing feature engineering.\\\"\\\"\\\"\\n        tickers = dataf.loc[:, self.ticker_col].unique().tolist()\\n        rich_print(\\n            f\\\"Feature engineering for {len(tickers)} tickers using {self.num_cores} CPU cores.\\\"\\n        )\\n        dataf_list = [\\n            x\\n            for _, x in tqdm(\\n                dataf.groupby(self.ticker_col), desc=\\\"Generating ticker DataFrames\\\"\\n            )\\n        ]\\n        dataf = self._generate_features(dataf_list=dataf_list)\\n        return NumerFrame(dataf)\\n\\n    def feature_engineering(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"Feature engineering for single ticker.\\\"\\\"\\\"\\n        close_series = dataf.loc[:, self.close_col]\\n        for x in self.windows:\\n            dataf.loc[\\n                :, f\\\"feature_{self.close_col}_ROCP_{x}\\\"\\n            ] = close_series.pct_change(x)\\n\\n            dataf.loc[:, f\\\"feature_{self.close_col}_VOL_{x}\\\"] = (\\n                np.log1p(close_series).pct_change().rolling(x).std()\\n            )\\n\\n            dataf.loc[:, f\\\"feature_{self.close_col}_MA_gap_{x}\\\"] = (\\n                close_series / close_series.rolling(x).mean()\\n            )\\n\\n        dataf.loc[:, \\\"feature_RSI\\\"] = self._rsi(close_series)\\n        macd, macd_signal = self._macd(close_series)\\n        dataf.loc[:, \\\"feature_MACD\\\"] = macd\\n        dataf.loc[:, \\\"feature_MACD_signal\\\"] = macd_signal\\n        return dataf.bfill()\\n\\n    def _generate_features(self, dataf_list: list) -> pd.DataFrame:\\n        \\\"\\\"\\\"Add features for list of ticker DataFrames and concatenate.\\\"\\\"\\\"\\n        with Pool(self.num_cores) as p:\\n            feature_datafs = list(\\n                tqdm(\\n                    p.imap(self.feature_engineering, dataf_list),\\n                    desc=\\\"Generating features\\\",\\n                    total=len(dataf_list),\\n                )\\n            )\\n        return pd.concat(feature_datafs)\\n\\n    @staticmethod\\n    def _rsi(close: pd.Series, period: int = 14) -> pd.Series:\\n        \\\"\\\"\\\"\\n        See source https://github.com/peerchemist/finta\\n        and fix https://www.tradingview.com/wiki/Talk:Relative_Strength_Index_(RSI)\\n        \\\"\\\"\\\"\\n        delta = close.diff()\\n        up, down = delta.copy(), delta.copy()\\n        up[up < 0] = 0\\n        down[down > 0] = 0\\n\\n        gain = up.ewm(com=(period - 1), min_periods=period).mean()\\n        loss = down.abs().ewm(com=(period - 1), min_periods=period).mean()\\n\\n        rs = gain / loss\\n        return pd.Series(100 - (100 / (1 + rs)))\\n\\n    def _macd(\\n        self, close: pd.Series, span1=12, span2=26, span3=9\\n    ) -> Tuple[pd.Series, pd.Series]:\\n        \\\"\\\"\\\"Compute MACD and MACD signal.\\\"\\\"\\\"\\n        exp1 = self.__ema1(close, span1)\\n        exp2 = self.__ema1(close, span2)\\n        macd = 100 * (exp1 - exp2) / exp2\\n        signal = self.__ema1(macd, span3)\\n        return macd, signal\\n\\n    @staticmethod\\n    def __ema1(series: pd.Series, span: int) -> pd.Series:\\n        \\\"\\\"\\\"Exponential moving average\\\"\\\"\\\"\\n        a = 2 / (span + 1)\\n        return series.ewm(alpha=a).mean()\";\n                var nbb_formatted_code = \"# export\\nclass KatsuFeatureGenerator(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Effective feature engineering setup based on Katsu's starter notebook.\\n    Based on source by Katsu1110: https://www.kaggle.com/code1110/numeraisignals-starter-for-beginners\\n\\n    :param windows: Time interval to apply for window features: \\\\n\\n    1. Percentage Rate of change \\\\n\\n    2. Volatility \\\\n\\n    3. Moving Average gap \\\\n\\n    :param ticker_col: Columns with tickers to iterate over. \\\\n\\n    :param close_col: Column name where you have closing price stored.\\n    \\\"\\\"\\\"\\n\\n    warnings.filterwarnings(\\\"ignore\\\")\\n\\n    def __init__(\\n        self,\\n        windows: list,\\n        ticker_col: str = \\\"ticker\\\",\\n        close_col: str = \\\"close\\\",\\n        num_cores: int = None,\\n    ):\\n        super().__init__()\\n        self.windows = windows\\n        self.ticker_col = ticker_col\\n        self.close_col = close_col\\n        self.num_cores = num_cores if num_cores else os.cpu_count()\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        \\\"\\\"\\\"Multiprocessing feature engineering.\\\"\\\"\\\"\\n        tickers = dataf.loc[:, self.ticker_col].unique().tolist()\\n        rich_print(\\n            f\\\"Feature engineering for {len(tickers)} tickers using {self.num_cores} CPU cores.\\\"\\n        )\\n        dataf_list = [\\n            x\\n            for _, x in tqdm(\\n                dataf.groupby(self.ticker_col), desc=\\\"Generating ticker DataFrames\\\"\\n            )\\n        ]\\n        dataf = self._generate_features(dataf_list=dataf_list)\\n        return NumerFrame(dataf)\\n\\n    def feature_engineering(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"Feature engineering for single ticker.\\\"\\\"\\\"\\n        close_series = dataf.loc[:, self.close_col]\\n        for x in self.windows:\\n            dataf.loc[\\n                :, f\\\"feature_{self.close_col}_ROCP_{x}\\\"\\n            ] = close_series.pct_change(x)\\n\\n            dataf.loc[:, f\\\"feature_{self.close_col}_VOL_{x}\\\"] = (\\n                np.log1p(close_series).pct_change().rolling(x).std()\\n            )\\n\\n            dataf.loc[:, f\\\"feature_{self.close_col}_MA_gap_{x}\\\"] = (\\n                close_series / close_series.rolling(x).mean()\\n            )\\n\\n        dataf.loc[:, \\\"feature_RSI\\\"] = self._rsi(close_series)\\n        macd, macd_signal = self._macd(close_series)\\n        dataf.loc[:, \\\"feature_MACD\\\"] = macd\\n        dataf.loc[:, \\\"feature_MACD_signal\\\"] = macd_signal\\n        return dataf.bfill()\\n\\n    def _generate_features(self, dataf_list: list) -> pd.DataFrame:\\n        \\\"\\\"\\\"Add features for list of ticker DataFrames and concatenate.\\\"\\\"\\\"\\n        with Pool(self.num_cores) as p:\\n            feature_datafs = list(\\n                tqdm(\\n                    p.imap(self.feature_engineering, dataf_list),\\n                    desc=\\\"Generating features\\\",\\n                    total=len(dataf_list),\\n                )\\n            )\\n        return pd.concat(feature_datafs)\\n\\n    @staticmethod\\n    def _rsi(close: pd.Series, period: int = 14) -> pd.Series:\\n        \\\"\\\"\\\"\\n        See source https://github.com/peerchemist/finta\\n        and fix https://www.tradingview.com/wiki/Talk:Relative_Strength_Index_(RSI)\\n        \\\"\\\"\\\"\\n        delta = close.diff()\\n        up, down = delta.copy(), delta.copy()\\n        up[up < 0] = 0\\n        down[down > 0] = 0\\n\\n        gain = up.ewm(com=(period - 1), min_periods=period).mean()\\n        loss = down.abs().ewm(com=(period - 1), min_periods=period).mean()\\n\\n        rs = gain / loss\\n        return pd.Series(100 - (100 / (1 + rs)))\\n\\n    def _macd(\\n        self, close: pd.Series, span1=12, span2=26, span3=9\\n    ) -> Tuple[pd.Series, pd.Series]:\\n        \\\"\\\"\\\"Compute MACD and MACD signal.\\\"\\\"\\\"\\n        exp1 = self.__ema1(close, span1)\\n        exp2 = self.__ema1(close, span2)\\n        macd = 100 * (exp1 - exp2) / exp2\\n        signal = self.__ema1(macd, span3)\\n        return macd, signal\\n\\n    @staticmethod\\n    def __ema1(series: pd.Series, span: int) -> pd.Series:\\n        \\\"\\\"\\\"Exponential moving average\\\"\\\"\\\"\\n        a = 2 / (span + 1)\\n        return series.ewm(alpha=a).mean()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class KatsuFeatureGenerator(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Effective feature engineering setup based on Katsu's starter notebook.\n",
    "    Based on source by Katsu1110: https://www.kaggle.com/code1110/numeraisignals-starter-for-beginners\n",
    "\n",
    "    :param windows: Time interval to apply for window features: \\n\n",
    "    1. Percentage Rate of change \\n\n",
    "    2. Volatility \\n\n",
    "    3. Moving Average gap \\n\n",
    "    :param ticker_col: Columns with tickers to iterate over. \\n\n",
    "    :param close_col: Column name where you have closing price stored.\n",
    "    \"\"\"\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        windows: list,\n",
    "        ticker_col: str = \"ticker\",\n",
    "        close_col: str = \"close\",\n",
    "        num_cores: int = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.windows = windows\n",
    "        self.ticker_col = ticker_col\n",
    "        self.close_col = close_col\n",
    "        self.num_cores = num_cores if num_cores else os.cpu_count()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        \"\"\"Multiprocessing feature engineering.\"\"\"\n",
    "        tickers = dataf.loc[:, self.ticker_col].unique().tolist()\n",
    "        rich_print(\n",
    "            f\"Feature engineering for {len(tickers)} tickers using {self.num_cores} CPU cores.\"\n",
    "        )\n",
    "        dataf_list = [\n",
    "            x\n",
    "            for _, x in tqdm(\n",
    "                dataf.groupby(self.ticker_col), desc=\"Generating ticker DataFrames\"\n",
    "            )\n",
    "        ]\n",
    "        dataf = self._generate_features(dataf_list=dataf_list)\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def feature_engineering(self, dataf: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Feature engineering for single ticker.\"\"\"\n",
    "        close_series = dataf.loc[:, self.close_col]\n",
    "        for x in self.windows:\n",
    "            dataf.loc[\n",
    "                :, f\"feature_{self.close_col}_ROCP_{x}\"\n",
    "            ] = close_series.pct_change(x)\n",
    "\n",
    "            dataf.loc[:, f\"feature_{self.close_col}_VOL_{x}\"] = (\n",
    "                np.log1p(close_series).pct_change().rolling(x).std()\n",
    "            )\n",
    "\n",
    "            dataf.loc[:, f\"feature_{self.close_col}_MA_gap_{x}\"] = (\n",
    "                close_series / close_series.rolling(x).mean()\n",
    "            )\n",
    "\n",
    "        dataf.loc[:, \"feature_RSI\"] = self._rsi(close_series)\n",
    "        macd, macd_signal = self._macd(close_series)\n",
    "        dataf.loc[:, \"feature_MACD\"] = macd\n",
    "        dataf.loc[:, \"feature_MACD_signal\"] = macd_signal\n",
    "        return dataf.bfill()\n",
    "\n",
    "    def _generate_features(self, dataf_list: list) -> pd.DataFrame:\n",
    "        \"\"\"Add features for list of ticker DataFrames and concatenate.\"\"\"\n",
    "        with Pool(self.num_cores) as p:\n",
    "            feature_datafs = list(\n",
    "                tqdm(\n",
    "                    p.imap(self.feature_engineering, dataf_list),\n",
    "                    desc=\"Generating features\",\n",
    "                    total=len(dataf_list),\n",
    "                )\n",
    "            )\n",
    "        return pd.concat(feature_datafs)\n",
    "\n",
    "    @staticmethod\n",
    "    def _rsi(close: pd.Series, period: int = 14) -> pd.Series:\n",
    "        \"\"\"\n",
    "        See source https://github.com/peerchemist/finta\n",
    "        and fix https://www.tradingview.com/wiki/Talk:Relative_Strength_Index_(RSI)\n",
    "        \"\"\"\n",
    "        delta = close.diff()\n",
    "        up, down = delta.copy(), delta.copy()\n",
    "        up[up < 0] = 0\n",
    "        down[down > 0] = 0\n",
    "\n",
    "        gain = up.ewm(com=(period - 1), min_periods=period).mean()\n",
    "        loss = down.abs().ewm(com=(period - 1), min_periods=period).mean()\n",
    "\n",
    "        rs = gain / loss\n",
    "        return pd.Series(100 - (100 / (1 + rs)))\n",
    "\n",
    "    def _macd(\n",
    "        self, close: pd.Series, span1=12, span2=26, span3=9\n",
    "    ) -> Tuple[pd.Series, pd.Series]:\n",
    "        \"\"\"Compute MACD and MACD signal.\"\"\"\n",
    "        exp1 = self.__ema1(close, span1)\n",
    "        exp2 = self.__ema1(close, span2)\n",
    "        macd = 100 * (exp1 - exp2) / exp2\n",
    "        signal = self.__ema1(macd, span3)\n",
    "        return macd, signal\n",
    "\n",
    "    @staticmethod\n",
    "    def __ema1(series: pd.Series, span: int) -> pd.Series:\n",
    "        \"\"\"Exponential moving average\"\"\"\n",
    "        a = 2 / (span + 1)\n",
    "        return series.ewm(alpha=a).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "No existing directory found at \u001B[32m'\u001B[0m\u001B[34mkatsu_features_test\u001B[0m\u001B[32m'\u001B[0m. Creating directory\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">katsu_features_test</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 41;\n                var nbb_unformatted_code = \"# other\\nfrom numerblox.download import KaggleDownloader\\n\\n# Get price data from Kaggle\\nhome_dir = \\\"katsu_features_test/\\\"\\nkd = KaggleDownloader(home_dir)\\nkd.download_training_data(\\\"code1110/yfinance-stock-price-data-for-numerai-signals\\\")\";\n                var nbb_formatted_code = \"# other\\nfrom numerblox.download import KaggleDownloader\\n\\n# Get price data from Kaggle\\nhome_dir = \\\"katsu_features_test/\\\"\\nkd = KaggleDownloader(home_dir)\\nkd.download_training_data(\\\"code1110/yfinance-stock-price-data-for-numerai-signals\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "from numerblox.download import KaggleDownloader\n",
    "\n",
    "# Get price data from Kaggle\n",
    "home_dir = \"katsu_features_test/\"\n",
    "kd = KaggleDownloader(home_dir)\n",
    "kd.download_training_data(\"code1110/yfinance-stock-price-data-for-numerai-signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 42;\n                var nbb_unformatted_code = \"# other\\ndataf = create_numerframe(f\\\"{home_dir}/full_data.parquet\\\")\\ndataf.loc[:, \\\"friday_date\\\"] = dataf[\\\"date\\\"]\\n# Take 500 ticker sample for test\\ndataf = dataf[dataf[\\\"ticker\\\"].isin(dataf[\\\"ticker\\\"].unique()[:500])]\";\n                var nbb_formatted_code = \"# other\\ndataf = create_numerframe(f\\\"{home_dir}/full_data.parquet\\\")\\ndataf.loc[:, \\\"friday_date\\\"] = dataf[\\\"date\\\"]\\n# Take 500 ticker sample for test\\ndataf = dataf[dataf[\\\"ticker\\\"].isin(dataf[\\\"ticker\\\"].unique()[:500])]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "dataf = create_numerframe(f\"{home_dir}/full_data.parquet\")\n",
    "dataf.loc[:, \"friday_date\"] = dataf[\"date\"]\n",
    "# Take 500 ticker sample for test\n",
    "dataf = dataf[dataf[\"ticker\"].isin(dataf[\"ticker\"].unique()[:500])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Feature engineering for \u001B[1;36m500\u001B[0m tickers using \u001B[1;36m8\u001B[0m CPU cores.\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Feature engineering for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span> tickers using <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> CPU cores.\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating ticker DataFrames:   0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f05278bc45e4d1d9acb65b1b24ee771"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 18:35:32,931 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-05-26 18:35:32,937 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating features:   0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e048062dd7184794bbf2bc975793e87e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 18:35:32,937 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-05-26 18:35:32,942 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "2022-05-26 18:35:32,945 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-05-26 18:35:32,951 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "2022-05-26 18:35:32,953 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-05-26 18:35:32,960 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "2022-05-26 18:35:32,962 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-05-26 18:35:32,968 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "2022-05-26 18:35:32,973 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-05-26 18:35:32,980 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "2022-05-26 18:35:32,981 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-05-26 18:35:32,988 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "2022-05-26 18:35:32,987 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-05-26 18:35:32,994 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mKatsuFeatureGenerator\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m1977266\u001B[0m, \u001B[1;36m21\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:06\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m242101\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">KatsuFeatureGenerator</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1977266</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:06</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">242101</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 43;\n                var nbb_unformatted_code = \"# other\\nkfpp = KatsuFeatureGenerator(windows=[20, 40, 60], num_cores=8)\\nnew_dataf = kfpp.transform(dataf)\";\n                var nbb_formatted_code = \"# other\\nkfpp = KatsuFeatureGenerator(windows=[20, 40, 60], num_cores=8)\\nnew_dataf = kfpp.transform(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "kfpp = KatsuFeatureGenerator(windows=[20, 40, 60], num_cores=8)\n",
    "new_dataf = kfpp.transform(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 features are generated in this test (3*3 window features + 3 non window features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         feature_close_ROCP_20  feature_close_VOL_20  feature_close_MA_gap_20  \\\n1977264               0.077144              0.001958                 1.033635   \n1977265               0.051667              0.001904                 1.026899   \n\n         feature_close_ROCP_40  feature_close_VOL_40  feature_close_MA_gap_40  \\\n1977264               0.067426              0.001993                 1.063790   \n1977265               0.070268              0.001989                 1.057691   \n\n         feature_close_ROCP_60  feature_close_VOL_60  feature_close_MA_gap_60  \\\n1977264              -0.023033              0.002412                 1.059153   \n1977265              -0.038643              0.002404                 1.055659   \n\n         feature_RSI  feature_MACD  feature_MACD_signal  \n1977264    60.233996      1.701916             1.214393  \n1977265    58.878408      1.692849             1.310084  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_close_ROCP_20</th>\n      <th>feature_close_VOL_20</th>\n      <th>feature_close_MA_gap_20</th>\n      <th>feature_close_ROCP_40</th>\n      <th>feature_close_VOL_40</th>\n      <th>feature_close_MA_gap_40</th>\n      <th>feature_close_ROCP_60</th>\n      <th>feature_close_VOL_60</th>\n      <th>feature_close_MA_gap_60</th>\n      <th>feature_RSI</th>\n      <th>feature_MACD</th>\n      <th>feature_MACD_signal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1977264</th>\n      <td>0.077144</td>\n      <td>0.001958</td>\n      <td>1.033635</td>\n      <td>0.067426</td>\n      <td>0.001993</td>\n      <td>1.063790</td>\n      <td>-0.023033</td>\n      <td>0.002412</td>\n      <td>1.059153</td>\n      <td>60.233996</td>\n      <td>1.701916</td>\n      <td>1.214393</td>\n    </tr>\n    <tr>\n      <th>1977265</th>\n      <td>0.051667</td>\n      <td>0.001904</td>\n      <td>1.026899</td>\n      <td>0.070268</td>\n      <td>0.001989</td>\n      <td>1.057691</td>\n      <td>-0.038643</td>\n      <td>0.002404</td>\n      <td>1.055659</td>\n      <td>58.878408</td>\n      <td>1.692849</td>\n      <td>1.310084</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 44;\n                var nbb_unformatted_code = \"# other\\nnew_dataf.sort_values([\\\"ticker\\\", \\\"date\\\"]).get_feature_data.tail(2)\";\n                var nbb_formatted_code = \"# other\\nnew_dataf.sort_values([\\\"ticker\\\", \\\"date\\\"]).get_feature_data.tail(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "new_dataf.sort_values([\"ticker\", \"date\"]).get_feature_data.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. EraQuantileProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerai Signals' objective is predicting a ranking of equities. Therefore, we can benefit from creating rankings out of the features. Doing this reduces noise and works as a normalization mechanism for your features. `EraQuantileProcessor` bins features in a given number of quantiles for each era in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 45;\n                var nbb_unformatted_code = \"# export\\nclass EraQuantileProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Transform features into quantiles on a per-era basis\\n\\n    :param num_quantiles: Number of buckets to split data into. \\\\n\\n    :param era_col: Era column name in the dataframe to perform each transformation. \\\\n\\n    :param features: All features that you want quantized. All feature cols by default. \\\\n\\n    :param num_cores: CPU cores to allocate for quantile transforming. All available cores by default. \\\\n\\n    :param random_state: Seed for QuantileTransformer.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        num_quantiles: int = 50,\\n        era_col: str = \\\"friday_date\\\",\\n        features: list = None,\\n        num_cores: int = None,\\n        random_state: int = 0,\\n    ):\\n        super().__init__()\\n        self.num_quantiles = num_quantiles\\n        self.era_col = era_col\\n        self.num_cores = num_cores if num_cores else os.cpu_count()\\n        self.features = features\\n        self.random_state = random_state\\n\\n    def _process_eras(self, groupby_object):\\n        quantizer = QuantileTransformer(\\n            n_quantiles=self.num_quantiles, random_state=self.random_state\\n        )\\n        qt = lambda x: quantizer.fit_transform(x.values.reshape(-1, 1)).ravel()\\n\\n        column = groupby_object.transform(qt)\\n        return column\\n\\n    @display_processor_info\\n    def transform(\\n        self,\\n        dataf: Union[pd.DataFrame, NumerFrame],\\n    ) -> NumerFrame:\\n        \\\"\\\"\\\"Multiprocessing quantile transforms by era.\\\"\\\"\\\"\\n        self.features = self.features if self.features else dataf.feature_cols\\n        rich_print(\\n            f\\\"Quantiling for {len(self.features)} features using {self.num_cores} CPU cores.\\\"\\n        )\\n\\n        date_groups = dataf.groupby(self.era_col)\\n        groupby_objects = [date_groups[feature] for feature in self.features]\\n\\n        with Pool() as p:\\n            results = list(\\n                tqdm(\\n                    p.imap(self._process_eras, groupby_objects),\\n                    total=len(groupby_objects),\\n                )\\n            )\\n\\n        quantiles = pd.concat(results, axis=1)\\n        dataf[\\n            [f\\\"{feature}_quantile{self.num_quantiles}\\\" for feature in self.features]\\n        ] = quantiles\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\nclass EraQuantileProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Transform features into quantiles on a per-era basis\\n\\n    :param num_quantiles: Number of buckets to split data into. \\\\n\\n    :param era_col: Era column name in the dataframe to perform each transformation. \\\\n\\n    :param features: All features that you want quantized. All feature cols by default. \\\\n\\n    :param num_cores: CPU cores to allocate for quantile transforming. All available cores by default. \\\\n\\n    :param random_state: Seed for QuantileTransformer.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        num_quantiles: int = 50,\\n        era_col: str = \\\"friday_date\\\",\\n        features: list = None,\\n        num_cores: int = None,\\n        random_state: int = 0,\\n    ):\\n        super().__init__()\\n        self.num_quantiles = num_quantiles\\n        self.era_col = era_col\\n        self.num_cores = num_cores if num_cores else os.cpu_count()\\n        self.features = features\\n        self.random_state = random_state\\n\\n    def _process_eras(self, groupby_object):\\n        quantizer = QuantileTransformer(\\n            n_quantiles=self.num_quantiles, random_state=self.random_state\\n        )\\n        qt = lambda x: quantizer.fit_transform(x.values.reshape(-1, 1)).ravel()\\n\\n        column = groupby_object.transform(qt)\\n        return column\\n\\n    @display_processor_info\\n    def transform(\\n        self,\\n        dataf: Union[pd.DataFrame, NumerFrame],\\n    ) -> NumerFrame:\\n        \\\"\\\"\\\"Multiprocessing quantile transforms by era.\\\"\\\"\\\"\\n        self.features = self.features if self.features else dataf.feature_cols\\n        rich_print(\\n            f\\\"Quantiling for {len(self.features)} features using {self.num_cores} CPU cores.\\\"\\n        )\\n\\n        date_groups = dataf.groupby(self.era_col)\\n        groupby_objects = [date_groups[feature] for feature in self.features]\\n\\n        with Pool() as p:\\n            results = list(\\n                tqdm(\\n                    p.imap(self._process_eras, groupby_objects),\\n                    total=len(groupby_objects),\\n                )\\n            )\\n\\n        quantiles = pd.concat(results, axis=1)\\n        dataf[\\n            [f\\\"{feature}_quantile{self.num_quantiles}\\\" for feature in self.features]\\n        ] = quantiles\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class EraQuantileProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Transform features into quantiles on a per-era basis\n",
    "\n",
    "    :param num_quantiles: Number of buckets to split data into. \\n\n",
    "    :param era_col: Era column name in the dataframe to perform each transformation. \\n\n",
    "    :param features: All features that you want quantized. All feature cols by default. \\n\n",
    "    :param num_cores: CPU cores to allocate for quantile transforming. All available cores by default. \\n\n",
    "    :param random_state: Seed for QuantileTransformer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_quantiles: int = 50,\n",
    "        era_col: str = \"friday_date\",\n",
    "        features: list = None,\n",
    "        num_cores: int = None,\n",
    "        random_state: int = 0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_quantiles = num_quantiles\n",
    "        self.era_col = era_col\n",
    "        self.num_cores = num_cores if num_cores else os.cpu_count()\n",
    "        self.features = features\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def _process_eras(self, groupby_object):\n",
    "        quantizer = QuantileTransformer(\n",
    "            n_quantiles=self.num_quantiles, random_state=self.random_state\n",
    "        )\n",
    "        qt = lambda x: quantizer.fit_transform(x.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "        column = groupby_object.transform(qt)\n",
    "        return column\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(\n",
    "        self,\n",
    "        dataf: Union[pd.DataFrame, NumerFrame],\n",
    "    ) -> NumerFrame:\n",
    "        \"\"\"Multiprocessing quantile transforms by era.\"\"\"\n",
    "        self.features = self.features if self.features else dataf.feature_cols\n",
    "        rich_print(\n",
    "            f\"Quantiling for {len(self.features)} features using {self.num_cores} CPU cores.\"\n",
    "        )\n",
    "\n",
    "        date_groups = dataf.groupby(self.era_col)\n",
    "        groupby_objects = [date_groups[feature] for feature in self.features]\n",
    "\n",
    "        with Pool() as p:\n",
    "            results = list(\n",
    "                tqdm(\n",
    "                    p.imap(self._process_eras, groupby_objects),\n",
    "                    total=len(groupby_objects),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        quantiles = pd.concat(results, axis=1)\n",
    "        dataf[\n",
    "            [f\"{feature}_quantile{self.num_quantiles}\" for feature in self.features]\n",
    "        ] = quantiles\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Quantiling for \u001B[1;36m12\u001B[0m features using \u001B[1;36m16\u001B[0m CPU cores.\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Quantiling for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> features using <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> CPU cores.\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/12 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56083320809644b491a1e3cda7964414"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mEraQuantileProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10000\u001B[0m, \u001B[1;36m33\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:10\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m203531\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">EraQuantileProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:10</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">203531</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 46;\n                var nbb_unformatted_code = \"# other\\nnew_dataf = new_dataf.sample(10000)\\nera_quantiler = EraQuantileProcessor(num_quantiles=50)\\nera_dataf = era_quantiler.transform(new_dataf)\";\n                var nbb_formatted_code = \"# other\\nnew_dataf = new_dataf.sample(10000)\\nera_quantiler = EraQuantileProcessor(num_quantiles=50)\\nera_dataf = era_quantiler.transform(new_dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "new_dataf = new_dataf.sample(10000)\n",
    "era_quantiler = EraQuantileProcessor(num_quantiles=50)\n",
    "era_dataf = era_quantiler.transform(new_dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         feature_close_ROCP_20  feature_close_VOL_20  feature_close_MA_gap_20  \\\n940379                0.145235              0.003546                 1.104706   \n1742422               0.069231              0.007560                 1.028868   \n\n         feature_close_ROCP_40  feature_close_VOL_40  feature_close_MA_gap_40  \\\n940379                0.109971              0.003225                 1.116272   \n1742422               0.125506              0.007451                 1.055629   \n\n         feature_close_ROCP_60  feature_close_VOL_60  feature_close_MA_gap_60  \\\n940379                0.143504              0.002889                 1.113181   \n1742422               0.007246              0.008667                 1.053163   \n\n         feature_RSI  ...  feature_close_MA_gap_20_quantile50  \\\n940379     74.316053  ...                                 1.0   \n1742422    59.981264  ...                                 1.0   \n\n         feature_close_ROCP_40_quantile50  feature_close_VOL_40_quantile50  \\\n940379                                0.0                              1.0   \n1742422                               0.5                              1.0   \n\n         feature_close_MA_gap_40_quantile50  feature_close_ROCP_60_quantile50  \\\n940379                                  1.0                               0.0   \n1742422                                 0.5                               0.5   \n\n         feature_close_VOL_60_quantile50  feature_close_MA_gap_60_quantile50  \\\n940379                               1.0                                 0.0   \n1742422                              1.0                                 0.5   \n\n         feature_RSI_quantile50  feature_MACD_quantile50  \\\n940379                      1.0                      0.0   \n1742422                     1.0                      0.5   \n\n         feature_MACD_signal_quantile50  \n940379                              0.0  \n1742422                             0.5  \n\n[2 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_close_ROCP_20</th>\n      <th>feature_close_VOL_20</th>\n      <th>feature_close_MA_gap_20</th>\n      <th>feature_close_ROCP_40</th>\n      <th>feature_close_VOL_40</th>\n      <th>feature_close_MA_gap_40</th>\n      <th>feature_close_ROCP_60</th>\n      <th>feature_close_VOL_60</th>\n      <th>feature_close_MA_gap_60</th>\n      <th>feature_RSI</th>\n      <th>...</th>\n      <th>feature_close_MA_gap_20_quantile50</th>\n      <th>feature_close_ROCP_40_quantile50</th>\n      <th>feature_close_VOL_40_quantile50</th>\n      <th>feature_close_MA_gap_40_quantile50</th>\n      <th>feature_close_ROCP_60_quantile50</th>\n      <th>feature_close_VOL_60_quantile50</th>\n      <th>feature_close_MA_gap_60_quantile50</th>\n      <th>feature_RSI_quantile50</th>\n      <th>feature_MACD_quantile50</th>\n      <th>feature_MACD_signal_quantile50</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>940379</th>\n      <td>0.145235</td>\n      <td>0.003546</td>\n      <td>1.104706</td>\n      <td>0.109971</td>\n      <td>0.003225</td>\n      <td>1.116272</td>\n      <td>0.143504</td>\n      <td>0.002889</td>\n      <td>1.113181</td>\n      <td>74.316053</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1742422</th>\n      <td>0.069231</td>\n      <td>0.007560</td>\n      <td>1.028868</td>\n      <td>0.125506</td>\n      <td>0.007451</td>\n      <td>1.055629</td>\n      <td>0.007246</td>\n      <td>0.008667</td>\n      <td>1.053163</td>\n      <td>59.981264</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 47;\n                var nbb_unformatted_code = \"# other\\nera_dataf.get_feature_data.tail(2)\";\n                var nbb_formatted_code = \"# other\\nera_dataf.get_feature_data.tail(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "era_dataf.get_feature_data.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "⚠ \u001B[31mDeleting directory for \u001B[0m\u001B[31m'KaggleDownloader\u001B[0m\u001B[32m'\u001B[0m ⚠\nPath: \n\u001B[32m'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/katsu_features_test'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">⚠ <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'KaggleDownloader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> ⚠\nPath: \n<span style=\"color: #008000; text-decoration-color: #008000\">'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/katsu_features_test'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 48;\n                var nbb_unformatted_code = \"# other\\n# hide\\nkd.remove_base_directory()\";\n                var nbb_formatted_code = \"# other\\n# hide\\nkd.remove_base_directory()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "# hide\n",
    "kd.remove_base_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4. TickerMapper\n",
    "\n",
    "Numerai Signals data APIs may work with different ticker formats. Our goal with `TickerMapper` is to map `ticker_col` to `target_ticker_format`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 49;\n                var nbb_unformatted_code = \"# export\\nclass TickerMapper(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Map ticker from one format to another. \\\\n\\n    :param ticker_col: Column used for mapping. Must already be present in the input data. \\\\n\\n    :param target_ticker_format: Format to map tickers to. Must be present in the ticker map. \\\\n\\n    For default mapper supported ticker formats are: ['ticker', 'bloomberg_ticker', 'yahoo'] \\\\n\\n    :param mapper_path: Path to CSV file containing at least ticker_col and target_ticker_format columns. \\\\n\\n    Can be either a web link of local path. Numerai Signals mapping by default.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self, ticker_col: str = \\\"ticker\\\", target_ticker_format: str = \\\"bloomberg_ticker\\\",\\n        mapper_path: str = \\\"https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_ticker_map_w_bbg.csv\\\"\\n    ):\\n        super().__init__()\\n        self.ticker_col = ticker_col\\n        self.target_ticker_format = target_ticker_format\\n\\n        self.signals_map_path = mapper_path\\n        self.ticker_map = pd.read_csv(self.signals_map_path)\\n\\n        assert (\\n            self.ticker_col in self.ticker_map.columns\\n        ), f\\\"Ticker column '{self.ticker_col}' is not available in ticker mapping.\\\"\\n        assert (\\n            self.target_ticker_format in self.ticker_map.columns\\n        ), f\\\"Target ticker column '{self.target_ticker_format}' is not available in ticker mapping.\\\"\\n\\n        self.mapping = dict(\\n            self.ticker_map[[self.ticker_col, self.target_ticker_format]].values\\n        )\\n\\n    @display_processor_info\\n    def transform(\\n        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        dataf[self.target_ticker_format] = dataf[self.ticker_col].map(self.mapping)\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\nclass TickerMapper(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Map ticker from one format to another. \\\\n\\n    :param ticker_col: Column used for mapping. Must already be present in the input data. \\\\n\\n    :param target_ticker_format: Format to map tickers to. Must be present in the ticker map. \\\\n\\n    For default mapper supported ticker formats are: ['ticker', 'bloomberg_ticker', 'yahoo'] \\\\n\\n    :param mapper_path: Path to CSV file containing at least ticker_col and target_ticker_format columns. \\\\n\\n    Can be either a web link of local path. Numerai Signals mapping by default.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        ticker_col: str = \\\"ticker\\\",\\n        target_ticker_format: str = \\\"bloomberg_ticker\\\",\\n        mapper_path: str = \\\"https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_ticker_map_w_bbg.csv\\\",\\n    ):\\n        super().__init__()\\n        self.ticker_col = ticker_col\\n        self.target_ticker_format = target_ticker_format\\n\\n        self.signals_map_path = mapper_path\\n        self.ticker_map = pd.read_csv(self.signals_map_path)\\n\\n        assert (\\n            self.ticker_col in self.ticker_map.columns\\n        ), f\\\"Ticker column '{self.ticker_col}' is not available in ticker mapping.\\\"\\n        assert (\\n            self.target_ticker_format in self.ticker_map.columns\\n        ), f\\\"Target ticker column '{self.target_ticker_format}' is not available in ticker mapping.\\\"\\n\\n        self.mapping = dict(\\n            self.ticker_map[[self.ticker_col, self.target_ticker_format]].values\\n        )\\n\\n    @display_processor_info\\n    def transform(\\n        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        dataf[self.target_ticker_format] = dataf[self.ticker_col].map(self.mapping)\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class TickerMapper(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Map ticker from one format to another. \\n\n",
    "    :param ticker_col: Column used for mapping. Must already be present in the input data. \\n\n",
    "    :param target_ticker_format: Format to map tickers to. Must be present in the ticker map. \\n\n",
    "    For default mapper supported ticker formats are: ['ticker', 'bloomberg_ticker', 'yahoo'] \\n\n",
    "    :param mapper_path: Path to CSV file containing at least ticker_col and target_ticker_format columns. \\n\n",
    "    Can be either a web link of local path. Numerai Signals mapping by default.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, ticker_col: str = \"ticker\", target_ticker_format: str = \"bloomberg_ticker\",\n",
    "        mapper_path: str = \"https://numerai-signals-public-data.s3-us-west-2.amazonaws.com/signals_ticker_map_w_bbg.csv\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ticker_col = ticker_col\n",
    "        self.target_ticker_format = target_ticker_format\n",
    "\n",
    "        self.signals_map_path = mapper_path\n",
    "        self.ticker_map = pd.read_csv(self.signals_map_path)\n",
    "\n",
    "        assert (\n",
    "            self.ticker_col in self.ticker_map.columns\n",
    "        ), f\"Ticker column '{self.ticker_col}' is not available in ticker mapping.\"\n",
    "        assert (\n",
    "            self.target_ticker_format in self.ticker_map.columns\n",
    "        ), f\"Target ticker column '{self.target_ticker_format}' is not available in ticker mapping.\"\n",
    "\n",
    "        self.mapping = dict(\n",
    "            self.ticker_map[[self.ticker_col, self.target_ticker_format]].values\n",
    "        )\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(\n",
    "        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\n",
    "    ) -> NumerFrame:\n",
    "        dataf[self.target_ticker_format] = dataf[self.ticker_col].map(self.mapping)\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use default signals mapping to convert between Numerai ticker, Bloomberg ticker and Yahoo ticker formats."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mTickerMapper\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m2\u001B[0m, \u001B[1;36m2\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m004761\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">TickerMapper</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">004761</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  ticker bloomberg_ticker\n0   AAPL          AAPL US\n1   MSFT          MSFT US",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ticker</th>\n      <th>bloomberg_ticker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAPL</td>\n      <td>AAPL US</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MSFT</td>\n      <td>MSFT US</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 50;\n                var nbb_unformatted_code = \"test_dataf = pd.DataFrame([\\\"AAPL\\\", \\\"MSFT\\\"], columns=[\\\"ticker\\\"])\\nmapper = TickerMapper()\\nmapper.transform(test_dataf)\";\n                var nbb_formatted_code = \"test_dataf = pd.DataFrame([\\\"AAPL\\\", \\\"MSFT\\\"], columns=[\\\"ticker\\\"])\\nmapper = TickerMapper()\\nmapper.transform(test_dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataf = pd.DataFrame([\"AAPL\", \"MSFT\"], columns=[\"ticker\"])\n",
    "mapper = TickerMapper()\n",
    "mapper.transform(test_dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also use a CSV file for mapping. For example, the mapping Numerai user degerhan provides in [dsignals](https://github.com/degerhan/dsignals) for EOD data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mTickerMapper\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m5\u001B[0m, \u001B[1;36m2\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m007838\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">TickerMapper</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">007838</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  bloomberg_ticker signals_ticker\n0           LLB SW         LLB.SW\n1          DRAK NA        DRAK.AS\n2           SWB MK      5211.KLSE\n3      ELEKTRA* MF     ELEKTRA.MX\n4     NOT_A_TICKER            NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bloomberg_ticker</th>\n      <th>signals_ticker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LLB SW</td>\n      <td>LLB.SW</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DRAK NA</td>\n      <td>DRAK.AS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SWB MK</td>\n      <td>5211.KLSE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ELEKTRA* MF</td>\n      <td>ELEKTRA.MX</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NOT_A_TICKER</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 51;\n                var nbb_unformatted_code = \"test_dataf = pd.DataFrame([\\\"LLB SW\\\", \\\"DRAK NA\\\", \\\"SWB MK\\\", \\\"ELEKTRA* MF\\\", \\\"NOT_A_TICKER\\\"], columns=[\\\"bloomberg_ticker\\\"])\\nmapper = TickerMapper(ticker_col=\\\"bloomberg_ticker\\\", target_ticker_format=\\\"signals_ticker\\\",\\n                      mapper_path=\\\"test_assets/eodhd-map.csv\\\")\\nmapper.transform(test_dataf)\";\n                var nbb_formatted_code = \"test_dataf = pd.DataFrame(\\n    [\\\"LLB SW\\\", \\\"DRAK NA\\\", \\\"SWB MK\\\", \\\"ELEKTRA* MF\\\", \\\"NOT_A_TICKER\\\"],\\n    columns=[\\\"bloomberg_ticker\\\"],\\n)\\nmapper = TickerMapper(\\n    ticker_col=\\\"bloomberg_ticker\\\",\\n    target_ticker_format=\\\"signals_ticker\\\",\\n    mapper_path=\\\"test_assets/eodhd-map.csv\\\",\\n)\\nmapper.transform(test_dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataf = pd.DataFrame([\"LLB SW\", \"DRAK NA\", \"SWB MK\", \"ELEKTRA* MF\", \"NOT_A_TICKER\"], columns=[\"bloomberg_ticker\"])\n",
    "mapper = TickerMapper(ticker_col=\"bloomberg_ticker\", target_ticker_format=\"signals_ticker\",\n",
    "                      mapper_path=\"test_assets/eodhd-map.csv\")\n",
    "mapper.transform(test_dataf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5. SignalsTargetProcessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerai provides [targets for 5000 stocks](https://docs.numer.ai/numerai-signals/signals-overview#universe) that are neutralized against all sorts of factors. However, it can be helpful to experiment with creating your own targets. You might want to explore different windows, different target binning and/or neutralization. `SignalsTargetProcessor` engineers 3 different targets for every given windows:\n",
    "- `_raw`: Raw return based on price movements.\n",
    "- `_rank`: Ranks of raw return.\n",
    "- `_group`: Binned returns based on rank.\n",
    "\n",
    "Note that Numerai provides targets based on 4-day returns and 20-day returns. While you can explore any window you like, it makes sense to start with `windows` close to these timeframes.\n",
    "\n",
    "For the `bins` argument there are also many options possible. The followed are commonly used binning:\n",
    "- Nomi bins: `[0, 0.05, 0.25, 0.75, 0.95, 1]`\n",
    "- Uniform bins: `[0, 0.20, 0.40, 0.60, 0.80, 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 52;\n                var nbb_unformatted_code = \"# export\\nclass SignalsTargetProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Engineer targets for Numerai Signals. \\\\n\\n    More information on implements Numerai Signals targets: \\\\n\\n    https://forum.numer.ai/t/decoding-the-signals-target/2501\\n\\n    :param price_col: Column from which target will be derived. \\\\n\\n    :param windows: Timeframes to use for engineering targets. 10 and 20-day by default. \\\\n\\n    :param bins: Binning used to create group targets. Nomi binning by default. \\\\n\\n    :param labels: Scaling for binned target. Must be same length as resulting bins (bins-1). Numerai labels by default.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        price_col: str = \\\"close\\\",\\n        windows: list = None,\\n        bins: list = None,\\n        labels: list = None,\\n    ):\\n        super().__init__()\\n        self.price_col = price_col\\n        self.windows = windows if windows else [10, 20]\\n        self.bins = bins if bins else [0, 0.05, 0.25, 0.75, 0.95, 1]\\n        self.labels = labels if labels else [0, 0.25, 0.50, 0.75, 1]\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        for window in tqdm(self.windows, desc=\\\"Signals target engineering windows\\\"):\\n            dataf.loc[:, f\\\"target_{window}d_raw\\\"] = (\\n                dataf[self.price_col].pct_change(periods=window).shift(-window)\\n            )\\n            era_groups = dataf.groupby(dataf.meta.era_col)\\n\\n            dataf.loc[:, f\\\"target_{window}d_rank\\\"] = era_groups[\\n                f\\\"target_{window}d_raw\\\"\\n            ].rank(pct=True, method=\\\"first\\\")\\n            dataf.loc[:, f\\\"target_{window}d_group\\\"] = era_groups[\\n                f\\\"target_{window}d_rank\\\"\\n            ].transform(\\n                lambda group: pd.cut(\\n                    group, bins=self.bins, labels=self.labels, include_lowest=True\\n                )\\n            )\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\nclass SignalsTargetProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Engineer targets for Numerai Signals. \\\\n\\n    More information on implements Numerai Signals targets: \\\\n\\n    https://forum.numer.ai/t/decoding-the-signals-target/2501\\n\\n    :param price_col: Column from which target will be derived. \\\\n\\n    :param windows: Timeframes to use for engineering targets. 10 and 20-day by default. \\\\n\\n    :param bins: Binning used to create group targets. Nomi binning by default. \\\\n\\n    :param labels: Scaling for binned target. Must be same length as resulting bins (bins-1). Numerai labels by default.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        price_col: str = \\\"close\\\",\\n        windows: list = None,\\n        bins: list = None,\\n        labels: list = None,\\n    ):\\n        super().__init__()\\n        self.price_col = price_col\\n        self.windows = windows if windows else [10, 20]\\n        self.bins = bins if bins else [0, 0.05, 0.25, 0.75, 0.95, 1]\\n        self.labels = labels if labels else [0, 0.25, 0.50, 0.75, 1]\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        for window in tqdm(self.windows, desc=\\\"Signals target engineering windows\\\"):\\n            dataf.loc[:, f\\\"target_{window}d_raw\\\"] = (\\n                dataf[self.price_col].pct_change(periods=window).shift(-window)\\n            )\\n            era_groups = dataf.groupby(dataf.meta.era_col)\\n\\n            dataf.loc[:, f\\\"target_{window}d_rank\\\"] = era_groups[\\n                f\\\"target_{window}d_raw\\\"\\n            ].rank(pct=True, method=\\\"first\\\")\\n            dataf.loc[:, f\\\"target_{window}d_group\\\"] = era_groups[\\n                f\\\"target_{window}d_rank\\\"\\n            ].transform(\\n                lambda group: pd.cut(\\n                    group, bins=self.bins, labels=self.labels, include_lowest=True\\n                )\\n            )\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class SignalsTargetProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Engineer targets for Numerai Signals. \\n\n",
    "    More information on implements Numerai Signals targets: \\n\n",
    "    https://forum.numer.ai/t/decoding-the-signals-target/2501\n",
    "\n",
    "    :param price_col: Column from which target will be derived. \\n\n",
    "    :param windows: Timeframes to use for engineering targets. 10 and 20-day by default. \\n\n",
    "    :param bins: Binning used to create group targets. Nomi binning by default. \\n\n",
    "    :param labels: Scaling for binned target. Must be same length as resulting bins (bins-1). Numerai labels by default.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        price_col: str = \"close\",\n",
    "        windows: list = None,\n",
    "        bins: list = None,\n",
    "        labels: list = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.price_col = price_col\n",
    "        self.windows = windows if windows else [10, 20]\n",
    "        self.bins = bins if bins else [0, 0.05, 0.25, 0.75, 0.95, 1]\n",
    "        self.labels = labels if labels else [0, 0.25, 0.50, 0.75, 1]\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        for window in tqdm(self.windows, desc=\"Signals target engineering windows\"):\n",
    "            dataf.loc[:, f\"target_{window}d_raw\"] = (\n",
    "                dataf[self.price_col].pct_change(periods=window).shift(-window)\n",
    "            )\n",
    "            era_groups = dataf.groupby(dataf.meta.era_col)\n",
    "\n",
    "            dataf.loc[:, f\"target_{window}d_rank\"] = era_groups[\n",
    "                f\"target_{window}d_raw\"\n",
    "            ].rank(pct=True, method=\"first\")\n",
    "            dataf.loc[:, f\"target_{window}d_group\"] = era_groups[\n",
    "                f\"target_{window}d_rank\"\n",
    "            ].transform(\n",
    "                lambda group: pd.cut(\n",
    "                    group, bins=self.bins, labels=self.labels, include_lowest=True\n",
    "                )\n",
    "            )\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Signals target engineering windows:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a63a996c78f4df9a6211bf0c04de9fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 18:35:52,888 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-05-26 18:35:52,889 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mSignalsTargetProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10000\u001B[0m, \u001B[1;36m39\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:26\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m983702\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">SignalsTargetProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">39</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:26</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">983702</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "        target_10d_raw  target_10d_rank target_10d_group  target_20d_raw  \\\n607733       -0.993852              0.5              0.5       -0.986229   \n719896     2160.214111              1.0              1.0     2419.864990   \n\n        target_20d_rank target_20d_group  \n607733              0.5              0.5  \n719896              1.0              1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target_10d_raw</th>\n      <th>target_10d_rank</th>\n      <th>target_10d_group</th>\n      <th>target_20d_raw</th>\n      <th>target_20d_rank</th>\n      <th>target_20d_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>607733</th>\n      <td>-0.993852</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>-0.986229</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>719896</th>\n      <td>2160.214111</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2419.864990</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 53;\n                var nbb_unformatted_code = \"# other\\nstp = SignalsTargetProcessor()\\nera_dataf.meta.era_col = \\\"date\\\"\\nnew_target_dataf = stp.transform(era_dataf)\\nnew_target_dataf.get_target_data.head(2)\";\n                var nbb_formatted_code = \"# other\\nstp = SignalsTargetProcessor()\\nera_dataf.meta.era_col = \\\"date\\\"\\nnew_target_dataf = stp.transform(era_dataf)\\nnew_target_dataf.get_target_data.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "stp = SignalsTargetProcessor()\n",
    "era_dataf.meta.era_col = \"date\"\n",
    "new_target_dataf = stp.transform(era_dataf)\n",
    "new_target_dataf.get_target_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.6. LagPreProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many models like Gradient Boosting Machines (GBMs) don't learn any time-series patterns by itself. However, if we create lags of our features the models will pick up on time dependencies between features. `LagPreProcessor` create lag features for given features and windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 54;\n                var nbb_unformatted_code = \"# export\\nclass LagPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Add lag features based on given windows.\\n\\n    :param windows: All lag windows to process for all features. \\\\n\\n    [5, 10, 15, 20] by default (4 weeks lookback) \\\\n\\n    :param ticker_col: Column name for grouping by tickers. \\\\n\\n    :param feature_names: All features for which you want to create lags. All features by default.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        windows: list = None,\\n        ticker_col: str = \\\"bloomberg_ticker\\\",\\n        feature_names: list = None,\\n    ):\\n        super().__init__()\\n        self.windows = windows if windows else [5, 10, 15, 20]\\n        self.ticker_col = ticker_col\\n        self.feature_names = feature_names\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\\n        ticker_groups = dataf.groupby(self.ticker_col)\\n        for feature in tqdm(feature_names, desc=\\\"Lag feature generation\\\"):\\n            feature_group = ticker_groups[feature]\\n            for day in self.windows:\\n                shifted = feature_group.shift(day, axis=0)\\n                dataf.loc[:, f\\\"{feature}_lag{day}\\\"] = shifted\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\nclass LagPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Add lag features based on given windows.\\n\\n    :param windows: All lag windows to process for all features. \\\\n\\n    [5, 10, 15, 20] by default (4 weeks lookback) \\\\n\\n    :param ticker_col: Column name for grouping by tickers. \\\\n\\n    :param feature_names: All features for which you want to create lags. All features by default.\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        windows: list = None,\\n        ticker_col: str = \\\"bloomberg_ticker\\\",\\n        feature_names: list = None,\\n    ):\\n        super().__init__()\\n        self.windows = windows if windows else [5, 10, 15, 20]\\n        self.ticker_col = ticker_col\\n        self.feature_names = feature_names\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\\n        ticker_groups = dataf.groupby(self.ticker_col)\\n        for feature in tqdm(feature_names, desc=\\\"Lag feature generation\\\"):\\n            feature_group = ticker_groups[feature]\\n            for day in self.windows:\\n                shifted = feature_group.shift(day, axis=0)\\n                dataf.loc[:, f\\\"{feature}_lag{day}\\\"] = shifted\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class LagPreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Add lag features based on given windows.\n",
    "\n",
    "    :param windows: All lag windows to process for all features. \\n\n",
    "    [5, 10, 15, 20] by default (4 weeks lookback) \\n\n",
    "    :param ticker_col: Column name for grouping by tickers. \\n\n",
    "    :param feature_names: All features for which you want to create lags. All features by default.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        windows: list = None,\n",
    "        ticker_col: str = \"bloomberg_ticker\",\n",
    "        feature_names: list = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.windows = windows if windows else [5, 10, 15, 20]\n",
    "        self.ticker_col = ticker_col\n",
    "        self.feature_names = feature_names\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\n",
    "        ticker_groups = dataf.groupby(self.ticker_col)\n",
    "        for feature in tqdm(feature_names, desc=\"Lag feature generation\"):\n",
    "            feature_group = ticker_groups[feature]\n",
    "            for day in self.windows:\n",
    "                shifted = feature_group.shift(day, axis=0)\n",
    "                dataf.loc[:, f\"{feature}_lag{day}\"] = shifted\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Lag feature generation:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f851d21fabdf4a0aa8e7a852cccf2ef4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mLagPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m1977266\u001B[0m, \u001B[1;36m17\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m582301\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">LagPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1977266</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">582301</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 55;\n                var nbb_unformatted_code = \"# other\\nlpp = LagPreProcessor(ticker_col=\\\"ticker\\\", feature_names=[\\\"close\\\", \\\"volume\\\"])\\ndataf = lpp(dataf)\";\n                var nbb_formatted_code = \"# other\\nlpp = LagPreProcessor(ticker_col=\\\"ticker\\\", feature_names=[\\\"close\\\", \\\"volume\\\"])\\ndataf = lpp(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "lpp = LagPreProcessor(ticker_col=\"ticker\", feature_names=[\"close\", \"volume\"])\n",
    "dataf = lpp(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All lag features will contain `lag` in the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         close_lag5  close_lag10  close_lag15  close_lag20  volume_lag5  \\\n1977264      2224.0       2117.0       2152.0       2087.0     333400.0   \n1977265      2232.0       2094.0       2180.0       2129.0     285400.0   \n\n         volume_lag10  volume_lag15  volume_lag20  \n1977264      305900.0      449200.0      206600.0  \n1977265      502000.0      341100.0      294200.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>close_lag5</th>\n      <th>close_lag10</th>\n      <th>close_lag15</th>\n      <th>close_lag20</th>\n      <th>volume_lag5</th>\n      <th>volume_lag10</th>\n      <th>volume_lag15</th>\n      <th>volume_lag20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1977264</th>\n      <td>2224.0</td>\n      <td>2117.0</td>\n      <td>2152.0</td>\n      <td>2087.0</td>\n      <td>333400.0</td>\n      <td>305900.0</td>\n      <td>449200.0</td>\n      <td>206600.0</td>\n    </tr>\n    <tr>\n      <th>1977265</th>\n      <td>2232.0</td>\n      <td>2094.0</td>\n      <td>2180.0</td>\n      <td>2129.0</td>\n      <td>285400.0</td>\n      <td>502000.0</td>\n      <td>341100.0</td>\n      <td>294200.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 56;\n                var nbb_unformatted_code = \"# other\\ndataf.get_pattern_data(\\\"lag\\\").tail(2)\";\n                var nbb_formatted_code = \"# other\\ndataf.get_pattern_data(\\\"lag\\\").tail(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "dataf.get_pattern_data(\"lag\").tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.7. DifferencePreProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating lags with the `LagPreProcessor`, it may be useful to create new features that calculate the difference between those lags. Through this process in `DifferencePreProcessor`, we can provide models with more time-series related patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 57;\n                var nbb_unformatted_code = \"# export\\nclass DifferencePreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Add difference features based on given windows. Run LagPreProcessor first.\\n\\n    :param windows: All lag windows to process for all features. \\\\n\\n    :param feature_names: All features for which you want to create differences. All features that also have lags by default. \\\\n\\n    :param pct_change: Method to calculate differences. If True, will calculate differences with a percentage change. Otherwise calculates a simple difference. Defaults to False \\\\n\\n    :param abs_diff: Whether to also calculate the absolute value of all differences. Defaults to True \\\\n\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        windows: list = None,\\n        feature_names: list = None,\\n        pct_diff: bool = False,\\n        abs_diff: bool = False,\\n    ):\\n        super().__init__()\\n        self.windows = windows if windows else [5, 10, 15, 20]\\n        self.feature_names = feature_names\\n        self.pct_diff = pct_diff\\n        self.abs_diff = abs_diff\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\\n        for feature in tqdm(self.feature_names, desc=\\\"Difference feature generation\\\"):\\n            lag_columns = dataf.get_pattern_data(f\\\"{feature}_lag\\\").columns\\n            if not lag_columns.empty:\\n                for day in self.windows:\\n                    differenced_values = (\\n                        (dataf[feature] / dataf[f\\\"{feature}_lag{day}\\\"]) - 1\\n                        if self.pct_diff\\n                        else dataf[feature] - dataf[f\\\"{feature}_lag{day}\\\"]\\n                    )\\n                    dataf[f\\\"{feature}_diff{day}\\\"] = differenced_values\\n                    if self.abs_diff:\\n                        dataf[f\\\"{feature}_absdiff{day}\\\"] = np.abs(\\n                            dataf[f\\\"{feature}_diff{day}\\\"]\\n                        )\\n            else:\\n                rich_print(\\n                    f\\\":warning: WARNING: Skipping {feature}. Lag features for feature: {feature} were not detected. Have you already run LagPreProcessor? :warning:\\\"\\n                )\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\nclass DifferencePreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Add difference features based on given windows. Run LagPreProcessor first.\\n\\n    :param windows: All lag windows to process for all features. \\\\n\\n    :param feature_names: All features for which you want to create differences. All features that also have lags by default. \\\\n\\n    :param pct_change: Method to calculate differences. If True, will calculate differences with a percentage change. Otherwise calculates a simple difference. Defaults to False \\\\n\\n    :param abs_diff: Whether to also calculate the absolute value of all differences. Defaults to True \\\\n\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        windows: list = None,\\n        feature_names: list = None,\\n        pct_diff: bool = False,\\n        abs_diff: bool = False,\\n    ):\\n        super().__init__()\\n        self.windows = windows if windows else [5, 10, 15, 20]\\n        self.feature_names = feature_names\\n        self.pct_diff = pct_diff\\n        self.abs_diff = abs_diff\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\\n        for feature in tqdm(self.feature_names, desc=\\\"Difference feature generation\\\"):\\n            lag_columns = dataf.get_pattern_data(f\\\"{feature}_lag\\\").columns\\n            if not lag_columns.empty:\\n                for day in self.windows:\\n                    differenced_values = (\\n                        (dataf[feature] / dataf[f\\\"{feature}_lag{day}\\\"]) - 1\\n                        if self.pct_diff\\n                        else dataf[feature] - dataf[f\\\"{feature}_lag{day}\\\"]\\n                    )\\n                    dataf[f\\\"{feature}_diff{day}\\\"] = differenced_values\\n                    if self.abs_diff:\\n                        dataf[f\\\"{feature}_absdiff{day}\\\"] = np.abs(\\n                            dataf[f\\\"{feature}_diff{day}\\\"]\\n                        )\\n            else:\\n                rich_print(\\n                    f\\\":warning: WARNING: Skipping {feature}. Lag features for feature: {feature} were not detected. Have you already run LagPreProcessor? :warning:\\\"\\n                )\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class DifferencePreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Add difference features based on given windows. Run LagPreProcessor first.\n",
    "\n",
    "    :param windows: All lag windows to process for all features. \\n\n",
    "    :param feature_names: All features for which you want to create differences. All features that also have lags by default. \\n\n",
    "    :param pct_change: Method to calculate differences. If True, will calculate differences with a percentage change. Otherwise calculates a simple difference. Defaults to False \\n\n",
    "    :param abs_diff: Whether to also calculate the absolute value of all differences. Defaults to True \\n\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        windows: list = None,\n",
    "        feature_names: list = None,\n",
    "        pct_diff: bool = False,\n",
    "        abs_diff: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.windows = windows if windows else [5, 10, 15, 20]\n",
    "        self.feature_names = feature_names\n",
    "        self.pct_diff = pct_diff\n",
    "        self.abs_diff = abs_diff\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        feature_names = self.feature_names if self.feature_names else dataf.feature_cols\n",
    "        for feature in tqdm(self.feature_names, desc=\"Difference feature generation\"):\n",
    "            lag_columns = dataf.get_pattern_data(f\"{feature}_lag\").columns\n",
    "            if not lag_columns.empty:\n",
    "                for day in self.windows:\n",
    "                    differenced_values = (\n",
    "                        (dataf[feature] / dataf[f\"{feature}_lag{day}\"]) - 1\n",
    "                        if self.pct_diff\n",
    "                        else dataf[feature] - dataf[f\"{feature}_lag{day}\"]\n",
    "                    )\n",
    "                    dataf[f\"{feature}_diff{day}\"] = differenced_values\n",
    "                    if self.abs_diff:\n",
    "                        dataf[f\"{feature}_absdiff{day}\"] = np.abs(\n",
    "                            dataf[f\"{feature}_diff{day}\"]\n",
    "                        )\n",
    "            else:\n",
    "                rich_print(\n",
    "                    f\":warning: WARNING: Skipping {feature}. Lag features for feature: {feature} were not detected. Have you already run LagPreProcessor? :warning:\"\n",
    "                )\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Difference feature generation:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9adad25bbcfe454db5082528cbb79260"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mDifferencePreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m1977266\u001B[0m, \u001B[1;36m25\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m337694\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">DifferencePreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1977266</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">337694</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 58;\n                var nbb_unformatted_code = \"# other\\ndpp = DifferencePreProcessor(\\n    feature_names=[\\\"close\\\", \\\"volume\\\"], windows=[5, 10, 15, 20], pct_diff=True\\n)\\ndataf = dpp.transform(dataf)\";\n                var nbb_formatted_code = \"# other\\ndpp = DifferencePreProcessor(\\n    feature_names=[\\\"close\\\", \\\"volume\\\"], windows=[5, 10, 15, 20], pct_diff=True\\n)\\ndataf = dpp.transform(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "dpp = DifferencePreProcessor(\n",
    "    feature_names=[\"close\", \"volume\"], windows=[5, 10, 15, 20], pct_diff=True\n",
    ")\n",
    "dataf = dpp.transform(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All difference features will contain `diff` in the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         close_diff5  close_diff10  close_diff15  close_diff20  volume_diff5  \\\n1977264     0.010791      0.061880      0.044610      0.077144     -0.105879   \n1977265     0.003136      0.069245      0.027064      0.051667     -0.113875   \n\n         volume_diff10  volume_diff15  volume_diff20  \n1977264      -0.025499      -0.336376       0.442885  \n1977265      -0.496215      -0.258575      -0.140381  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>close_diff5</th>\n      <th>close_diff10</th>\n      <th>close_diff15</th>\n      <th>close_diff20</th>\n      <th>volume_diff5</th>\n      <th>volume_diff10</th>\n      <th>volume_diff15</th>\n      <th>volume_diff20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1977264</th>\n      <td>0.010791</td>\n      <td>0.061880</td>\n      <td>0.044610</td>\n      <td>0.077144</td>\n      <td>-0.105879</td>\n      <td>-0.025499</td>\n      <td>-0.336376</td>\n      <td>0.442885</td>\n    </tr>\n    <tr>\n      <th>1977265</th>\n      <td>0.003136</td>\n      <td>0.069245</td>\n      <td>0.027064</td>\n      <td>0.051667</td>\n      <td>-0.113875</td>\n      <td>-0.496215</td>\n      <td>-0.258575</td>\n      <td>-0.140381</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 59;\n                var nbb_unformatted_code = \"# other\\ndataf.get_pattern_data(\\\"diff\\\").tail(2)\";\n                var nbb_formatted_code = \"# other\\ndataf.get_pattern_data(\\\"diff\\\").tail(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "dataf.get_pattern_data(\"diff\").tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom preprocessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are an almost unlimited number of ways to preprocess (selection, engineering and manipulation). We have only scratched the surface with the preprocessors currently implemented. We invite the Numerai community to develop Numerai Classic and Numerai Signals preprocessors.\n",
    "\n",
    "A new Preprocessor should inherit from `BaseProcessor` and implement a `transform` method. For efficient implementation, we recommend you use `NumerFrame` functionality for preprocessing. You can also support Pandas DataFrame input as long as the `transform` method returns a `NumerFrame`. This ensures that the Preprocessor still works within a full `numerai-blocks` pipeline. A template for new preprocessors is given below.\n",
    "\n",
    "To enable fancy logging output. Add the `@display_processor_info` decorator to the `transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 60;\n                var nbb_unformatted_code = \"# export\\nclass AwesomePreProcessor(BaseProcessor):\\n    \\\"\\\"\\\" TEMPLATE - Do some awesome preprocessing. \\\"\\\"\\\"\\n    def __init__(self):\\n        super().__init__()\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        # Do processing\\n        ...\\n        # Parse all contents of NumerFrame to the next pipeline step\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\nclass AwesomePreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"TEMPLATE - Do some awesome preprocessing.\\\"\\\"\\\"\\n\\n    def __init__(self):\\n        super().__init__()\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        # Do processing\\n        ...\\n        # Parse all contents of NumerFrame to the next pipeline step\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class AwesomePreProcessor(BaseProcessor):\n",
    "    \"\"\" TEMPLATE - Do some awesome preprocessing. \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        # Do processing\n",
    "        ...\n",
    "        # Parse all contents of NumerFrame to the next pipeline step\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_misc.ipynb.\n",
      "Converted 01_download.ipynb.\n",
      "Converted 02_numerframe.ipynb.\n",
      "Converted 03_preprocessing.ipynb.\n",
      "Converted 04_model.ipynb.\n",
      "Converted 05_postprocessing.ipynb.\n",
      "Converted 06_modelpipeline.ipynb.\n",
      "Converted 07_evaluation.ipynb.\n",
      "Converted 08_key.ipynb.\n",
      "Converted 09_submission.ipynb.\n",
      "Converted 10_staking.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 61;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# Run this cell to sync all changes with library\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 61;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}