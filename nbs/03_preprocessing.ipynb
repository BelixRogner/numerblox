{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_formatted_code = \"%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"# default_exp preprocessing\";\n                var nbb_formatted_code = \"# default_exp preprocessing\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default_exp preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_formatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"#export\\nimport uuid\\nimport time\\n# import talib\\nimport numpy as np\\nimport pandas as pd\\nimport datetime as dt\\nfrom typing import Union\\nfrom functools import wraps\\n# from scipy.special import gamma\\nfrom typeguard import typechecked\\nfrom abc import ABC, abstractmethod\\nfrom rich import print as rich_print\\n\\nfrom numerai_blocks.dataset import Dataset, create_dataset\";\n                var nbb_formatted_code = \"# export\\nimport uuid\\nimport time\\n\\n# import talib\\nimport numpy as np\\nimport pandas as pd\\nimport datetime as dt\\nfrom typing import Union\\nfrom functools import wraps\\n\\n# from scipy.special import gamma\\nfrom typeguard import typechecked\\nfrom abc import ABC, abstractmethod\\nfrom rich import print as rich_print\\n\\nfrom numerai_blocks.dataset import Dataset, create_dataset\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "import uuid\n",
    "import time\n",
    "# import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from typing import Union\n",
    "from functools import wraps\n",
    "# from scipy.special import gamma\n",
    "from typeguard import typechecked\n",
    "from abc import ABC, abstractmethod\n",
    "from rich import print as rich_print\n",
    "\n",
    "from numerai_blocks.dataset import Dataset, create_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. BaseProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"#export\\nclass BaseProcessor(ABC):\\n    \\\"\\\"\\\"\\n    New Preprocessors and Postprocessors should inherit from this object\\n    and implement the transform method.\\n    \\\"\\\"\\\"\\n    def __init__(self):\\n        ...\\n\\n    @abstractmethod\\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        ...\\n\\n    def __call__(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        return self.transform(dataset=dataset, *args, **kwargs)\";\n                var nbb_formatted_code = \"# export\\nclass BaseProcessor(ABC):\\n    \\\"\\\"\\\"\\n    New Preprocessors and Postprocessors should inherit from this object\\n    and implement the transform method.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self):\\n        ...\\n\\n    @abstractmethod\\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        ...\\n\\n    def __call__(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        return self.transform(dataset=dataset, *args, **kwargs)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "class BaseProcessor(ABC):\n",
    "    \"\"\"\n",
    "    New Preprocessors and Postprocessors should inherit from this object\n",
    "    and implement the transform method.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n",
    "        ...\n",
    "\n",
    "    def __call__(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n",
    "        return self.transform(dataset=dataset, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Decorators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have preprocessing functions that work with Pandas DataFrames and want to make them compatible with `numerai-blocks` `Dataset`s. This can be done by adding a single decorator (`support_dataset_processing`) to a method where you call a DataFrame function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"#export\\ndef support_dataset_processing(func):\\n    \\\"\\\"\\\"\\n    Make existing DataFrame transformer compatible with Dataset input.\\n    :param func: Some function/method that takes Pandas DataFrame as input\\n    and return Pandas DataFrame.\\n    \\\"\\\"\\\"\\n    @wraps(func)\\n    def wrapper(dataset: Dataset, *args, **kwargs) -> Dataset:\\n        dataf_transform = func(dataset.dataf, *args, **kwargs)\\n        metadata = dataset.__dict__\\n        metadata.pop(\\\"dataf\\\", None)\\n        return Dataset(dataf_transform, metadata)\\n    return wrapper\";\n                var nbb_formatted_code = \"# export\\ndef support_dataset_processing(func):\\n    \\\"\\\"\\\"\\n    Make existing DataFrame transformer compatible with Dataset input.\\n    :param func: Some function/method that takes Pandas DataFrame as input\\n    and return Pandas DataFrame.\\n    \\\"\\\"\\\"\\n\\n    @wraps(func)\\n    def wrapper(dataset: Dataset, *args, **kwargs) -> Dataset:\\n        dataf_transform = func(dataset.dataf, *args, **kwargs)\\n        metadata = dataset.__dict__\\n        metadata.pop(\\\"dataf\\\", None)\\n        return Dataset(dataf_transform, metadata)\\n\\n    return wrapper\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "def support_dataset_processing(func):\n",
    "    \"\"\"\n",
    "    Make existing DataFrame transformer compatible with Dataset input.\n",
    "    :param func: Some function/method that takes Pandas DataFrame as input\n",
    "    and return Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(dataset: Dataset, *args, **kwargs) -> Dataset:\n",
    "        dataf_transform = func(dataset.dataf, *args, **kwargs)\n",
    "        metadata = dataset.__dict__\n",
    "        metadata.pop(\"dataf\", None)\n",
    "        return Dataset(dataf_transform, metadata)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decorator example + tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"# Random DataFrame\\ntest_features = [f\\\"feature_{l}\\\" for l in \\\"ABCDEFGHIK\\\"]\\nid_col = [uuid.uuid4().hex for _ in range(100)]\\ndf = pd.DataFrame(np.random.uniform(size=(100, 10)), columns=test_features)\\n\\ndef pandas_quad(df: pd.DataFrame, col: str):\\n    \\\"\\\"\\\" Simple DataFrame function which takes gives column to power of 2. \\\"\\\"\\\"\\n    df_copy = df.copy()\\n    df_copy.loc[:, col] = df_copy.loc[:, col].apply(lambda x: x ** 2)\\n    return df_copy\\n\\n@support_dataset_processing\\ndef test_dataf_with_dataset_input(dataset: Dataset, col: str) -> Dataset:\\n    \\\"\\\"\\\" Put Dataset through function that normally only accepts Pandas DataFrame. \\\"\\\"\\\"\\n    return pandas_quad(dataset, col=col)\";\n                var nbb_formatted_code = \"# Random DataFrame\\ntest_features = [f\\\"feature_{l}\\\" for l in \\\"ABCDEFGHIK\\\"]\\nid_col = [uuid.uuid4().hex for _ in range(100)]\\ndf = pd.DataFrame(np.random.uniform(size=(100, 10)), columns=test_features)\\n\\n\\ndef pandas_quad(df: pd.DataFrame, col: str):\\n    \\\"\\\"\\\"Simple DataFrame function which takes gives column to power of 2.\\\"\\\"\\\"\\n    df_copy = df.copy()\\n    df_copy.loc[:, col] = df_copy.loc[:, col].apply(lambda x: x ** 2)\\n    return df_copy\\n\\n\\n@support_dataset_processing\\ndef test_dataf_with_dataset_input(dataset: Dataset, col: str) -> Dataset:\\n    \\\"\\\"\\\"Put Dataset through function that normally only accepts Pandas DataFrame.\\\"\\\"\\\"\\n    return pandas_quad(dataset, col=col)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random DataFrame\n",
    "test_features = [f\"feature_{l}\" for l in \"ABCDEFGHIK\"]\n",
    "id_col = [uuid.uuid4().hex for _ in range(100)]\n",
    "df = pd.DataFrame(np.random.uniform(size=(100, 10)), columns=test_features)\n",
    "\n",
    "def pandas_quad(df: pd.DataFrame, col: str):\n",
    "    \"\"\" Simple DataFrame function which takes gives column to power of 2. \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    df_copy.loc[:, col] = df_copy.loc[:, col].apply(lambda x: x ** 2)\n",
    "    return df_copy\n",
    "\n",
    "@support_dataset_processing\n",
    "def test_dataf_with_dataset_input(dataset: Dataset, col: str) -> Dataset:\n",
    "    \"\"\" Put Dataset through function that normally only accepts Pandas DataFrame. \"\"\"\n",
    "    return pandas_quad(dataset, col=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `test_dataf_with_dataset_input` will behave as a `Dataset` preprocessor even though the function called within normally only accepts Pandas DataFrames.\n",
    "\n",
    "`transform_method_1` and `transform_method_2` will there lead to the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"feature_to_transform = \\\"feature_B\\\"\\ntransform_method_1 = test_dataf_with_dataset_input(Dataset(df), col=feature_to_transform).get_column_selection(feature_to_transform).round(8)\\ntransform_method_2 = pandas_quad(df, col=feature_to_transform).loc[:, [feature_to_transform]].round(8)\\n\\nassert transform_method_1.equals(transform_method_2)\";\n                var nbb_formatted_code = \"feature_to_transform = \\\"feature_B\\\"\\ntransform_method_1 = (\\n    test_dataf_with_dataset_input(Dataset(df), col=feature_to_transform)\\n    .get_column_selection(feature_to_transform)\\n    .round(8)\\n)\\ntransform_method_2 = (\\n    pandas_quad(df, col=feature_to_transform).loc[:, [feature_to_transform]].round(8)\\n)\\n\\nassert transform_method_1.equals(transform_method_2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_to_transform = \"feature_B\"\n",
    "transform_method_1 = test_dataf_with_dataset_input(Dataset(df), col=feature_to_transform).get_column_selection(feature_to_transform).round(8)\n",
    "transform_method_2 = pandas_quad(df, col=feature_to_transform).loc[:, [feature_to_transform]].round(8)\n",
    "\n",
    "assert transform_method_1.equals(transform_method_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to keep an overview of which steps are done in a data pipeline and where processing bottlenecks occur.\n",
    "The decorator below will display:\n",
    "1. When a step has finished.\n",
    "2. What the output shape of the data is.\n",
    "3. How long the step took to finish.\n",
    "\n",
    "Note that this wrapper only works for methods that return a `Dataset` object as a result. All implemented preprocessors, models and postprocessors have this property.\n",
    "\n",
    "To use this functionality, simply add `@display_processor_info` as a decorator to the function/method you want to track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"#export\\ndef display_processor_info(func):\\n    \\\"\\\"\\\" Fancy console output for data processing. \\\"\\\"\\\"\\n    @wraps(func)\\n    def wrapper(*args, **kwargs):\\n        tic = dt.datetime.now()\\n        result = func(*args, **kwargs)\\n        time_taken = str(dt.datetime.now() - tic)\\n        class_name = func.__qualname__.split('.')[0]\\n        rich_print(f\\\":white_check_mark: Finished step [bold]{class_name}[/bold]. Output shape={result.dataf.shape}. Time taken for step: [blue]{time_taken}[/blue]. :white_check_mark:\\\")\\n        return result\\n    return wrapper\";\n                var nbb_formatted_code = \"# export\\ndef display_processor_info(func):\\n    \\\"\\\"\\\"Fancy console output for data processing.\\\"\\\"\\\"\\n\\n    @wraps(func)\\n    def wrapper(*args, **kwargs):\\n        tic = dt.datetime.now()\\n        result = func(*args, **kwargs)\\n        time_taken = str(dt.datetime.now() - tic)\\n        class_name = func.__qualname__.split(\\\".\\\")[0]\\n        rich_print(\\n            f\\\":white_check_mark: Finished step [bold]{class_name}[/bold]. Output shape={result.dataf.shape}. Time taken for step: [blue]{time_taken}[/blue]. :white_check_mark:\\\"\\n        )\\n        return result\\n\\n    return wrapper\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "def display_processor_info(func):\n",
    "    \"\"\" Fancy console output for data processing. \"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        tic = dt.datetime.now()\n",
    "        result = func(*args, **kwargs)\n",
    "        time_taken = str(dt.datetime.now() - tic)\n",
    "        class_name = func.__qualname__.split('.')[0]\n",
    "        rich_print(f\":white_check_mark: Finished step [bold]{class_name}[/bold]. Output shape={result.dataf.shape}. Time taken for step: [blue]{time_taken}[/blue]. :white_check_mark:\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mTestDisplay\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m314\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \u001B[1;34m0:00:02\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m001349\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">TestDisplay</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">314</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:02</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">001349</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"class TestDisplay:\\n    def __init__(self, dataset: Dataset):\\n        self.dataset = dataset\\n    @display_processor_info\\n    def test(self) -> Dataset:\\n        time.sleep(2)\\n        return self.dataset\\n\\ndataset = create_dataset(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\nTestDisplay(dataset).test();\";\n                var nbb_formatted_code = \"class TestDisplay:\\n    def __init__(self, dataset: Dataset):\\n        self.dataset = dataset\\n\\n    @display_processor_info\\n    def test(self) -> Dataset:\\n        time.sleep(2)\\n        return self.dataset\\n\\n\\ndataset = create_dataset(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\nTestDisplay(dataset).test()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class TestDisplay:\n",
    "    def __init__(self, dataset: Dataset):\n",
    "        self.dataset = dataset\n",
    "    @display_processor_info\n",
    "    def test(self) -> Dataset:\n",
    "        time.sleep(2)\n",
    "        return self.dataset\n",
    "\n",
    "dataset = create_dataset(\"test_assets/mini_numerai_version_1_data.csv\")\n",
    "TestDisplay(dataset).test();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Common preprocessing steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Version agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass CopyPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"Copy DataFrame to avoid manipulation of original DataFrame. \\\"\\\"\\\"\\n    def __init__(self):\\n        super(CopyPreProcessor, self).__init__()\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        return dataset.copy_dataset()\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass CopyPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"Copy DataFrame to avoid manipulation of original DataFrame.\\\"\\\"\\\"\\n\\n    def __init__(self):\\n        super(CopyPreProcessor, self).__init__()\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        return dataset.copy_dataset()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class CopyPreProcessor(BaseProcessor):\n",
    "    \"\"\"Copy DataFrame to avoid manipulation of original DataFrame. \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CopyPreProcessor, self).__init__()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n",
    "        return dataset.copy_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mCopyPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m314\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m000594\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">CopyPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">314</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">000594</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"dataset = create_dataset(\\\"test_assets/mini_numerai_version_1_data.csv\\\", version=1)\\ncopied_dataset = CopyPreProcessor().transform(dataset)\\nassert copied_dataset.dataf.equals(dataset.dataf)\\nassert dataset.version, dataset.multi_target == (copied_dataset.version, copied_dataset.multi_target)\";\n                var nbb_formatted_code = \"dataset = create_dataset(\\\"test_assets/mini_numerai_version_1_data.csv\\\", version=1)\\ncopied_dataset = CopyPreProcessor().transform(dataset)\\nassert copied_dataset.dataf.equals(dataset.dataf)\\nassert dataset.version, dataset.multi_target == (\\n    copied_dataset.version,\\n    copied_dataset.multi_target,\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = create_dataset(\"test_assets/mini_numerai_version_1_data.csv\", version=1)\n",
    "copied_dataset = CopyPreProcessor().transform(dataset)\n",
    "assert copied_dataset.dataf.equals(dataset.dataf)\n",
    "assert dataset.version, dataset.multi_target == (copied_dataset.version, copied_dataset.multi_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass FeatureSelectionPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Keep only features given + all target, predictions and aux columns.\\n    \\\"\\\"\\\"\\n    def __init__(self, feature_cols: Union[str, list]):\\n        super(FeatureSelectionPreProcessor, self).__init__()\\n        self.feature_cols = feature_cols\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset) -> Dataset:\\n        keep_cols = self.feature_cols + dataset.target_cols + dataset.prediction_cols + dataset.aux_cols\\n        dataset.dataf = dataset.dataf.loc[:, keep_cols]\\n        return Dataset(**dataset.__dict__)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass FeatureSelectionPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Keep only features given + all target, predictions and aux columns.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, feature_cols: Union[str, list]):\\n        super(FeatureSelectionPreProcessor, self).__init__()\\n        self.feature_cols = feature_cols\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset) -> Dataset:\\n        keep_cols = (\\n            self.feature_cols\\n            + dataset.target_cols\\n            + dataset.prediction_cols\\n            + dataset.aux_cols\\n        )\\n        dataset.dataf = dataset.dataf.loc[:, keep_cols]\\n        return Dataset(**dataset.__dict__)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class FeatureSelectionPreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Keep only features given + all target, predictions and aux columns.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_cols: Union[str, list]):\n",
    "        super(FeatureSelectionPreProcessor, self).__init__()\n",
    "        self.feature_cols = feature_cols\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataset: Dataset) -> Dataset:\n",
    "        keep_cols = self.feature_cols + dataset.target_cols + dataset.prediction_cols + dataset.aux_cols\n",
    "        dataset.dataf = dataset.dataf.loc[:, keep_cols]\n",
    "        return Dataset(**dataset.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mFeatureSelectionPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m5\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m000670\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">FeatureSelectionPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">000670</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"selected_dataset = FeatureSelectionPreProcessor(feature_cols=['feature_wisdom1']).transform(dataset)\\nassert selected_dataset.get_feature_data.shape[1] == 1\\nassert dataset.version, dataset.multi_target == (selected_dataset.version, selected_dataset.multi_target)\";\n                var nbb_formatted_code = \"selected_dataset = FeatureSelectionPreProcessor(\\n    feature_cols=[\\\"feature_wisdom1\\\"]\\n).transform(dataset)\\nassert selected_dataset.get_feature_data.shape[1] == 1\\nassert dataset.version, dataset.multi_target == (\\n    selected_dataset.version,\\n    selected_dataset.multi_target,\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_dataset = FeatureSelectionPreProcessor(feature_cols=['feature_wisdom1']).transform(dataset)\n",
    "assert selected_dataset.get_feature_data.shape[1] == 1\n",
    "assert dataset.version, dataset.multi_target == (selected_dataset.version, selected_dataset.multi_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   feature_wisdom1  target                id   era data_type\n0             0.25    0.50  n000315175b67977  era1     train\n1             0.50    0.25  n0014af834a96cdd  era1     train",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_wisdom1</th>\n      <th>target</th>\n      <th>id</th>\n      <th>era</th>\n      <th>data_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>n000315175b67977</td>\n      <td>era1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>n0014af834a96cdd</td>\n      <td>era1</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 15;\n                var nbb_unformatted_code = \"selected_dataset.dataf.head(2)\";\n                var nbb_formatted_code = \"selected_dataset.dataf.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_dataset.dataf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass TargetSelectionPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Keep only features given + all target, predictions and aux columns.\\n    \\\"\\\"\\\"\\n    def __init__(self, target_cols: Union[str, list]):\\n        super(TargetSelectionPreProcessor, self).__init__()\\n        self.target_cols = target_cols\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset) -> Dataset:\\n        keep_cols = self.target_cols + dataset.feature_cols + dataset.prediction_cols + dataset.aux_cols\\n        dataset.dataf = dataset.dataf.loc[:, keep_cols]\\n        return Dataset(**dataset.__dict__)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass TargetSelectionPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Keep only features given + all target, predictions and aux columns.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, target_cols: Union[str, list]):\\n        super(TargetSelectionPreProcessor, self).__init__()\\n        self.target_cols = target_cols\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset) -> Dataset:\\n        keep_cols = (\\n            self.target_cols\\n            + dataset.feature_cols\\n            + dataset.prediction_cols\\n            + dataset.aux_cols\\n        )\\n        dataset.dataf = dataset.dataf.loc[:, keep_cols]\\n        return Dataset(**dataset.__dict__)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class TargetSelectionPreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Keep only features given + all target, predictions and aux columns.\n",
    "    \"\"\"\n",
    "    def __init__(self, target_cols: Union[str, list]):\n",
    "        super(TargetSelectionPreProcessor, self).__init__()\n",
    "        self.target_cols = target_cols\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataset: Dataset) -> Dataset:\n",
    "        keep_cols = self.target_cols + dataset.feature_cols + dataset.prediction_cols + dataset.aux_cols\n",
    "        dataset.dataf = dataset.dataf.loc[:, keep_cols]\n",
    "        return Dataset(**dataset.__dict__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mTargetSelectionPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m1055\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m008141\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">TargetSelectionPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1055</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">008141</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                  target  target_nomi_20  target_nomi_60  \\\nid                                                         \nn559bd06a8861222    0.25            0.25            0.50   \nn9d39dea58c9e3cf    0.50            0.50            0.75   \n\n                  feature_dichasial_hammier_spawner  \\\nid                                                    \nn559bd06a8861222                               0.25   \nn9d39dea58c9e3cf                               0.75   \n\n                  feature_rheumy_epistemic_prancer  \\\nid                                                   \nn559bd06a8861222                              0.75   \nn9d39dea58c9e3cf                              0.50   \n\n                  feature_pert_performative_hormuz  \\\nid                                                   \nn559bd06a8861222                              0.25   \nn9d39dea58c9e3cf                              0.75   \n\n                  feature_hillier_unpitied_theobromine  \\\nid                                                       \nn559bd06a8861222                                  0.75   \nn9d39dea58c9e3cf                                  1.00   \n\n                  feature_perigean_bewitching_thruster  \\\nid                                                       \nn559bd06a8861222                                  0.25   \nn9d39dea58c9e3cf                                  0.50   \n\n                  feature_renegade_undomestic_milord  \\\nid                                                     \nn559bd06a8861222                                0.50   \nn9d39dea58c9e3cf                                0.25   \n\n                  feature_koranic_rude_corf  ...  \\\nid                                           ...   \nn559bd06a8861222                        1.0  ...   \nn9d39dea58c9e3cf                        0.5  ...   \n\n                  feature_drawable_exhortative_dispersant  \\\nid                                                          \nn559bd06a8861222                                     1.00   \nn9d39dea58c9e3cf                                     0.25   \n\n                  feature_metabolic_minded_armorist  \\\nid                                                    \nn559bd06a8861222                                0.0   \nn9d39dea58c9e3cf                                0.5   \n\n                  feature_investigatory_inerasable_circumvallation  \\\nid                                                                   \nn559bd06a8861222                                               0.0   \nn9d39dea58c9e3cf                                               0.0   \n\n                  feature_centroclinal_incentive_lancelet  \\\nid                                                          \nn559bd06a8861222                                     0.25   \nn9d39dea58c9e3cf                                     0.25   \n\n                  feature_unemotional_quietistic_chirper  \\\nid                                                         \nn559bd06a8861222                                    0.00   \nn9d39dea58c9e3cf                                    0.75   \n\n                  feature_behaviorist_microbiological_farina  \\\nid                                                             \nn559bd06a8861222                                         0.0   \nn9d39dea58c9e3cf                                         1.0   \n\n                  feature_lofty_acceptable_challenge  \\\nid                                                     \nn559bd06a8861222                                1.00   \nn9d39dea58c9e3cf                                0.75   \n\n                  feature_coactive_prefatorial_lucy   era  data_type  \nid                                                                    \nn559bd06a8861222                               0.25  0297      train  \nn9d39dea58c9e3cf                               1.00  0003      train  \n\n[2 rows x 1055 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>target_nomi_20</th>\n      <th>target_nomi_60</th>\n      <th>feature_dichasial_hammier_spawner</th>\n      <th>feature_rheumy_epistemic_prancer</th>\n      <th>feature_pert_performative_hormuz</th>\n      <th>feature_hillier_unpitied_theobromine</th>\n      <th>feature_perigean_bewitching_thruster</th>\n      <th>feature_renegade_undomestic_milord</th>\n      <th>feature_koranic_rude_corf</th>\n      <th>...</th>\n      <th>feature_drawable_exhortative_dispersant</th>\n      <th>feature_metabolic_minded_armorist</th>\n      <th>feature_investigatory_inerasable_circumvallation</th>\n      <th>feature_centroclinal_incentive_lancelet</th>\n      <th>feature_unemotional_quietistic_chirper</th>\n      <th>feature_behaviorist_microbiological_farina</th>\n      <th>feature_lofty_acceptable_challenge</th>\n      <th>feature_coactive_prefatorial_lucy</th>\n      <th>era</th>\n      <th>data_type</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>0.25</td>\n      <td>0297</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0003</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 1055 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 17;\n                var nbb_unformatted_code = \"dataset = create_dataset(\\\"test_assets/mini_numerai_version_2_data.parquet\\\", version=2)\\ntarget_cols = ['target', 'target_nomi_20', 'target_nomi_60']\\nselected_dataset = TargetSelectionPreProcessor(target_cols=target_cols).transform(dataset)\\nassert selected_dataset.get_target_data.shape[1] == len(target_cols)\\nselected_dataset.dataf.head(2)\";\n                var nbb_formatted_code = \"dataset = create_dataset(\\\"test_assets/mini_numerai_version_2_data.parquet\\\", version=2)\\ntarget_cols = [\\\"target\\\", \\\"target_nomi_20\\\", \\\"target_nomi_60\\\"]\\nselected_dataset = TargetSelectionPreProcessor(target_cols=target_cols).transform(\\n    dataset\\n)\\nassert selected_dataset.get_target_data.shape[1] == len(target_cols)\\nselected_dataset.dataf.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = create_dataset(\"test_assets/mini_numerai_version_2_data.parquet\", version=2)\n",
    "target_cols = ['target', 'target_nomi_20', 'target_nomi_60']\n",
    "selected_dataset = TargetSelectionPreProcessor(target_cols=target_cols).transform(dataset)\n",
    "assert selected_dataset.get_target_data.shape[1] == len(target_cols)\n",
    "selected_dataset.dataf.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Version 1 specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"#export\\n@typechecked\\nclass GroupStatsPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    WARNING: Only supported for Version 1 (legacy) data.\\n    Calculate group statistics for all data groups.\\n    :param groups: Groups to create features for. All groups by default.\\n    \\\"\\\"\\\"\\n    def __init__(self, groups: list = None):\\n        super(GroupStatsPreProcessor, self).__init__()\\n        self.all_groups = [\\\"intelligence\\\", \\\"wisdom\\\", \\\"charisma\\\",\\n                           \\\"dexterity\\\", \\\"strength\\\", \\\"constitution\\\"]\\n        self.group_names = groups if groups else self.all_groups\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        self._check_data_validity(dataset=dataset)\\n        dataset.dataf = dataset.dataf.pipe(self._add_group_features)\\n        return Dataset(**dataset.__dict__)\\n\\n    def _add_group_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\" Mean, standard deviation and skew for each group. \\\"\\\"\\\"\\n        for group in self.group_names:\\n            cols = [col for col in dataf.columns if group in col]\\n            dataf[f\\\"feature_{group}_mean\\\"] = dataf[cols].mean(axis=1)\\n            dataf[f\\\"feature_{group}_std\\\"] = dataf[cols].std(axis=1)\\n            dataf[f\\\"feature_{group}_skew\\\"] = dataf[cols].skew(axis=1)\\n        return dataf\\n\\n    def _check_data_validity(self, dataset: Dataset):\\n        assert hasattr(dataset, 'version'), f\\\"Version should be specified for '{self.__class__.__name__}' This Preprocessor will only work on version 1 data.\\\"\\n        assert getattr(dataset, 'version') == 1, f\\\"'{self.__class__.__name__}' only works on version 1 data. Got version: '{getattr(dataset, 'version')}'.\\\"\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass GroupStatsPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    WARNING: Only supported for Version 1 (legacy) data.\\n    Calculate group statistics for all data groups.\\n    :param groups: Groups to create features for. All groups by default.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, groups: list = None):\\n        super(GroupStatsPreProcessor, self).__init__()\\n        self.all_groups = [\\n            \\\"intelligence\\\",\\n            \\\"wisdom\\\",\\n            \\\"charisma\\\",\\n            \\\"dexterity\\\",\\n            \\\"strength\\\",\\n            \\\"constitution\\\",\\n        ]\\n        self.group_names = groups if groups else self.all_groups\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        self._check_data_validity(dataset=dataset)\\n        dataset.dataf = dataset.dataf.pipe(self._add_group_features)\\n        return Dataset(**dataset.__dict__)\\n\\n    def _add_group_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"Mean, standard deviation and skew for each group.\\\"\\\"\\\"\\n        for group in self.group_names:\\n            cols = [col for col in dataf.columns if group in col]\\n            dataf[f\\\"feature_{group}_mean\\\"] = dataf[cols].mean(axis=1)\\n            dataf[f\\\"feature_{group}_std\\\"] = dataf[cols].std(axis=1)\\n            dataf[f\\\"feature_{group}_skew\\\"] = dataf[cols].skew(axis=1)\\n        return dataf\\n\\n    def _check_data_validity(self, dataset: Dataset):\\n        assert hasattr(\\n            dataset, \\\"version\\\"\\n        ), f\\\"Version should be specified for '{self.__class__.__name__}' This Preprocessor will only work on version 1 data.\\\"\\n        assert (\\n            getattr(dataset, \\\"version\\\") == 1\\n        ), f\\\"'{self.__class__.__name__}' only works on version 1 data. Got version: '{getattr(dataset, 'version')}'.\\\"\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#export\n",
    "@typechecked\n",
    "class GroupStatsPreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    WARNING: Only supported for Version 1 (legacy) data.\n",
    "    Calculate group statistics for all data groups.\n",
    "    :param groups: Groups to create features for. All groups by default.\n",
    "    \"\"\"\n",
    "    def __init__(self, groups: list = None):\n",
    "        super(GroupStatsPreProcessor, self).__init__()\n",
    "        self.all_groups = [\"intelligence\", \"wisdom\", \"charisma\",\n",
    "                           \"dexterity\", \"strength\", \"constitution\"]\n",
    "        self.group_names = groups if groups else self.all_groups\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n",
    "        self._check_data_validity(dataset=dataset)\n",
    "        dataset.dataf = dataset.dataf.pipe(self._add_group_features)\n",
    "        return Dataset(**dataset.__dict__)\n",
    "\n",
    "    def _add_group_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\" Mean, standard deviation and skew for each group. \"\"\"\n",
    "        for group in self.group_names:\n",
    "            cols = [col for col in dataf.columns if group in col]\n",
    "            dataf[f\"feature_{group}_mean\"] = dataf[cols].mean(axis=1)\n",
    "            dataf[f\"feature_{group}_std\"] = dataf[cols].std(axis=1)\n",
    "            dataf[f\"feature_{group}_skew\"] = dataf[cols].skew(axis=1)\n",
    "        return dataf\n",
    "\n",
    "    def _check_data_validity(self, dataset: Dataset):\n",
    "        assert hasattr(dataset, 'version'), f\"Version should be specified for '{self.__class__.__name__}' This Preprocessor will only work on version 1 data.\"\n",
    "        assert getattr(dataset, 'version') == 1, f\"'{self.__class__.__name__}' only works on version 1 data. Got version: '{getattr(dataset, 'version')}'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mGroupStatsPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m332\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m022085\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">GroupStatsPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">332</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">022085</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 19;\n                var nbb_unformatted_code = \"group_features_dataset = GroupStatsPreProcessor().transform(copied_dataset)\\ngroup_features_dataset.dataf.head(2)\\nassert group_features_dataset.version == 1\";\n                var nbb_formatted_code = \"group_features_dataset = GroupStatsPreProcessor().transform(copied_dataset)\\ngroup_features_dataset.dataf.head(2)\\nassert group_features_dataset.version == 1\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_features_dataset = GroupStatsPreProcessor().transform(copied_dataset)\n",
    "group_features_dataset.dataf.head(2)\n",
    "assert group_features_dataset.version == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   feature_intelligence_mean  feature_intelligence_std  \\\n0                   0.333333                  0.246183   \n1                   0.208333                  0.234359   \n\n   feature_intelligence_skew  feature_wisdom_mean  feature_wisdom_std  \\\n0                   0.558528             0.668478            0.236022   \n1                   0.382554             0.559783            0.358177   \n\n   feature_wisdom_skew  feature_charisma_mean  feature_charisma_std  \\\n0            -0.115082               0.438953              0.259910   \n1            -0.062362               0.485465              0.252501   \n\n   feature_charisma_skew  feature_dexterity_mean  feature_dexterity_std  \\\n0              -0.004783                0.696429               0.200446   \n1              -0.021737                0.267857               0.249312   \n\n   feature_dexterity_skew  feature_strength_mean  feature_strength_std  \\\n0               -0.607620               0.480263              0.292829   \n1                0.382267               0.407895              0.309866   \n\n   feature_strength_skew  feature_constitution_mean  feature_constitution_std  \\\n0              -0.372064                   0.427632                   0.27572   \n1               0.220625                   0.644737                   0.33408   \n\n   feature_constitution_skew  \n0                   0.276155  \n1                  -0.794938  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_intelligence_mean</th>\n      <th>feature_intelligence_std</th>\n      <th>feature_intelligence_skew</th>\n      <th>feature_wisdom_mean</th>\n      <th>feature_wisdom_std</th>\n      <th>feature_wisdom_skew</th>\n      <th>feature_charisma_mean</th>\n      <th>feature_charisma_std</th>\n      <th>feature_charisma_skew</th>\n      <th>feature_dexterity_mean</th>\n      <th>feature_dexterity_std</th>\n      <th>feature_dexterity_skew</th>\n      <th>feature_strength_mean</th>\n      <th>feature_strength_std</th>\n      <th>feature_strength_skew</th>\n      <th>feature_constitution_mean</th>\n      <th>feature_constitution_std</th>\n      <th>feature_constitution_skew</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.333333</td>\n      <td>0.246183</td>\n      <td>0.558528</td>\n      <td>0.668478</td>\n      <td>0.236022</td>\n      <td>-0.115082</td>\n      <td>0.438953</td>\n      <td>0.259910</td>\n      <td>-0.004783</td>\n      <td>0.696429</td>\n      <td>0.200446</td>\n      <td>-0.607620</td>\n      <td>0.480263</td>\n      <td>0.292829</td>\n      <td>-0.372064</td>\n      <td>0.427632</td>\n      <td>0.27572</td>\n      <td>0.276155</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.208333</td>\n      <td>0.234359</td>\n      <td>0.382554</td>\n      <td>0.559783</td>\n      <td>0.358177</td>\n      <td>-0.062362</td>\n      <td>0.485465</td>\n      <td>0.252501</td>\n      <td>-0.021737</td>\n      <td>0.267857</td>\n      <td>0.249312</td>\n      <td>0.382267</td>\n      <td>0.407895</td>\n      <td>0.309866</td>\n      <td>0.220625</td>\n      <td>0.644737</td>\n      <td>0.33408</td>\n      <td>-0.794938</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 20;\n                var nbb_unformatted_code = \"new_cols =  ['feature_intelligence_mean', 'feature_intelligence_std', 'feature_intelligence_skew',\\n             'feature_wisdom_mean', 'feature_wisdom_std', 'feature_wisdom_skew',\\n             'feature_charisma_mean', 'feature_charisma_std', 'feature_charisma_skew',\\n             'feature_dexterity_mean', 'feature_dexterity_std', 'feature_dexterity_skew',\\n             'feature_strength_mean', 'feature_strength_std', 'feature_strength_skew',\\n             'feature_constitution_mean', 'feature_constitution_std', 'feature_constitution_skew']\\nassert set(group_features_dataset.dataf.columns).intersection(new_cols)\\ngroup_features_dataset.get_feature_data[new_cols].head(2)\";\n                var nbb_formatted_code = \"new_cols = [\\n    \\\"feature_intelligence_mean\\\",\\n    \\\"feature_intelligence_std\\\",\\n    \\\"feature_intelligence_skew\\\",\\n    \\\"feature_wisdom_mean\\\",\\n    \\\"feature_wisdom_std\\\",\\n    \\\"feature_wisdom_skew\\\",\\n    \\\"feature_charisma_mean\\\",\\n    \\\"feature_charisma_std\\\",\\n    \\\"feature_charisma_skew\\\",\\n    \\\"feature_dexterity_mean\\\",\\n    \\\"feature_dexterity_std\\\",\\n    \\\"feature_dexterity_skew\\\",\\n    \\\"feature_strength_mean\\\",\\n    \\\"feature_strength_std\\\",\\n    \\\"feature_strength_skew\\\",\\n    \\\"feature_constitution_mean\\\",\\n    \\\"feature_constitution_std\\\",\\n    \\\"feature_constitution_skew\\\",\\n]\\nassert set(group_features_dataset.dataf.columns).intersection(new_cols)\\ngroup_features_dataset.get_feature_data[new_cols].head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_cols =  ['feature_intelligence_mean', 'feature_intelligence_std', 'feature_intelligence_skew',\n",
    "             'feature_wisdom_mean', 'feature_wisdom_std', 'feature_wisdom_skew',\n",
    "             'feature_charisma_mean', 'feature_charisma_std', 'feature_charisma_skew',\n",
    "             'feature_dexterity_mean', 'feature_dexterity_std', 'feature_dexterity_skew',\n",
    "             'feature_strength_mean', 'feature_strength_std', 'feature_strength_skew',\n",
    "             'feature_constitution_mean', 'feature_constitution_std', 'feature_constitution_skew']\n",
    "assert set(group_features_dataset.dataf.columns).intersection(new_cols)\n",
    "group_features_dataset.get_feature_data[new_cols].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GroupStatsPreProcessor` should break if `version != 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 21;\n                var nbb_unformatted_code = \"def test_invalid_version(dataset: Dataset):\\n    copied_dataset = dataset.copy_dataset()\\n    copied_dataset.version = 2\\n    try:\\n        GroupStatsPreProcessor().transform(copied_dataset)\\n    except AssertionError:\\n        return True\\n    return False\\n\\ntest_invalid_version(dataset);\";\n                var nbb_formatted_code = \"def test_invalid_version(dataset: Dataset):\\n    copied_dataset = dataset.copy_dataset()\\n    copied_dataset.version = 2\\n    try:\\n        GroupStatsPreProcessor().transform(copied_dataset)\\n    except AssertionError:\\n        return True\\n    return False\\n\\n\\ntest_invalid_version(dataset)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_invalid_version(dataset: Dataset):\n",
    "    copied_dataset = dataset.copy_dataset()\n",
    "    copied_dataset.version = 2\n",
    "    try:\n",
    "        GroupStatsPreProcessor().transform(copied_dataset)\n",
    "    except AssertionError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "test_invalid_version(dataset);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Version 2 specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Signals specific"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.4.1. Pattern Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 22;\n                var nbb_unformatted_code = \"# # export\\n# @typechecked\\n# class TalibPatternFeatures(BaseProcessor):\\n#     \\\"\\\"\\\"\\n#     Get all pattern recognition features available in TA-Lib\\n#     More information: https://mrjbq7.github.io/ta-lib/func_groups/pattern_recognition.html\\n#     \\\"\\\"\\\"\\n#     def __init__(self, ticker_col: str = \\\"ticker\\\"):\\n#         super(TalibPatternFeatures, self).__init__()\\n#         self.ticker_col = ticker_col\\n#         # All pattern recognition features start with \\\"CDL\\\" in TA-Lib\\n#         self.funcs = [getattr(talib, name) for name in dir(talib) if name.startswith(\\\"CDL\\\")]\\n#\\n#     @display_processor_info\\n#     def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n#         all_tickers = list(dataset.dataf[self.ticker_col].unique())\\n#         for func in self.funcs:\\n#             for ticker in all_tickers:\\n#                 index_mask = dataset.dataf[self.ticker_col] == ticker\\n#                 sub_df = dataset.dataf.loc[index_mask, :]\\n#                 open, high = sub_df['Open'], sub_df['High']\\n#                 low, close = sub_df['Low'], sub_df['Close']\\n#                 dataset.dataf.loc[index_mask, f\\\"feature_{func.__qualname__}\\\"] = func(open, high, low, close)\\n#         return Dataset(**dataset.__dict__)\";\n                var nbb_formatted_code = \"# # export\\n# @typechecked\\n# class TalibPatternFeatures(BaseProcessor):\\n#     \\\"\\\"\\\"\\n#     Get all pattern recognition features available in TA-Lib\\n#     More information: https://mrjbq7.github.io/ta-lib/func_groups/pattern_recognition.html\\n#     \\\"\\\"\\\"\\n#     def __init__(self, ticker_col: str = \\\"ticker\\\"):\\n#         super(TalibPatternFeatures, self).__init__()\\n#         self.ticker_col = ticker_col\\n#         # All pattern recognition features start with \\\"CDL\\\" in TA-Lib\\n#         self.funcs = [getattr(talib, name) for name in dir(talib) if name.startswith(\\\"CDL\\\")]\\n#\\n#     @display_processor_info\\n#     def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n#         all_tickers = list(dataset.dataf[self.ticker_col].unique())\\n#         for func in self.funcs:\\n#             for ticker in all_tickers:\\n#                 index_mask = dataset.dataf[self.ticker_col] == ticker\\n#                 sub_df = dataset.dataf.loc[index_mask, :]\\n#                 open, high = sub_df['Open'], sub_df['High']\\n#                 low, close = sub_df['Low'], sub_df['Close']\\n#                 dataset.dataf.loc[index_mask, f\\\"feature_{func.__qualname__}\\\"] = func(open, high, low, close)\\n#         return Dataset(**dataset.__dict__)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # export\n",
    "# @typechecked\n",
    "# class TalibPatternFeatures(BaseProcessor):\n",
    "#     \"\"\"\n",
    "#     Get all pattern recognition features available in TA-Lib\n",
    "#     More information: https://mrjbq7.github.io/ta-lib/func_groups/pattern_recognition.html\n",
    "#     \"\"\"\n",
    "#     def __init__(self, ticker_col: str = \"ticker\"):\n",
    "#         super(TalibPatternFeatures, self).__init__()\n",
    "#         self.ticker_col = ticker_col\n",
    "#         # All pattern recognition features start with \"CDL\" in TA-Lib\n",
    "#         self.funcs = [getattr(talib, name) for name in dir(talib) if name.startswith(\"CDL\")]\n",
    "#\n",
    "#     @display_processor_info\n",
    "#     def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n",
    "#         all_tickers = list(dataset.dataf[self.ticker_col].unique())\n",
    "#         for func in self.funcs:\n",
    "#             for ticker in all_tickers:\n",
    "#                 index_mask = dataset.dataf[self.ticker_col] == ticker\n",
    "#                 sub_df = dataset.dataf.loc[index_mask, :]\n",
    "#                 open, high = sub_df['Open'], sub_df['High']\n",
    "#                 low, close = sub_df['Low'], sub_df['Close']\n",
    "#                 dataset.dataf.loc[index_mask, f\"feature_{func.__qualname__}\"] = func(open, high, low, close)\n",
    "#         return Dataset(**dataset.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 23;\n                var nbb_unformatted_code = \"# signals_test_data = create_dataset(\\\"test_assets/bitcoin_time_series_test_data.csv\\\")\\n# ticker_col = \\\"Symbol\\\"\\n# ta_patterns = TalibPatternFeatures(ticker_col=ticker_col)\\n# transformed_dataset = ta_patterns.transform(signals_test_data)\\n# assert len(transformed_dataset.feature_cols) == 61\\n# assert not (transformed_dataset.get_feature_data == 0).all().all()\\n# transformed_dataset.get_feature_data.head(2)\";\n                var nbb_formatted_code = \"# signals_test_data = create_dataset(\\\"test_assets/bitcoin_time_series_test_data.csv\\\")\\n# ticker_col = \\\"Symbol\\\"\\n# ta_patterns = TalibPatternFeatures(ticker_col=ticker_col)\\n# transformed_dataset = ta_patterns.transform(signals_test_data)\\n# assert len(transformed_dataset.feature_cols) == 61\\n# assert not (transformed_dataset.get_feature_data == 0).all().all()\\n# transformed_dataset.get_feature_data.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# signals_test_data = create_dataset(\"test_assets/bitcoin_time_series_test_data.csv\")\n",
    "# ticker_col = \"Symbol\"\n",
    "# ta_patterns = TalibPatternFeatures(ticker_col=ticker_col)\n",
    "# transformed_dataset = ta_patterns.transform(signals_test_data)\n",
    "# assert len(transformed_dataset.feature_cols) == 61\n",
    "# assert not (transformed_dataset.get_feature_data == 0).all().all()\n",
    "# transformed_dataset.get_feature_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.4.2. Volume indicators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 24;\n                var nbb_unformatted_code = \"# # export\\n# @typechecked\\n# class TalibVolumeFeatures(BaseProcessor):\\n#     \\\"\\\"\\\"\\n#     Get all volume features using TA-Lib\\n#     More information: https://mrjbq7.github.io/ta-lib/func_groups/volume_indicators.html\\n#\\n#     :param ticker_col: Column name that points to ticker names\\n#     :param fastperiod, slowperiod: Periodic arguments for ADOSC (Chaikin A/D Oscillator).\\n#     See http://www.tadoc.org/indicator/ADOSC.htm for more information on how these arguments are used.\\n#     \\\"\\\"\\\"\\n#     def __init__(self, ticker_col: str = \\\"ticker\\\", fastperiod: int = 3, slowperiod: int = 10):\\n#         super(TalibVolumeFeatures, self).__init__()\\n#         self.ticker_col = ticker_col\\n#         self.volume_features = ['AD', 'ADOSC', 'OBV']\\n#         self.fastperiod = fastperiod\\n#         self.slowperiod = slowperiod\\n#\\n#     @display_processor_info\\n#     def transform(self, dataset: Dataset) -> Dataset:\\n#         all_tickers = list(dataset.dataf[self.ticker_col].unique())\\n#         for ticker in all_tickers:\\n#             index_mask = dataset.dataf[self.ticker_col] == ticker\\n#             sub_df = dataset.dataf.loc[index_mask, :]\\n#\\n#             high, low = sub_df['High'].to_numpy(), sub_df['Low'].to_numpy()\\n#             close, volume = sub_df['Close'].to_numpy(), sub_df['Volume'].to_numpy()\\n#\\n#             dataset.dataf.loc[index_mask, \\\"feature_AD\\\"] = talib.AD(high, low, close, volume)\\n#             adosc = talib.ADOSC(high, low, close, volume, fastperiod=self.fastperiod, slowperiod=self.slowperiod)\\n#             dataset.dataf.loc[index_mask, \\\"feature_ADOSC\\\"] = np.nan_to_num(adosc, nan=0.0)\\n#             dataset.dataf.loc[index_mask, \\\"feature_OBV\\\"] = talib.OBV(close, volume)\\n#         return Dataset(**dataset.__dict__)\";\n                var nbb_formatted_code = \"# # export\\n# @typechecked\\n# class TalibVolumeFeatures(BaseProcessor):\\n#     \\\"\\\"\\\"\\n#     Get all volume features using TA-Lib\\n#     More information: https://mrjbq7.github.io/ta-lib/func_groups/volume_indicators.html\\n#\\n#     :param ticker_col: Column name that points to ticker names\\n#     :param fastperiod, slowperiod: Periodic arguments for ADOSC (Chaikin A/D Oscillator).\\n#     See http://www.tadoc.org/indicator/ADOSC.htm for more information on how these arguments are used.\\n#     \\\"\\\"\\\"\\n#     def __init__(self, ticker_col: str = \\\"ticker\\\", fastperiod: int = 3, slowperiod: int = 10):\\n#         super(TalibVolumeFeatures, self).__init__()\\n#         self.ticker_col = ticker_col\\n#         self.volume_features = ['AD', 'ADOSC', 'OBV']\\n#         self.fastperiod = fastperiod\\n#         self.slowperiod = slowperiod\\n#\\n#     @display_processor_info\\n#     def transform(self, dataset: Dataset) -> Dataset:\\n#         all_tickers = list(dataset.dataf[self.ticker_col].unique())\\n#         for ticker in all_tickers:\\n#             index_mask = dataset.dataf[self.ticker_col] == ticker\\n#             sub_df = dataset.dataf.loc[index_mask, :]\\n#\\n#             high, low = sub_df['High'].to_numpy(), sub_df['Low'].to_numpy()\\n#             close, volume = sub_df['Close'].to_numpy(), sub_df['Volume'].to_numpy()\\n#\\n#             dataset.dataf.loc[index_mask, \\\"feature_AD\\\"] = talib.AD(high, low, close, volume)\\n#             adosc = talib.ADOSC(high, low, close, volume, fastperiod=self.fastperiod, slowperiod=self.slowperiod)\\n#             dataset.dataf.loc[index_mask, \\\"feature_ADOSC\\\"] = np.nan_to_num(adosc, nan=0.0)\\n#             dataset.dataf.loc[index_mask, \\\"feature_OBV\\\"] = talib.OBV(close, volume)\\n#         return Dataset(**dataset.__dict__)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # export\n",
    "# @typechecked\n",
    "# class TalibVolumeFeatures(BaseProcessor):\n",
    "#     \"\"\"\n",
    "#     Get all volume features using TA-Lib\n",
    "#     More information: https://mrjbq7.github.io/ta-lib/func_groups/volume_indicators.html\n",
    "#\n",
    "#     :param ticker_col: Column name that points to ticker names\n",
    "#     :param fastperiod, slowperiod: Periodic arguments for ADOSC (Chaikin A/D Oscillator).\n",
    "#     See http://www.tadoc.org/indicator/ADOSC.htm for more information on how these arguments are used.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, ticker_col: str = \"ticker\", fastperiod: int = 3, slowperiod: int = 10):\n",
    "#         super(TalibVolumeFeatures, self).__init__()\n",
    "#         self.ticker_col = ticker_col\n",
    "#         self.volume_features = ['AD', 'ADOSC', 'OBV']\n",
    "#         self.fastperiod = fastperiod\n",
    "#         self.slowperiod = slowperiod\n",
    "#\n",
    "#     @display_processor_info\n",
    "#     def transform(self, dataset: Dataset) -> Dataset:\n",
    "#         all_tickers = list(dataset.dataf[self.ticker_col].unique())\n",
    "#         for ticker in all_tickers:\n",
    "#             index_mask = dataset.dataf[self.ticker_col] == ticker\n",
    "#             sub_df = dataset.dataf.loc[index_mask, :]\n",
    "#\n",
    "#             high, low = sub_df['High'].to_numpy(), sub_df['Low'].to_numpy()\n",
    "#             close, volume = sub_df['Close'].to_numpy(), sub_df['Volume'].to_numpy()\n",
    "#\n",
    "#             dataset.dataf.loc[index_mask, \"feature_AD\"] = talib.AD(high, low, close, volume)\n",
    "#             adosc = talib.ADOSC(high, low, close, volume, fastperiod=self.fastperiod, slowperiod=self.slowperiod)\n",
    "#             dataset.dataf.loc[index_mask, \"feature_ADOSC\"] = np.nan_to_num(adosc, nan=0.0)\n",
    "#             dataset.dataf.loc[index_mask, \"feature_OBV\"] = talib.OBV(close, volume)\n",
    "#         return Dataset(**dataset.__dict__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 25;\n                var nbb_unformatted_code = \"# signals_test_data = create_dataset(\\\"test_assets/bitcoin_time_series_test_data.csv\\\")\\n# ticker_col = \\\"Symbol\\\"\\n# fastperiod, slowperiod = 4, 11\\n# ta_volume_features = TalibVolumeFeatures(ticker_col=ticker_col, fastperiod=fastperiod, slowperiod=slowperiod)\\n# dataset_with_volume_features = ta_volume_features.transform(dataset=signals_test_data)\\n# assert fastperiod == ta_volume_features.fastperiod\\n# assert slowperiod == ta_volume_features.slowperiod\\n# assert list(dataset_with_volume_features.get_feature_data.columns) == [f\\\"feature_{name}\\\" for name in ta_volume_features.volume_features]\\n# dataset_with_volume_features.get_feature_data.head(2)\";\n                var nbb_formatted_code = \"# signals_test_data = create_dataset(\\\"test_assets/bitcoin_time_series_test_data.csv\\\")\\n# ticker_col = \\\"Symbol\\\"\\n# fastperiod, slowperiod = 4, 11\\n# ta_volume_features = TalibVolumeFeatures(ticker_col=ticker_col, fastperiod=fastperiod, slowperiod=slowperiod)\\n# dataset_with_volume_features = ta_volume_features.transform(dataset=signals_test_data)\\n# assert fastperiod == ta_volume_features.fastperiod\\n# assert slowperiod == ta_volume_features.slowperiod\\n# assert list(dataset_with_volume_features.get_feature_data.columns) == [f\\\"feature_{name}\\\" for name in ta_volume_features.volume_features]\\n# dataset_with_volume_features.get_feature_data.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# signals_test_data = create_dataset(\"test_assets/bitcoin_time_series_test_data.csv\")\n",
    "# ticker_col = \"Symbol\"\n",
    "# fastperiod, slowperiod = 4, 11\n",
    "# ta_volume_features = TalibVolumeFeatures(ticker_col=ticker_col, fastperiod=fastperiod, slowperiod=slowperiod)\n",
    "# dataset_with_volume_features = ta_volume_features.transform(dataset=signals_test_data)\n",
    "# assert fastperiod == ta_volume_features.fastperiod\n",
    "# assert slowperiod == ta_volume_features.slowperiod\n",
    "# assert list(dataset_with_volume_features.get_feature_data.columns) == [f\"feature_{name}\" for name in ta_volume_features.volume_features]\n",
    "# dataset_with_volume_features.get_feature_data.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4.3. Realized volatility"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement 30day and 90 days, 180 days and 360 days vol?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 26;\n                var nbb_unformatted_code = \"# export\\n# @typechecked\\n# class RealizedVolFeatures(BaseProcessor):\\n#     \\\"\\\"\\\"\\n#     Features based on realized volatility features.\\n#     Dataset DataFrame should have a column named \\\"Close\\\".\\n#     Source and more information: https://dspyt.com/advanced-realized-volatility-and-quarticity/\\n#     \\\"\\\"\\\"\\n#     def __init__(self, ticker_col: str = 'ticker', price_col: str = 'Close'):\\n#         super(RealizedVolFeatures, self).__init__()\\n#         self.ticker_col = ticker_col\\n#         self.price_col = price_col\\n#\\n#     @display_processor_info\\n#     def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n#         \\\"\\\"\\\" Get all realized volatility features. \\\"\\\"\\\"\\n#         series = dataset.dataf.loc[:, self.price_col]\\n#         tickers = dataset.dataf.loc[:, self.ticker_col]\\n#         dataset.dataf.loc[:, \\\"feature_vol2\\\"] = series.groupby(tickers).agg(self.realized_2)\\n#         dataset.dataf.loc[:, \\\"feature_vol3\\\"] = series.groupby(tickers).agg(self.realized_3)\\n#         dataset.dataf.loc[:, \\\"feature_vol4\\\"] = series.groupby(tickers).agg(self.realized_4)\\n#         # Parse all contents of Dataset to the next pipeline step\\n#         return Dataset(**dataset.__dict__)\\n#\\n#     @staticmethod\\n#     def simple_realized_vol(series: pd.Series) -> np.float64:\\n#         \\\"\\\"\\\" Most simple way to calculate realized volatility. \\\"\\\"\\\"\\n#         return np.sqrt(np.sum(series**2))\\n#\\n#     @staticmethod\\n#     def realized_2(series: pd.Series) -> np.float64:\\n#         return np.sqrt(np.sum(series**4)/(6*np.sum(series**2)))\\n#\\n#     @staticmethod\\n#     def realized_3(series: pd.Series) -> np.float64:\\n#         return np.sqrt(((np.pi**2)*np.sum(abs(series.rolling(window=4).apply(np.product,\\n#                                                                              raw=True))))/(8*np.sum(series**2)))\\n#\\n#     @staticmethod\\n#     def realized_4(series: pd.Series) -> np.float64:\\n#         numerator = (gamma(1/2)**3)*np.sum((abs(series)**(4/3)).rolling(window=3).apply(np.prod))\\n#         denominator = 8 * (gamma(7/6)**3)*np.sum(series**2)\\n#         return np.sqrt(numerator/denominator)\";\n                var nbb_formatted_code = \"# export\\n# @typechecked\\n# class RealizedVolFeatures(BaseProcessor):\\n#     \\\"\\\"\\\"\\n#     Features based on realized volatility features.\\n#     Dataset DataFrame should have a column named \\\"Close\\\".\\n#     Source and more information: https://dspyt.com/advanced-realized-volatility-and-quarticity/\\n#     \\\"\\\"\\\"\\n#     def __init__(self, ticker_col: str = 'ticker', price_col: str = 'Close'):\\n#         super(RealizedVolFeatures, self).__init__()\\n#         self.ticker_col = ticker_col\\n#         self.price_col = price_col\\n#\\n#     @display_processor_info\\n#     def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n#         \\\"\\\"\\\" Get all realized volatility features. \\\"\\\"\\\"\\n#         series = dataset.dataf.loc[:, self.price_col]\\n#         tickers = dataset.dataf.loc[:, self.ticker_col]\\n#         dataset.dataf.loc[:, \\\"feature_vol2\\\"] = series.groupby(tickers).agg(self.realized_2)\\n#         dataset.dataf.loc[:, \\\"feature_vol3\\\"] = series.groupby(tickers).agg(self.realized_3)\\n#         dataset.dataf.loc[:, \\\"feature_vol4\\\"] = series.groupby(tickers).agg(self.realized_4)\\n#         # Parse all contents of Dataset to the next pipeline step\\n#         return Dataset(**dataset.__dict__)\\n#\\n#     @staticmethod\\n#     def simple_realized_vol(series: pd.Series) -> np.float64:\\n#         \\\"\\\"\\\" Most simple way to calculate realized volatility. \\\"\\\"\\\"\\n#         return np.sqrt(np.sum(series**2))\\n#\\n#     @staticmethod\\n#     def realized_2(series: pd.Series) -> np.float64:\\n#         return np.sqrt(np.sum(series**4)/(6*np.sum(series**2)))\\n#\\n#     @staticmethod\\n#     def realized_3(series: pd.Series) -> np.float64:\\n#         return np.sqrt(((np.pi**2)*np.sum(abs(series.rolling(window=4).apply(np.product,\\n#                                                                              raw=True))))/(8*np.sum(series**2)))\\n#\\n#     @staticmethod\\n#     def realized_4(series: pd.Series) -> np.float64:\\n#         numerator = (gamma(1/2)**3)*np.sum((abs(series)**(4/3)).rolling(window=3).apply(np.prod))\\n#         denominator = 8 * (gamma(7/6)**3)*np.sum(series**2)\\n#         return np.sqrt(numerator/denominator)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "# @typechecked\n",
    "# class RealizedVolFeatures(BaseProcessor):\n",
    "#     \"\"\"\n",
    "#     Features based on realized volatility features.\n",
    "#     Dataset DataFrame should have a column named \"Close\".\n",
    "#     Source and more information: https://dspyt.com/advanced-realized-volatility-and-quarticity/\n",
    "#     \"\"\"\n",
    "#     def __init__(self, ticker_col: str = 'ticker', price_col: str = 'Close'):\n",
    "#         super(RealizedVolFeatures, self).__init__()\n",
    "#         self.ticker_col = ticker_col\n",
    "#         self.price_col = price_col\n",
    "#\n",
    "#     @display_processor_info\n",
    "#     def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n",
    "#         \"\"\" Get all realized volatility features. \"\"\"\n",
    "#         series = dataset.dataf.loc[:, self.price_col]\n",
    "#         tickers = dataset.dataf.loc[:, self.ticker_col]\n",
    "#         dataset.dataf.loc[:, \"feature_vol2\"] = series.groupby(tickers).agg(self.realized_2)\n",
    "#         dataset.dataf.loc[:, \"feature_vol3\"] = series.groupby(tickers).agg(self.realized_3)\n",
    "#         dataset.dataf.loc[:, \"feature_vol4\"] = series.groupby(tickers).agg(self.realized_4)\n",
    "#         # Parse all contents of Dataset to the next pipeline step\n",
    "#         return Dataset(**dataset.__dict__)\n",
    "#\n",
    "#     @staticmethod\n",
    "#     def simple_realized_vol(series: pd.Series) -> np.float64:\n",
    "#         \"\"\" Most simple way to calculate realized volatility. \"\"\"\n",
    "#         return np.sqrt(np.sum(series**2))\n",
    "#\n",
    "#     @staticmethod\n",
    "#     def realized_2(series: pd.Series) -> np.float64:\n",
    "#         return np.sqrt(np.sum(series**4)/(6*np.sum(series**2)))\n",
    "#\n",
    "#     @staticmethod\n",
    "#     def realized_3(series: pd.Series) -> np.float64:\n",
    "#         return np.sqrt(((np.pi**2)*np.sum(abs(series.rolling(window=4).apply(np.product,\n",
    "#                                                                              raw=True))))/(8*np.sum(series**2)))\n",
    "#\n",
    "#     @staticmethod\n",
    "#     def realized_4(series: pd.Series) -> np.float64:\n",
    "#         numerator = (gamma(1/2)**3)*np.sum((abs(series)**(4/3)).rolling(window=3).apply(np.prod))\n",
    "#         denominator = 8 * (gamma(7/6)**3)*np.sum(series**2)\n",
    "#         return np.sqrt(numerator/denominator)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 27;\n                var nbb_unformatted_code = \"# signals_test_data = create_dataset(\\\"test_assets/bitcoin_time_series_test_data.csv\\\")\\n# ticker_col = \\\"Symbol\\\"\\n# vol_features = RealizedVolFeatures(ticker_col=ticker_col)\\n# dataset_with_vol_features = vol_features.transform(dataset=signals_test_data)\\n# all_vol_cols = ['feature_vol2', 'feature_vol3', 'feature_vol4']\\n# assert dataset_with_vol_features.feature_cols == all_vol_cols\\n# for col in all_vol_cols:\\n#     assert dataset_with_vol_features.dataf[col].value_counts().nunique() != 1\\n# # assert not dataset_with_vol_features.get_feature_data.isna().all().all()\\n# dataset_with_vol_features.get_feature_data.head(3)\";\n                var nbb_formatted_code = \"# signals_test_data = create_dataset(\\\"test_assets/bitcoin_time_series_test_data.csv\\\")\\n# ticker_col = \\\"Symbol\\\"\\n# vol_features = RealizedVolFeatures(ticker_col=ticker_col)\\n# dataset_with_vol_features = vol_features.transform(dataset=signals_test_data)\\n# all_vol_cols = ['feature_vol2', 'feature_vol3', 'feature_vol4']\\n# assert dataset_with_vol_features.feature_cols == all_vol_cols\\n# for col in all_vol_cols:\\n#     assert dataset_with_vol_features.dataf[col].value_counts().nunique() != 1\\n# # assert not dataset_with_vol_features.get_feature_data.isna().all().all()\\n# dataset_with_vol_features.get_feature_data.head(3)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# signals_test_data = create_dataset(\"test_assets/bitcoin_time_series_test_data.csv\")\n",
    "# ticker_col = \"Symbol\"\n",
    "# vol_features = RealizedVolFeatures(ticker_col=ticker_col)\n",
    "# dataset_with_vol_features = vol_features.transform(dataset=signals_test_data)\n",
    "# all_vol_cols = ['feature_vol2', 'feature_vol3', 'feature_vol4']\n",
    "# assert dataset_with_vol_features.feature_cols == all_vol_cols\n",
    "# for col in all_vol_cols:\n",
    "#     assert dataset_with_vol_features.dataf[col].value_counts().nunique() != 1\n",
    "# # assert not dataset_with_vol_features.get_feature_data.isna().all().all()\n",
    "# dataset_with_vol_features.get_feature_data.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4.4. Quarticity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 28;\n                var nbb_unformatted_code = \"# export\\n# @typechecked\\n# class QuarticityFeatures(BaseProcessor):\\n#     \\\"\\\"\\\"\\n#     Quarticity (Vol of vol) features.\\n#     Source and more information: https://dspyt.com/advanced-realized-volatility-and-quarticity/\\n#     \\\"\\\"\\\"\\n#     def __init__(self, ticker_col: str = 'ticker', price_col: str = 'Close'):\\n#         super(QuarticityFeatures, self).__init__()\\n#         self.ticker_col = ticker_col\\n#         self.price_col = price_col\\n#\\n#     @display_processor_info\\n#     def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n#         \\\"\\\"\\\" Get most powerful quarticity features for every stock. \\\"\\\"\\\"\\n#         series = dataset.dataf.loc[:, self.price_col]\\n#         tickers = dataset.dataf.loc[:, self.ticker_col]\\n#         quad_quarticity = series.groupby(tickers).agg(self.realized_quadpower_quarticity)\\n#         tripower_quarticity = series.groupby(tickers).agg(self.realized_tripower_quarticity)\\n#         dataset.dataf.loc[:, \\\"feature_quadpower_quarticity\\\"] = quad_quarticity\\n#         dataset.dataf.loc[:, \\\"feature_tripower_quarticity\\\"] = tripower_quarticity\\n#         return Dataset(**dataset.__dict__)\\n#\\n#     @staticmethod\\n#     def realized_quarticity(series: pd.Series) -> np.float64:\\n#         \\\"\\\"\\\"\\n#         The realized fourth-power variation or realized quarticity\\n#         is a consistent estimator of the integrated quarticity.\\n#         \\\"\\\"\\\"\\n#         return np.sum(series**4) * series.shape[0] / 3\\n#\\n#     @staticmethod\\n#     def realized_quadpower_quarticity(series: pd.Series) -> np.float64:\\n#         \\\"\\\"\\\"\\n#         A more robust estimator compared to realized quarticity,\\n#         particularly in the presence of jumps, is the realized quad-power quarticity.\\n#         \\\"\\\"\\\"\\n#         series = abs(series.rolling(window=4).apply(np.product, raw=True))\\n#         return (np.sum(series) * series.shape[0] * (np.pi**2)) / 4\\n#\\n#     @staticmethod\\n#     def realized_tripower_quarticity(series: pd.Series) -> np.float64:\\n#         \\\"\\\"\\\" Similarly robust estimator to quad power quarticity. \\\"\\\"\\\"\\n#         series = series ** (4/3)\\n#         series = abs(series).rolling(window=3).apply(np.prod, raw=True)\\n#         return series.shape[0]*0.25*((gamma(1/2)**3)/(gamma(7/6)**3))*np.sum(series)\";\n                var nbb_formatted_code = \"# export\\n# @typechecked\\n# class QuarticityFeatures(BaseProcessor):\\n#     \\\"\\\"\\\"\\n#     Quarticity (Vol of vol) features.\\n#     Source and more information: https://dspyt.com/advanced-realized-volatility-and-quarticity/\\n#     \\\"\\\"\\\"\\n#     def __init__(self, ticker_col: str = 'ticker', price_col: str = 'Close'):\\n#         super(QuarticityFeatures, self).__init__()\\n#         self.ticker_col = ticker_col\\n#         self.price_col = price_col\\n#\\n#     @display_processor_info\\n#     def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n#         \\\"\\\"\\\" Get most powerful quarticity features for every stock. \\\"\\\"\\\"\\n#         series = dataset.dataf.loc[:, self.price_col]\\n#         tickers = dataset.dataf.loc[:, self.ticker_col]\\n#         quad_quarticity = series.groupby(tickers).agg(self.realized_quadpower_quarticity)\\n#         tripower_quarticity = series.groupby(tickers).agg(self.realized_tripower_quarticity)\\n#         dataset.dataf.loc[:, \\\"feature_quadpower_quarticity\\\"] = quad_quarticity\\n#         dataset.dataf.loc[:, \\\"feature_tripower_quarticity\\\"] = tripower_quarticity\\n#         return Dataset(**dataset.__dict__)\\n#\\n#     @staticmethod\\n#     def realized_quarticity(series: pd.Series) -> np.float64:\\n#         \\\"\\\"\\\"\\n#         The realized fourth-power variation or realized quarticity\\n#         is a consistent estimator of the integrated quarticity.\\n#         \\\"\\\"\\\"\\n#         return np.sum(series**4) * series.shape[0] / 3\\n#\\n#     @staticmethod\\n#     def realized_quadpower_quarticity(series: pd.Series) -> np.float64:\\n#         \\\"\\\"\\\"\\n#         A more robust estimator compared to realized quarticity,\\n#         particularly in the presence of jumps, is the realized quad-power quarticity.\\n#         \\\"\\\"\\\"\\n#         series = abs(series.rolling(window=4).apply(np.product, raw=True))\\n#         return (np.sum(series) * series.shape[0] * (np.pi**2)) / 4\\n#\\n#     @staticmethod\\n#     def realized_tripower_quarticity(series: pd.Series) -> np.float64:\\n#         \\\"\\\"\\\" Similarly robust estimator to quad power quarticity. \\\"\\\"\\\"\\n#         series = series ** (4/3)\\n#         series = abs(series).rolling(window=3).apply(np.prod, raw=True)\\n#         return series.shape[0]*0.25*((gamma(1/2)**3)/(gamma(7/6)**3))*np.sum(series)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "# @typechecked\n",
    "# class QuarticityFeatures(BaseProcessor):\n",
    "#     \"\"\"\n",
    "#     Quarticity (Vol of vol) features.\n",
    "#     Source and more information: https://dspyt.com/advanced-realized-volatility-and-quarticity/\n",
    "#     \"\"\"\n",
    "#     def __init__(self, ticker_col: str = 'ticker', price_col: str = 'Close'):\n",
    "#         super(QuarticityFeatures, self).__init__()\n",
    "#         self.ticker_col = ticker_col\n",
    "#         self.price_col = price_col\n",
    "#\n",
    "#     @display_processor_info\n",
    "#     def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n",
    "#         \"\"\" Get most powerful quarticity features for every stock. \"\"\"\n",
    "#         series = dataset.dataf.loc[:, self.price_col]\n",
    "#         tickers = dataset.dataf.loc[:, self.ticker_col]\n",
    "#         quad_quarticity = series.groupby(tickers).agg(self.realized_quadpower_quarticity)\n",
    "#         tripower_quarticity = series.groupby(tickers).agg(self.realized_tripower_quarticity)\n",
    "#         dataset.dataf.loc[:, \"feature_quadpower_quarticity\"] = quad_quarticity\n",
    "#         dataset.dataf.loc[:, \"feature_tripower_quarticity\"] = tripower_quarticity\n",
    "#         return Dataset(**dataset.__dict__)\n",
    "#\n",
    "#     @staticmethod\n",
    "#     def realized_quarticity(series: pd.Series) -> np.float64:\n",
    "#         \"\"\"\n",
    "#         The realized fourth-power variation or realized quarticity\n",
    "#         is a consistent estimator of the integrated quarticity.\n",
    "#         \"\"\"\n",
    "#         return np.sum(series**4) * series.shape[0] / 3\n",
    "#\n",
    "#     @staticmethod\n",
    "#     def realized_quadpower_quarticity(series: pd.Series) -> np.float64:\n",
    "#         \"\"\"\n",
    "#         A more robust estimator compared to realized quarticity,\n",
    "#         particularly in the presence of jumps, is the realized quad-power quarticity.\n",
    "#         \"\"\"\n",
    "#         series = abs(series.rolling(window=4).apply(np.product, raw=True))\n",
    "#         return (np.sum(series) * series.shape[0] * (np.pi**2)) / 4\n",
    "#\n",
    "#     @staticmethod\n",
    "#     def realized_tripower_quarticity(series: pd.Series) -> np.float64:\n",
    "#         \"\"\" Similarly robust estimator to quad power quarticity. \"\"\"\n",
    "#         series = series ** (4/3)\n",
    "#         series = abs(series).rolling(window=3).apply(np.prod, raw=True)\n",
    "#         return series.shape[0]*0.25*((gamma(1/2)**3)/(gamma(7/6)**3))*np.sum(series)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 29;\n                var nbb_unformatted_code = \"# signals_test_data = create_dataset(\\\"test_assets/bitcoin_time_series_test_data.csv\\\")\\n# ticker_col = \\\"Symbol\\\"\\n# quart_features = QuarticityFeatures(ticker_col=ticker_col)\\n# dataset_with_quart_features = quart_features.transform(dataset=signals_test_data)\\n# assert dataset_with_quart_features.feature_cols == [\\\"feature_quadpower_quarticity\\\", \\\"feature_tripower_quarticity\\\"]\\n# assert dataset_with_quart_features.dataf[\\\"feature_quadpower_quarticity\\\"].value_counts().nunique() != 1\\n# assert dataset_with_quart_features.dataf[\\\"feature_tripower_quarticity\\\"].value_counts().nunique() != 1\\n# # assert not dataset_with_quart_features.get_feature_data.isna().all().all()\\n# dataset_with_quart_features.get_feature_data.head(2)\";\n                var nbb_formatted_code = \"# signals_test_data = create_dataset(\\\"test_assets/bitcoin_time_series_test_data.csv\\\")\\n# ticker_col = \\\"Symbol\\\"\\n# quart_features = QuarticityFeatures(ticker_col=ticker_col)\\n# dataset_with_quart_features = quart_features.transform(dataset=signals_test_data)\\n# assert dataset_with_quart_features.feature_cols == [\\\"feature_quadpower_quarticity\\\", \\\"feature_tripower_quarticity\\\"]\\n# assert dataset_with_quart_features.dataf[\\\"feature_quadpower_quarticity\\\"].value_counts().nunique() != 1\\n# assert dataset_with_quart_features.dataf[\\\"feature_tripower_quarticity\\\"].value_counts().nunique() != 1\\n# # assert not dataset_with_quart_features.get_feature_data.isna().all().all()\\n# dataset_with_quart_features.get_feature_data.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# signals_test_data = create_dataset(\"test_assets/bitcoin_time_series_test_data.csv\")\n",
    "# ticker_col = \"Symbol\"\n",
    "# quart_features = QuarticityFeatures(ticker_col=ticker_col)\n",
    "# dataset_with_quart_features = quart_features.transform(dataset=signals_test_data)\n",
    "# assert dataset_with_quart_features.feature_cols == [\"feature_quadpower_quarticity\", \"feature_tripower_quarticity\"]\n",
    "# assert dataset_with_quart_features.dataf[\"feature_quadpower_quarticity\"].value_counts().nunique() != 1\n",
    "# assert dataset_with_quart_features.dataf[\"feature_tripower_quarticity\"].value_counts().nunique() != 1\n",
    "# # assert not dataset_with_quart_features.get_feature_data.isna().all().all()\n",
    "# dataset_with_quart_features.get_feature_data.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom preprocessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are an almost unlimited number of ways to preprocess data. We have only scratched the surface with the preprocessors currently implemented in `numerai-blocks`. We invite the Numerai community to develop Numerai Classic and Signals preprocessors for `numerai-blocks`.\n",
    "\n",
    "A new Preprocessor should inherit from `BaseProcessor` and implement a `transform` method. The `transform` method should take a `Dataset` as input and return a `Dataset` object as output. An example is given below.\n",
    "\n",
    "To enable fancy logging output. Add the `@display_processor_info` decorator to the `transform` method.\n",
    "\n",
    "Note that arbitrary metadata can be added or changed in a preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 30;\n                var nbb_unformatted_code = \"# export\\nclass AwesomePreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    - TEMPLATE -\\n    Do some awesome preprocessing.\\n    \\\"\\\"\\\"\\n    def __init__(self, *args, **kwargs):\\n        super(AwesomePreProcessor, self).__init__()\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        # Do processing\\n        ...\\n        # Parse all contents of Dataset to the next pipeline step\\n        return Dataset(**dataset.__dict__)\";\n                var nbb_formatted_code = \"# export\\nclass AwesomePreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    - TEMPLATE -\\n    Do some awesome preprocessing.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, *args, **kwargs):\\n        super(AwesomePreProcessor, self).__init__()\\n\\n    @display_processor_info\\n    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\\n        # Do processing\\n        ...\\n        # Parse all contents of Dataset to the next pipeline step\\n        return Dataset(**dataset.__dict__)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class AwesomePreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    - TEMPLATE -\n",
    "    Do some awesome preprocessing.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AwesomePreProcessor, self).__init__()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataset: Dataset, *args, **kwargs) -> Dataset:\n",
    "        # Do processing\n",
    "        ...\n",
    "        # Parse all contents of Dataset to the next pipeline step\n",
    "        return Dataset(**dataset.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_download.ipynb.\n",
      "Converted 02_dataset.ipynb.\n",
      "Converted 03_preprocessing.ipynb.\n",
      "Converted 04_model.ipynb.\n",
      "Converted 05_postprocessing.ipynb.\n",
      "Converted 06_modelpipeline.ipynb.\n",
      "Converted 07_evaluation.ipynb.\n",
      "Converted 08_key.ipynb.\n",
      "Converted 09_submission.ipynb.\n",
      "Converted 10_staking.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 31;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# Run this cell to sync all changes with library\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 31;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}