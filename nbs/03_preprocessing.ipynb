{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"# hide\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_formatted_code = \"# hide\\n%load_ext autoreload\\n%autoreload 2\\n%load_ext nb_black\\n%load_ext lab_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"# default_exp preprocessing\";\n                var nbb_formatted_code = \"# default_exp preprocessing\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default_exp preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "> Feature/target selection, engineering and manipulation.\n",
    "\n",
    "## Overview\n",
    "This section provides functionality for all data manipulation steps that are needed before data is passed into a model for prediction. We group all these steps under Preprocessing. This includes feature/target selection, feature/target engineering and feature/target manipulation.\n",
    "\n",
    "Some preprocessors work with both Pandas DataFrames and NumerFrames. Most preprocessors use specific `NumerFrame` functionality.\n",
    "\n",
    "In the last section we explain how you can implement your own Preprocessor that integrates well with the rest of this framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_formatted_code = \"# hide\\nfrom nbdev.showdoc import *\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "import sdv\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from functools import wraps\n",
    "from scipy.stats import rankdata\n",
    "from typeguard import typechecked\n",
    "from abc import ABC, abstractmethod\n",
    "from rich import print as rich_print\n",
    "from typing import Union, List, Tuple\n",
    "from multiprocessing.pool import Pool\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "from numerblox.download import NumeraiClassicDownloader\n",
    "from numerblox.numerframe import NumerFrame, create_numerframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These objects will provide a base for all pre- and post-processing functionality and log relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1. BaseProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BaseProcessor` defines common functionality for `preprocessing` and `postprocessing` (Section 5).\n",
    "\n",
    "Every Preprocessor should inherit from `BaseProcessor` and implement the `.transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"# export\\nclass BaseProcessor(ABC):\\n    \\\"\\\"\\\"Common functionality for preprocessors and postprocessors.\\\"\\\"\\\"\\n\\n    def __init__(self):\\n        ...\\n\\n    @abstractmethod\\n    def transform(\\n        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        ...\\n\\n    def __call__(\\n        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        return self.transform(dataf=dataf, *args, **kwargs)\";\n                var nbb_formatted_code = \"# export\\nclass BaseProcessor(ABC):\\n    \\\"\\\"\\\"Common functionality for preprocessors and postprocessors.\\\"\\\"\\\"\\n\\n    def __init__(self):\\n        ...\\n\\n    @abstractmethod\\n    def transform(\\n        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        ...\\n\\n    def __call__(\\n        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\\n    ) -> NumerFrame:\\n        return self.transform(dataf=dataf, *args, **kwargs)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class BaseProcessor(ABC):\n",
    "    \"\"\"Common functionality for preprocessors and postprocessors.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(\n",
    "        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\n",
    "    ) -> NumerFrame:\n",
    "        ...\n",
    "\n",
    "    def __call__(\n",
    "        self, dataf: Union[pd.DataFrame, NumerFrame], *args, **kwargs\n",
    "    ) -> NumerFrame:\n",
    "        return self.transform(dataf=dataf, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2. Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to keep an overview of which steps are done in a data pipeline and where processing bottlenecks occur.\n",
    "The decorator below will display for a given function/method:\n",
    "1. When it has finished.\n",
    "2. What the output shape of the data is.\n",
    "3. How long it took to finish.\n",
    "\n",
    "To use this functionality, simply add `@display_processor_info` as a decorator to the function/method you want to track.\n",
    "\n",
    "We will use this decorator throughout the pipeline (`preprocessing`, `model` and `postprocessing`).\n",
    "\n",
    "Inspiration for this decorator: [Calmcode Pandas Pipe Logs](https://calmcode.io/pandas-pipe/logs.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"# export\\ndef display_processor_info(func):\\n    \\\"\\\"\\\"Fancy console output for data processing.\\\"\\\"\\\"\\n\\n    @wraps(func)\\n    def wrapper(*args, **kwargs):\\n        tic = dt.datetime.now()\\n        result = func(*args, **kwargs)\\n        time_taken = str(dt.datetime.now() - tic)\\n        class_name = func.__qualname__.split(\\\".\\\")[0]\\n        rich_print(\\n            f\\\":white_check_mark: Finished step [bold]{class_name}[/bold]. Output shape={result.shape}. Time taken for step: [blue]{time_taken}[/blue]. :white_check_mark:\\\"\\n        )\\n        return result\\n\\n    return wrapper\";\n                var nbb_formatted_code = \"# export\\ndef display_processor_info(func):\\n    \\\"\\\"\\\"Fancy console output for data processing.\\\"\\\"\\\"\\n\\n    @wraps(func)\\n    def wrapper(*args, **kwargs):\\n        tic = dt.datetime.now()\\n        result = func(*args, **kwargs)\\n        time_taken = str(dt.datetime.now() - tic)\\n        class_name = func.__qualname__.split(\\\".\\\")[0]\\n        rich_print(\\n            f\\\":white_check_mark: Finished step [bold]{class_name}[/bold]. Output shape={result.shape}. Time taken for step: [blue]{time_taken}[/blue]. :white_check_mark:\\\"\\n        )\\n        return result\\n\\n    return wrapper\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "def display_processor_info(func):\n",
    "    \"\"\"Fancy console output for data processing.\"\"\"\n",
    "\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        tic = dt.datetime.now()\n",
    "        result = func(*args, **kwargs)\n",
    "        time_taken = str(dt.datetime.now() - tic)\n",
    "        class_name = func.__qualname__.split(\".\")[0]\n",
    "        rich_print(\n",
    "            f\":white_check_mark: Finished step [bold]{class_name}[/bold]. Output shape={result.shape}. Time taken for step: [blue]{time_taken}[/blue]. :white_check_mark:\"\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mTestDisplay\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m314\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \u001B[1;34m0:00:02\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m002765\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">TestDisplay</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">314</span><span style=\"font-weight: bold\">)</span>. Time taken for step: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:02</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">002765</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                 id   era data_type  feature_intelligence1  \\\n0  n000315175b67977  era1     train                   0.00   \n1  n0014af834a96cdd  era1     train                   0.00   \n2  n001c93979ac41d4  era1     train                   0.25   \n3  n0034e4143f22a13  era1     train                   1.00   \n4  n00679d1a636062f  era1     train                   0.25   \n5  n009aa2d32389eca  era1     train                   0.50   \n6  n009ef1a5fe009b6  era1     train                   0.50   \n7  n00ae5d51f55fb0f  era1     train                   0.25   \n8  n00b0ac86d77aed7  era1     train                   0.50   \n9  n00c63366aeaf76a  era1     train                   0.50   \n\n   feature_intelligence2  feature_intelligence3  feature_intelligence4  \\\n0                   0.50                   0.25                   0.00   \n1                   0.00                   0.00                   0.25   \n2                   0.50                   0.25                   0.25   \n3                   0.00                   0.00                   0.50   \n4                   0.25                   0.25                   0.25   \n5                   0.50                   0.25                   0.25   \n6                   0.25                   0.25                   0.75   \n7                   1.00                   1.00                   0.75   \n8                   0.50                   0.50                   1.00   \n9                   1.00                   1.00                   0.25   \n\n   feature_intelligence5  feature_intelligence6  feature_intelligence7  ...  \\\n0                   0.50                   0.25                   0.25  ...   \n1                   0.50                   0.00                   0.00  ...   \n2                   1.00                   0.75                   0.75  ...   \n3                   0.50                   0.25                   0.25  ...   \n4                   0.00                   0.25                   0.50  ...   \n5                   0.75                   0.75                   0.75  ...   \n6                   1.00                   1.00                   1.00  ...   \n7                   1.00                   0.75                   0.75  ...   \n8                   1.00                   0.25                   0.50  ...   \n9                   0.75                   0.25                   0.25  ...   \n\n   feature_wisdom38  feature_wisdom39  feature_wisdom40  feature_wisdom41  \\\n0              1.00              1.00              0.75              0.50   \n1              1.00              1.00              0.00              0.00   \n2              0.25              0.50              0.00              0.00   \n3              1.00              1.00              0.75              0.75   \n4              0.75              0.75              0.25              0.50   \n5              0.75              0.75              0.00              0.00   \n6              1.00              1.00              0.50              0.50   \n7              0.50              0.25              0.75              0.75   \n8              0.00              0.00              0.00              0.00   \n9              0.00              0.00              1.00              1.00   \n\n   feature_wisdom42  feature_wisdom43  feature_wisdom44  feature_wisdom45  \\\n0              0.75              0.50              1.00              0.50   \n1              0.75              0.25              0.00              0.25   \n2              0.50              1.00              0.00              0.25   \n3              1.00              1.00              0.75              1.00   \n4              0.75              0.00              0.50              0.25   \n5              0.75              0.50              0.00              0.25   \n6              0.75              0.50              0.50              0.50   \n7              0.00              0.25              0.75              0.50   \n8              0.00              1.00              0.00              0.00   \n9              0.75              0.50              1.00              1.00   \n\n   feature_wisdom46  target  \n0              0.75    0.50  \n1              1.00    0.25  \n2              0.75    0.25  \n3              1.00    0.25  \n4              0.75    0.75  \n5              0.00    0.50  \n6              1.00    0.25  \n7              0.25    0.25  \n8              0.00    0.50  \n9              0.75    0.75  \n\n[10 rows x 314 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>era</th>\n      <th>data_type</th>\n      <th>feature_intelligence1</th>\n      <th>feature_intelligence2</th>\n      <th>feature_intelligence3</th>\n      <th>feature_intelligence4</th>\n      <th>feature_intelligence5</th>\n      <th>feature_intelligence6</th>\n      <th>feature_intelligence7</th>\n      <th>...</th>\n      <th>feature_wisdom38</th>\n      <th>feature_wisdom39</th>\n      <th>feature_wisdom40</th>\n      <th>feature_wisdom41</th>\n      <th>feature_wisdom42</th>\n      <th>feature_wisdom43</th>\n      <th>feature_wisdom44</th>\n      <th>feature_wisdom45</th>\n      <th>feature_wisdom46</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>n000315175b67977</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n0014af834a96cdd</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>1.00</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>n001c93979ac41d4</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>...</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>n0034e4143f22a13</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n00679d1a636062f</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>n009aa2d32389eca</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>...</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>n009ef1a5fe009b6</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>n00ae5d51f55fb0f</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.25</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>...</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.00</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.25</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>n00b0ac86d77aed7</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>n00c63366aeaf76a</td>\n      <td>era1</td>\n      <td>train</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.75</td>\n      <td>0.75</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 314 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"# hide_input\\nclass TestDisplay:\\n    \\\"\\\"\\\"\\n    Small test for logging.\\n    Output should mention 'TestDisplay',\\n    Return output shape of (10, 314) and\\n    time taken for step should be close to 2 seconds.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, dataf: NumerFrame):\\n        self.dataf = dataf\\n\\n    @display_processor_info\\n    def test(self) -> NumerFrame:\\n        time.sleep(2)\\n        return self.dataf\\n\\n\\ndataf = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\nTestDisplay(dataf).test()\";\n                var nbb_formatted_code = \"# hide_input\\nclass TestDisplay:\\n    \\\"\\\"\\\"\\n    Small test for logging.\\n    Output should mention 'TestDisplay',\\n    Return output shape of (10, 314) and\\n    time taken for step should be close to 2 seconds.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, dataf: NumerFrame):\\n        self.dataf = dataf\\n\\n    @display_processor_info\\n    def test(self) -> NumerFrame:\\n        time.sleep(2)\\n        return self.dataf\\n\\n\\ndataf = create_numerframe(\\\"test_assets/mini_numerai_version_1_data.csv\\\")\\nTestDisplay(dataf).test()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_input\n",
    "class TestDisplay:\n",
    "    \"\"\"\n",
    "    Small test for logging.\n",
    "    Output should mention 'TestDisplay',\n",
    "    Return output shape of (10, 314) and\n",
    "    time taken for step should be close to 2 seconds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataf: NumerFrame):\n",
    "        self.dataf = dataf\n",
    "\n",
    "    @display_processor_info\n",
    "    def test(self) -> NumerFrame:\n",
    "        time.sleep(2)\n",
    "        return self.dataf\n",
    "\n",
    "\n",
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_1_data.csv\")\n",
    "TestDisplay(dataf).test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Common preprocessing steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section implements commonly used preprocessing for Numerai. We invite the Numerai community to develop new preprocessors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Tournament agnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessors that can be applied for both Numerai Classic and Numerai Signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.1. CopyPreProcessor\n",
    "\n",
    "The first and obvious preprocessor is copying, which is implemented as a default in `ModelPipeline` (Section 4) to avoid manipulation of the original DataFrame or `NumerFrame` that you load in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass CopyPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"Copy DataFrame to avoid manipulation of original DataFrame.\\\"\\\"\\\"\\n\\n    def __init__(self):\\n        super().__init__()\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        return NumerFrame(dataf.copy())\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass CopyPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"Copy DataFrame to avoid manipulation of original DataFrame.\\\"\\\"\\\"\\n\\n    def __init__(self):\\n        super().__init__()\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        return NumerFrame(dataf.copy())\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class CopyPreProcessor(BaseProcessor):\n",
    "    \"\"\"Copy DataFrame to avoid manipulation of original DataFrame.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        return NumerFrame(dataf.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mCopyPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m314\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m002971\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">CopyPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">314</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">002971</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 9;\n                var nbb_unformatted_code = \"dataset = create_numerframe(\\n    \\\"test_assets/mini_numerai_version_1_data.csv\\\", metadata={\\\"version\\\": 1}\\n)\\ncopied_dataset = CopyPreProcessor().transform(dataset)\\nassert np.array_equal(copied_dataset.values, dataset.values)\\nassert dataset.meta == copied_dataset.meta\";\n                var nbb_formatted_code = \"dataset = create_numerframe(\\n    \\\"test_assets/mini_numerai_version_1_data.csv\\\", metadata={\\\"version\\\": 1}\\n)\\ncopied_dataset = CopyPreProcessor().transform(dataset)\\nassert np.array_equal(copied_dataset.values, dataset.values)\\nassert dataset.meta == copied_dataset.meta\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = create_numerframe(\n",
    "    \"test_assets/mini_numerai_version_1_data.csv\", metadata={\"version\": 1}\n",
    ")\n",
    "copied_dataset = CopyPreProcessor().transform(dataset)\n",
    "assert np.array_equal(copied_dataset.values, dataset.values)\n",
    "assert dataset.meta == copied_dataset.meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.2. FeatureSelectionPreProcessor\n",
    "\n",
    "`FeatureSelectionPreProcessor` will keep all features that you pass + keeps all other columns that are not features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 10;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass FeatureSelectionPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Keep only features given + all target, predictions and aux columns.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, feature_cols: Union[str, list]):\\n        super().__init__()\\n        self.feature_cols = feature_cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        keep_cols = (\\n            self.feature_cols\\n            + dataf.target_cols\\n            + dataf.prediction_cols\\n            + dataf.aux_cols\\n        )\\n        dataf = dataf.loc[:, keep_cols]\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass FeatureSelectionPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Keep only features given + all target, predictions and aux columns.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, feature_cols: Union[str, list]):\\n        super().__init__()\\n        self.feature_cols = feature_cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        keep_cols = (\\n            self.feature_cols\\n            + dataf.target_cols\\n            + dataf.prediction_cols\\n            + dataf.aux_cols\\n        )\\n        dataf = dataf.loc[:, keep_cols]\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class FeatureSelectionPreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Keep only features given + all target, predictions and aux columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_cols: Union[str, list]):\n",
    "        super().__init__()\n",
    "        self.feature_cols = feature_cols\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        keep_cols = (\n",
    "            self.feature_cols\n",
    "            + dataf.target_cols\n",
    "            + dataf.prediction_cols\n",
    "            + dataf.aux_cols\n",
    "        )\n",
    "        dataf = dataf.loc[:, keep_cols]\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mFeatureSelectionPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m5\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m001182\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">FeatureSelectionPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">001182</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"selected_dataset = FeatureSelectionPreProcessor(\\n    feature_cols=[\\\"feature_wisdom1\\\"]\\n).transform(dataset)\\n\\nassert selected_dataset.get_feature_data.shape[1] == 1\\nassert dataset.meta == selected_dataset.meta\";\n                var nbb_formatted_code = \"selected_dataset = FeatureSelectionPreProcessor(\\n    feature_cols=[\\\"feature_wisdom1\\\"]\\n).transform(dataset)\\n\\nassert selected_dataset.get_feature_data.shape[1] == 1\\nassert dataset.meta == selected_dataset.meta\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_dataset = FeatureSelectionPreProcessor(\n",
    "    feature_cols=[\"feature_wisdom1\"]\n",
    ").transform(dataset)\n",
    "\n",
    "assert selected_dataset.get_feature_data.shape[1] == 1\n",
    "assert dataset.meta == selected_dataset.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   feature_wisdom1  target                id   era data_type\n0             0.25    0.50  n000315175b67977  era1     train\n1             0.50    0.25  n0014af834a96cdd  era1     train",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_wisdom1</th>\n      <th>target</th>\n      <th>id</th>\n      <th>era</th>\n      <th>data_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>n000315175b67977</td>\n      <td>era1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>n0014af834a96cdd</td>\n      <td>era1</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"selected_dataset.head(2)\";\n                var nbb_formatted_code = \"selected_dataset.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0.3. TargetSelectionPreProcessor\n",
    "\n",
    "`TargetSelectionPreProcessor` will keep all targets that you pass + all other columns that are not targets.\n",
    "\n",
    "Not relevant for an inference pipeline, but especially convenient for Numerai Classic training if you train on a subset of the available targets. Can also be applied to Signals if you are using engineered targets in your pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"# export\\n@typechecked\\nclass TargetSelectionPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Keep only features given + all target, predictions and aux columns.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, target_cols: Union[str, list]):\\n        super().__init__()\\n        self.target_cols = target_cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        keep_cols = (\\n            self.target_cols\\n            + dataf.feature_cols\\n            + dataf.prediction_cols\\n            + dataf.aux_cols\\n        )\\n        dataf = dataf.loc[:, keep_cols]\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\n@typechecked\\nclass TargetSelectionPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Keep only features given + all target, predictions and aux columns.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, target_cols: Union[str, list]):\\n        super().__init__()\\n        self.target_cols = target_cols\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame) -> NumerFrame:\\n        keep_cols = (\\n            self.target_cols\\n            + dataf.feature_cols\\n            + dataf.prediction_cols\\n            + dataf.aux_cols\\n        )\\n        dataf = dataf.loc[:, keep_cols]\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "@typechecked\n",
    "class TargetSelectionPreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Keep only features given + all target, predictions and aux columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, target_cols: Union[str, list]):\n",
    "        super().__init__()\n",
    "        self.target_cols = target_cols\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame) -> NumerFrame:\n",
    "        keep_cols = (\n",
    "            self.target_cols\n",
    "            + dataf.feature_cols\n",
    "            + dataf.prediction_cols\n",
    "            + dataf.aux_cols\n",
    "        )\n",
    "        dataf = dataf.loc[:, keep_cols]\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mTargetSelectionPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m1055\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m024226\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">TargetSelectionPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1055</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">024226</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                  target  target_nomi_20  target_nomi_60  \\\nid                                                         \nn559bd06a8861222    0.25            0.25            0.50   \nn9d39dea58c9e3cf    0.50            0.50            0.75   \n\n                  feature_dichasial_hammier_spawner  \\\nid                                                    \nn559bd06a8861222                               0.25   \nn9d39dea58c9e3cf                               0.75   \n\n                  feature_rheumy_epistemic_prancer  \\\nid                                                   \nn559bd06a8861222                              0.75   \nn9d39dea58c9e3cf                              0.50   \n\n                  feature_pert_performative_hormuz  \\\nid                                                   \nn559bd06a8861222                              0.25   \nn9d39dea58c9e3cf                              0.75   \n\n                  feature_hillier_unpitied_theobromine  \\\nid                                                       \nn559bd06a8861222                                  0.75   \nn9d39dea58c9e3cf                                  1.00   \n\n                  feature_perigean_bewitching_thruster  \\\nid                                                       \nn559bd06a8861222                                  0.25   \nn9d39dea58c9e3cf                                  0.50   \n\n                  feature_renegade_undomestic_milord  \\\nid                                                     \nn559bd06a8861222                                0.50   \nn9d39dea58c9e3cf                                0.25   \n\n                  feature_koranic_rude_corf  ...  \\\nid                                           ...   \nn559bd06a8861222                        1.0  ...   \nn9d39dea58c9e3cf                        0.5  ...   \n\n                  feature_drawable_exhortative_dispersant  \\\nid                                                          \nn559bd06a8861222                                     1.00   \nn9d39dea58c9e3cf                                     0.25   \n\n                  feature_metabolic_minded_armorist  \\\nid                                                    \nn559bd06a8861222                                0.0   \nn9d39dea58c9e3cf                                0.5   \n\n                  feature_investigatory_inerasable_circumvallation  \\\nid                                                                   \nn559bd06a8861222                                               0.0   \nn9d39dea58c9e3cf                                               0.0   \n\n                  feature_centroclinal_incentive_lancelet  \\\nid                                                          \nn559bd06a8861222                                     0.25   \nn9d39dea58c9e3cf                                     0.25   \n\n                  feature_unemotional_quietistic_chirper  \\\nid                                                         \nn559bd06a8861222                                    0.00   \nn9d39dea58c9e3cf                                    0.75   \n\n                  feature_behaviorist_microbiological_farina  \\\nid                                                             \nn559bd06a8861222                                         0.0   \nn9d39dea58c9e3cf                                         1.0   \n\n                  feature_lofty_acceptable_challenge  \\\nid                                                     \nn559bd06a8861222                                1.00   \nn9d39dea58c9e3cf                                0.75   \n\n                  feature_coactive_prefatorial_lucy   era  data_type  \nid                                                                    \nn559bd06a8861222                               0.25  0297      train  \nn9d39dea58c9e3cf                               1.00  0003      train  \n\n[2 rows x 1055 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>target_nomi_20</th>\n      <th>target_nomi_60</th>\n      <th>feature_dichasial_hammier_spawner</th>\n      <th>feature_rheumy_epistemic_prancer</th>\n      <th>feature_pert_performative_hormuz</th>\n      <th>feature_hillier_unpitied_theobromine</th>\n      <th>feature_perigean_bewitching_thruster</th>\n      <th>feature_renegade_undomestic_milord</th>\n      <th>feature_koranic_rude_corf</th>\n      <th>...</th>\n      <th>feature_drawable_exhortative_dispersant</th>\n      <th>feature_metabolic_minded_armorist</th>\n      <th>feature_investigatory_inerasable_circumvallation</th>\n      <th>feature_centroclinal_incentive_lancelet</th>\n      <th>feature_unemotional_quietistic_chirper</th>\n      <th>feature_behaviorist_microbiological_farina</th>\n      <th>feature_lofty_acceptable_challenge</th>\n      <th>feature_coactive_prefatorial_lucy</th>\n      <th>era</th>\n      <th>data_type</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>0.25</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>0.25</td>\n      <td>0297</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>0.50</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>1.0</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0003</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 1055 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"dataset = create_numerframe(\\n    \\\"test_assets/mini_numerai_version_2_data.parquet\\\", metadata={\\\"version\\\": 2}\\n)\\ntarget_cols = [\\\"target\\\", \\\"target_nomi_20\\\", \\\"target_nomi_60\\\"]\\nselected_dataset = TargetSelectionPreProcessor(target_cols=target_cols).transform(\\n    dataset\\n)\\nassert selected_dataset.get_target_data.shape[1] == len(target_cols)\\nselected_dataset.head(2)\";\n                var nbb_formatted_code = \"dataset = create_numerframe(\\n    \\\"test_assets/mini_numerai_version_2_data.parquet\\\", metadata={\\\"version\\\": 2}\\n)\\ntarget_cols = [\\\"target\\\", \\\"target_nomi_20\\\", \\\"target_nomi_60\\\"]\\nselected_dataset = TargetSelectionPreProcessor(target_cols=target_cols).transform(\\n    dataset\\n)\\nassert selected_dataset.get_target_data.shape[1] == len(target_cols)\\nselected_dataset.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = create_numerframe(\n",
    "    \"test_assets/mini_numerai_version_2_data.parquet\", metadata={\"version\": 2}\n",
    ")\n",
    "target_cols = [\"target\", \"target_nomi_20\", \"target_nomi_60\"]\n",
    "selected_dataset = TargetSelectionPreProcessor(target_cols=target_cols).transform(\n",
    "    dataset\n",
    ")\n",
    "assert selected_dataset.get_target_data.shape[1] == len(target_cols)\n",
    "selected_dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.0.4. ReduceMemoryProcessor\n",
    "\n",
    "Numerai datasets can take up a lot of RAM and may put a strain on your compute environment.\n",
    "\n",
    "For Numerai Classic, many of the feature and target columns can be downscaled to `float16`. `int8` if you are using the Numerai int8 datasets. For Signals it depends on the features you are generating.\n",
    "\n",
    "`ReduceMemoryProcessor` downscales the type of your numeric columns to reduce the memory footprint as much as possible."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 15;\n                var nbb_unformatted_code = \"# export\\nclass ReduceMemoryProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Reduce memory usage as much as possible.\\n\\n    Credits to kainsama and others for writing about memory usage reduction for Numerai data:\\n    https://forum.numer.ai/t/reducing-memory/313\\n\\n    :param deep_mem_inspect: Introspect the data deeply by interrogating object dtypes.\\n    Yields a more accurate representation of memory usage if you have complex object columns.\\n    \\\"\\\"\\\"\\n    def __init__(self, deep_mem_inspect = False):\\n        super().__init__()\\n        self.deep_mem_inspect = deep_mem_inspect\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        dataf = self._reduce_mem_usage(dataf)\\n        return NumerFrame(dataf)\\n\\n    def _reduce_mem_usage(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Iterate through all columns and modify the numeric column types\\n        to reduce memory usage.\\n        \\\"\\\"\\\"\\n        start_memory_usage = dataf.memory_usage(deep=self.deep_mem_inspect).sum() / 1024**2\\n        rich_print(f\\\"Memory usage of DataFrame is [bold]{round(start_memory_usage, 2)} MB[/bold]\\\")\\n\\n        for col in dataf.columns:\\n            col_type = dataf[col].dtype.name\\n\\n            if col_type not in ['object', 'category', 'datetime64[ns, UTC]','datetime64[ns]']:\\n                c_min = dataf[col].min()\\n                c_max = dataf[col].max()\\n                if str(col_type)[:3] == 'int':\\n                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\\n                        dataf[col] = dataf[col].astype(np.int16)\\n                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\\n                        dataf[col] = dataf[col].astype(np.int16)\\n                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\\n                        dataf[col] = dataf[col].astype(np.int32)\\n                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\\n                        dataf[col] = dataf[col].astype(np.int64)\\n                else:\\n                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\\n                        dataf[col] = dataf[col].astype(np.float16)\\n                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\\n                        dataf[col] = dataf[col].astype(np.float32)\\n                    else:\\n                        dataf[col] = dataf[col].astype(np.float64)\\n\\n        end_memory_usage = dataf.memory_usage(deep=self.deep_mem_inspect).sum() / 1024**2\\n        rich_print(f\\\"Memory usage after optimization is: [bold]{round(end_memory_usage, 2)} MB[/bold]\\\")\\n        rich_print(f\\\"[green] Usage decreased by [bold]{round(100 * (start_memory_usage - end_memory_usage) / start_memory_usage, 2)}%[/bold][/green]\\\")\\n        return dataf\";\n                var nbb_formatted_code = \"# export\\nclass ReduceMemoryProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Reduce memory usage as much as possible.\\n\\n    Credits to kainsama and others for writing about memory usage reduction for Numerai data:\\n    https://forum.numer.ai/t/reducing-memory/313\\n\\n    :param deep_mem_inspect: Introspect the data deeply by interrogating object dtypes.\\n    Yields a more accurate representation of memory usage if you have complex object columns.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, deep_mem_inspect=False):\\n        super().__init__()\\n        self.deep_mem_inspect = deep_mem_inspect\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        dataf = self._reduce_mem_usage(dataf)\\n        return NumerFrame(dataf)\\n\\n    def _reduce_mem_usage(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"\\n        Iterate through all columns and modify the numeric column types\\n        to reduce memory usage.\\n        \\\"\\\"\\\"\\n        start_memory_usage = (\\n            dataf.memory_usage(deep=self.deep_mem_inspect).sum() / 1024 ** 2\\n        )\\n        rich_print(\\n            f\\\"Memory usage of DataFrame is [bold]{round(start_memory_usage, 2)} MB[/bold]\\\"\\n        )\\n\\n        for col in dataf.columns:\\n            col_type = dataf[col].dtype.name\\n\\n            if col_type not in [\\n                \\\"object\\\",\\n                \\\"category\\\",\\n                \\\"datetime64[ns, UTC]\\\",\\n                \\\"datetime64[ns]\\\",\\n            ]:\\n                c_min = dataf[col].min()\\n                c_max = dataf[col].max()\\n                if str(col_type)[:3] == \\\"int\\\":\\n                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\\n                        dataf[col] = dataf[col].astype(np.int16)\\n                    elif (\\n                        c_min > np.iinfo(np.int16).min\\n                        and c_max < np.iinfo(np.int16).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.int16)\\n                    elif (\\n                        c_min > np.iinfo(np.int32).min\\n                        and c_max < np.iinfo(np.int32).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.int32)\\n                    elif (\\n                        c_min > np.iinfo(np.int64).min\\n                        and c_max < np.iinfo(np.int64).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.int64)\\n                else:\\n                    if (\\n                        c_min > np.finfo(np.float16).min\\n                        and c_max < np.finfo(np.float16).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.float16)\\n                    elif (\\n                        c_min > np.finfo(np.float32).min\\n                        and c_max < np.finfo(np.float32).max\\n                    ):\\n                        dataf[col] = dataf[col].astype(np.float32)\\n                    else:\\n                        dataf[col] = dataf[col].astype(np.float64)\\n\\n        end_memory_usage = (\\n            dataf.memory_usage(deep=self.deep_mem_inspect).sum() / 1024 ** 2\\n        )\\n        rich_print(\\n            f\\\"Memory usage after optimization is: [bold]{round(end_memory_usage, 2)} MB[/bold]\\\"\\n        )\\n        rich_print(\\n            f\\\"[green] Usage decreased by [bold]{round(100 * (start_memory_usage - end_memory_usage) / start_memory_usage, 2)}%[/bold][/green]\\\"\\n        )\\n        return dataf\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class ReduceMemoryProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Reduce memory usage as much as possible.\n",
    "\n",
    "    Credits to kainsama and others for writing about memory usage reduction for Numerai data:\n",
    "    https://forum.numer.ai/t/reducing-memory/313\n",
    "\n",
    "    :param deep_mem_inspect: Introspect the data deeply by interrogating object dtypes.\n",
    "    Yields a more accurate representation of memory usage if you have complex object columns.\n",
    "    \"\"\"\n",
    "    def __init__(self, deep_mem_inspect = False):\n",
    "        super().__init__()\n",
    "        self.deep_mem_inspect = deep_mem_inspect\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        dataf = self._reduce_mem_usage(dataf)\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def _reduce_mem_usage(self, dataf: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Iterate through all columns and modify the numeric column types\n",
    "        to reduce memory usage.\n",
    "        \"\"\"\n",
    "        start_memory_usage = dataf.memory_usage(deep=self.deep_mem_inspect).sum() / 1024**2\n",
    "        rich_print(f\"Memory usage of DataFrame is [bold]{round(start_memory_usage, 2)} MB[/bold]\")\n",
    "\n",
    "        for col in dataf.columns:\n",
    "            col_type = dataf[col].dtype.name\n",
    "\n",
    "            if col_type not in ['object', 'category', 'datetime64[ns, UTC]','datetime64[ns]']:\n",
    "                c_min = dataf[col].min()\n",
    "                c_max = dataf[col].max()\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        dataf[col] = dataf[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        dataf[col] = dataf[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        dataf[col] = dataf[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        dataf[col] = dataf[col].astype(np.int64)\n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        dataf[col] = dataf[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        dataf[col] = dataf[col].astype(np.float32)\n",
    "                    else:\n",
    "                        dataf[col] = dataf[col].astype(np.float64)\n",
    "\n",
    "        end_memory_usage = dataf.memory_usage(deep=self.deep_mem_inspect).sum() / 1024**2\n",
    "        rich_print(f\"Memory usage after optimization is: [bold]{round(end_memory_usage, 2)} MB[/bold]\")\n",
    "        rich_print(f\"[green] Usage decreased by [bold]{round(100 * (start_memory_usage - end_memory_usage) / start_memory_usage, 2)}%[/bold][/green]\")\n",
    "        return dataf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Memory usage of DataFrame is \u001B[1;36m0.04\u001B[0m\u001B[1m MB\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory usage of DataFrame is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.04</span><span style=\"font-weight: bold\"> MB</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Memory usage after optimization is: \u001B[1;36m0.02\u001B[0m\u001B[1m MB\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Memory usage after optimization is: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02</span><span style=\"font-weight: bold\"> MB</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[32m Usage decreased by \u001B[0m\u001B[1;32m49.72\u001B[0m\u001B[1;32m%\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\"> Usage decreased by </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">49.72</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">%</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mReduceMemoryProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m1073\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:01\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m085155\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">ReduceMemoryProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1073</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:01</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">085155</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 16;\n                var nbb_unformatted_code = \"dataf = create_numerframe(\\\"test_assets/mini_numerai_version_2_data.parquet\\\")\\nrmp = ReduceMemoryProcessor()\\ndataf = rmp.transform(dataf)\";\n                var nbb_formatted_code = \"dataf = create_numerframe(\\\"test_assets/mini_numerai_version_2_data.parquet\\\")\\nrmp = ReduceMemoryProcessor()\\ndataf = rmp.transform(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataf = create_numerframe(\"test_assets/mini_numerai_version_2_data.parquet\")\n",
    "rmp = ReduceMemoryProcessor()\n",
    "dataf = rmp.transform(dataf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                   era data_type  feature_dichasial_hammier_spawner  \\\nid                                                                    \nn559bd06a8861222  0297     train                               0.25   \nn9d39dea58c9e3cf  0003     train                               0.75   \n\n                  feature_rheumy_epistemic_prancer  \\\nid                                                   \nn559bd06a8861222                              0.75   \nn9d39dea58c9e3cf                              0.50   \n\n                  feature_pert_performative_hormuz  \\\nid                                                   \nn559bd06a8861222                              0.25   \nn9d39dea58c9e3cf                              0.75   \n\n                  feature_hillier_unpitied_theobromine  \\\nid                                                       \nn559bd06a8861222                                  0.75   \nn9d39dea58c9e3cf                                  1.00   \n\n                  feature_perigean_bewitching_thruster  \\\nid                                                       \nn559bd06a8861222                                  0.25   \nn9d39dea58c9e3cf                                  0.50   \n\n                  feature_renegade_undomestic_milord  \\\nid                                                     \nn559bd06a8861222                                0.50   \nn9d39dea58c9e3cf                                0.25   \n\n                  feature_koranic_rude_corf  \\\nid                                            \nn559bd06a8861222                        1.0   \nn9d39dea58c9e3cf                        0.5   \n\n                  feature_demisable_expiring_millepede  ...  target_paul_20  \\\nid                                                      ...                   \nn559bd06a8861222                                  0.25  ...             0.0   \nn9d39dea58c9e3cf                                  0.00  ...             0.5   \n\n                  target_paul_60  target_george_20  target_george_60  \\\nid                                                                     \nn559bd06a8861222            0.50              0.25               0.5   \nn9d39dea58c9e3cf            0.75              0.50               0.5   \n\n                  target_william_20  target_william_60  target_arthur_20  \\\nid                                                                         \nn559bd06a8861222           0.000000           0.500000          0.166626   \nn9d39dea58c9e3cf           0.666504           0.666504          0.500000   \n\n                  target_arthur_60  target_thomas_20  target_thomas_60  \nid                                                                      \nn559bd06a8861222          0.500000          0.333252          0.500000  \nn9d39dea58c9e3cf          0.666504          0.500000          0.666504  \n\n[2 rows x 1073 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>era</th>\n      <th>data_type</th>\n      <th>feature_dichasial_hammier_spawner</th>\n      <th>feature_rheumy_epistemic_prancer</th>\n      <th>feature_pert_performative_hormuz</th>\n      <th>feature_hillier_unpitied_theobromine</th>\n      <th>feature_perigean_bewitching_thruster</th>\n      <th>feature_renegade_undomestic_milord</th>\n      <th>feature_koranic_rude_corf</th>\n      <th>feature_demisable_expiring_millepede</th>\n      <th>...</th>\n      <th>target_paul_20</th>\n      <th>target_paul_60</th>\n      <th>target_george_20</th>\n      <th>target_george_60</th>\n      <th>target_william_20</th>\n      <th>target_william_60</th>\n      <th>target_arthur_20</th>\n      <th>target_arthur_60</th>\n      <th>target_thomas_20</th>\n      <th>target_thomas_60</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n559bd06a8861222</th>\n      <td>0297</td>\n      <td>train</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.75</td>\n      <td>0.25</td>\n      <td>0.50</td>\n      <td>1.0</td>\n      <td>0.25</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.166626</td>\n      <td>0.500000</td>\n      <td>0.333252</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>n9d39dea58c9e3cf</th>\n      <td>0003</td>\n      <td>train</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.75</td>\n      <td>1.00</td>\n      <td>0.50</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.75</td>\n      <td>0.50</td>\n      <td>0.5</td>\n      <td>0.666504</td>\n      <td>0.666504</td>\n      <td>0.500000</td>\n      <td>0.666504</td>\n      <td>0.500000</td>\n      <td>0.666504</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 1073 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 17;\n                var nbb_unformatted_code = \"#hide\\ndataf.head(2)\";\n                var nbb_formatted_code = \"# hide\\ndataf.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "dataf.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.0.5. SyntheticDataGenerator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# export\n",
    "class SyntheticDataGenerator(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Generate synthetic eras of data.\n",
    "    Uses SDV (sdv.dev) under the hood.\n",
    "\n",
    "    :param model_name: Exact class name of a model supported on sdv.\n",
    "    :param model_path: Path to trained model if you have so.\n",
    "    By default, initializes and fits a new model.\n",
    "    \"\"\"\n",
    "    SUPPORTED_MODELS = [\"GaussianCopula\", \"CTGAN\", \"CopulaGAN\"]\n",
    "    def __init__(self,\n",
    "                 model_path: str,\n",
    "                 model_name = \"GaussianCopula\",\n",
    "                 eras_to_add: int = 1):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        assert self.model_name in self.SUPPORTED_MODELS,\\\n",
    "            f\"Only models '{self.SUPPORTED_MODELS}' are supported. Got '{self.model_name}'.\"\n",
    "        self.model_path = Path(model_path)\n",
    "        self.eras_to_add = eras_to_add\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        model = self.prepare_model(dataf=dataf)\n",
    "        synth_datafs = []\n",
    "        for era_n in range(self.eras_to_add):\n",
    "            synth_era_data = self.get_synthetic_batch(model=model)\n",
    "            synth_era_data[dataf.meta.era_col] = f\"synth_{era_n.zfill(4)}\"\n",
    "            synth_datafs.append(synth_era_data)\n",
    "\n",
    "        synth_dataf = pd.concat(synth_datafs)\n",
    "\n",
    "\n",
    "        # Parse all contents of NumerFrame to the next pipeline step\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def prepare_model(self, dataf: Union[pd.DataFrame, NumerFrame]) -> Union[SUPPORTED_MODELS]:\n",
    "        if self.model_path.is_file():\n",
    "            model = getattr(sdv.tabular, self.model_name).load(self.model_path)\n",
    "        else:\n",
    "            rich_print(f\":warning: Model path '{self.model_path}' does not point to a file. Initializing, fitting and saving new model. :warning:\")\n",
    "            model = getattr(sdv.tabular, self.model_name)()\n",
    "            model.fit(dataf=dataf)\n",
    "            model.save(self.model_path)\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def get_synthetic_batch(model: Union[SUPPORTED_MODELS],\n",
    "                            num_rows: int = 200) -> pd.DataFrame:\n",
    "        synthetic_dataf = model.sample(num_rows=num_rows)\n",
    "        return synthetic_dataf\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Numerai Classic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Numerai Classic dataset has a certain structure that you may not encounter in the Numerai Signals tournament.\n",
    "Therefore, this section has all preprocessors that can only be applied to Numerai Classic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.0 Numerai Classic: Version agnostic\n",
    "\n",
    "Preprocessors that work for all Numerai Classic versions."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1.0.1. BayesianGMMTargetProcessor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 18;\n                var nbb_unformatted_code = \"# export\\nclass BayesianGMMTargetProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Generate synthetic (fake) target using a Bayesian Gaussian Mixture model. \\\\n\\n    Based on Michael Oliver's GitHub Gist implementation: \\\\n\\n    https://gist.github.com/the-moliver/dcdd2862dc2c78dda600f1b449071c93\\n\\n    :param target_col: Column from which to create fake target. \\\\n\\n    :param n_components: Number of components for fitting Bayesian Gaussian Mixture Model.\\n    \\\"\\\"\\\"\\n    def __init__(self, target_col: str = \\\"target\\\", n_components: int = 6):\\n        super().__init__()\\n        self.target_col = target_col\\n        self.n_components = n_components\\n        self.ridge = Ridge(fit_intercept=False)\\n        self.bins = [0, 0.05, 0.25, 0.75, 0.95, 1]\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        all_eras = dataf[dataf.meta.era_col].unique()\\n        coefs = self._get_coefs(dataf=dataf, all_eras=all_eras)\\n        bgmm = self._fit_bgmm(coefs=coefs)\\n        fake_target = self._generate_target(dataf=dataf,\\n                                            bgmm=bgmm,\\n                                            all_eras=all_eras)\\n        dataf[f\\\"fake_{self.target_col}\\\"] = fake_target\\n        return NumerFrame(dataf)\\n\\n    def _get_coefs(self, dataf: NumerFrame, all_eras: list) -> np.ndarray:\\n        \\\"\\\"\\\"\\n        Generate coefficients for BGMM.\\n        Data should already be scaled between 0 and 1\\n        (Already done with Numerai Classic data)\\n        \\\"\\\"\\\"\\n        coefs = []\\n        for era in all_eras:\\n            features, target = self.__get_features_target(dataf=dataf, era=era)\\n            self.ridge.fit(features, target)\\n            coefs.append(self.ridge.coef_)\\n        stacked_coefs = np.vstack(coefs)\\n        return stacked_coefs\\n\\n    def _fit_bgmm(self, coefs: np.ndarray) -> BayesianGaussianMixture:\\n        \\\"\\\"\\\"\\n        Fit Bayesian Gaussian Mixture model on coefficients and normalize.\\n        \\\"\\\"\\\"\\n        bggm = BayesianGaussianMixture(n_components=self.n_components)\\n        bggm.fit(coefs)\\n        # make probability of sampling each component equal to better balance rare regimes\\n        bggm.weights_[:] = 1 / self.n_components\\n        return bggm\\n\\n    def _generate_target(self, dataf: NumerFrame,\\n                         bgmm: BayesianGaussianMixture,\\n                         all_eras: list) -> np.ndarray:\\n        \\\"\\\"\\\" Generate fake target using Bayesian Gaussian Mixture model. \\\"\\\"\\\"\\n        fake_target = []\\n        for era in tqdm(all_eras, desc=\\\"Generating fake target\\\"):\\n            features, _ = self.__get_features_target(dataf=dataf, era=era)\\n            # Sample a set of weights from GMM\\n            beta, _ = bgmm.sample(1)\\n            # Create fake continuous target\\n            fake_targ = features @ beta[0]\\n            # Bin fake target like real target\\n            fake_targ = (rankdata(fake_targ) - .5) / len(fake_targ)\\n            fake_targ = (np.digitize(fake_targ, self.bins) - 1) / 4\\n            fake_target.append(fake_targ)\\n        return np.concatenate(fake_target)\\n\\n    def __get_features_target(self, dataf: NumerFrame, era) -> tuple:\\n        \\\"\\\"\\\" Get features and target for one era and center data. \\\"\\\"\\\"\\n        sub_df = dataf[dataf.era == era]\\n        features = sub_df.get_feature_data\\n        target = sub_df[self.target_col]\\n        features = features.values - .5\\n        target = target.values - .5\\n        return features, target\";\n                var nbb_formatted_code = \"# export\\nclass BayesianGMMTargetProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Generate synthetic (fake) target using a Bayesian Gaussian Mixture model. \\\\n\\n    Based on Michael Oliver's GitHub Gist implementation: \\\\n\\n    https://gist.github.com/the-moliver/dcdd2862dc2c78dda600f1b449071c93\\n\\n    :param target_col: Column from which to create fake target. \\\\n\\n    :param n_components: Number of components for fitting Bayesian Gaussian Mixture Model.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, target_col: str = \\\"target\\\", n_components: int = 6):\\n        super().__init__()\\n        self.target_col = target_col\\n        self.n_components = n_components\\n        self.ridge = Ridge(fit_intercept=False)\\n        self.bins = [0, 0.05, 0.25, 0.75, 0.95, 1]\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        all_eras = dataf[dataf.meta.era_col].unique()\\n        coefs = self._get_coefs(dataf=dataf, all_eras=all_eras)\\n        bgmm = self._fit_bgmm(coefs=coefs)\\n        fake_target = self._generate_target(dataf=dataf, bgmm=bgmm, all_eras=all_eras)\\n        dataf[f\\\"fake_{self.target_col}\\\"] = fake_target\\n        return NumerFrame(dataf)\\n\\n    def _get_coefs(self, dataf: NumerFrame, all_eras: list) -> np.ndarray:\\n        \\\"\\\"\\\"\\n        Generate coefficients for BGMM.\\n        Data should already be scaled between 0 and 1\\n        (Already done with Numerai Classic data)\\n        \\\"\\\"\\\"\\n        coefs = []\\n        for era in all_eras:\\n            features, target = self.__get_features_target(dataf=dataf, era=era)\\n            self.ridge.fit(features, target)\\n            coefs.append(self.ridge.coef_)\\n        stacked_coefs = np.vstack(coefs)\\n        return stacked_coefs\\n\\n    def _fit_bgmm(self, coefs: np.ndarray) -> BayesianGaussianMixture:\\n        \\\"\\\"\\\"\\n        Fit Bayesian Gaussian Mixture model on coefficients and normalize.\\n        \\\"\\\"\\\"\\n        bggm = BayesianGaussianMixture(n_components=self.n_components)\\n        bggm.fit(coefs)\\n        # make probability of sampling each component equal to better balance rare regimes\\n        bggm.weights_[:] = 1 / self.n_components\\n        return bggm\\n\\n    def _generate_target(\\n        self, dataf: NumerFrame, bgmm: BayesianGaussianMixture, all_eras: list\\n    ) -> np.ndarray:\\n        \\\"\\\"\\\"Generate fake target using Bayesian Gaussian Mixture model.\\\"\\\"\\\"\\n        fake_target = []\\n        for era in tqdm(all_eras, desc=\\\"Generating fake target\\\"):\\n            features, _ = self.__get_features_target(dataf=dataf, era=era)\\n            # Sample a set of weights from GMM\\n            beta, _ = bgmm.sample(1)\\n            # Create fake continuous target\\n            fake_targ = features @ beta[0]\\n            # Bin fake target like real target\\n            fake_targ = (rankdata(fake_targ) - 0.5) / len(fake_targ)\\n            fake_targ = (np.digitize(fake_targ, self.bins) - 1) / 4\\n            fake_target.append(fake_targ)\\n        return np.concatenate(fake_target)\\n\\n    def __get_features_target(self, dataf: NumerFrame, era) -> tuple:\\n        \\\"\\\"\\\"Get features and target for one era and center data.\\\"\\\"\\\"\\n        sub_df = dataf[dataf.era == era]\\n        features = sub_df.get_feature_data\\n        target = sub_df[self.target_col]\\n        features = features.values - 0.5\\n        target = target.values - 0.5\\n        return features, target\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class BayesianGMMTargetProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Generate synthetic (fake) target using a Bayesian Gaussian Mixture model. \\n\n",
    "    Based on Michael Oliver's GitHub Gist implementation: \\n\n",
    "    https://gist.github.com/the-moliver/dcdd2862dc2c78dda600f1b449071c93\n",
    "\n",
    "    :param target_col: Column from which to create fake target. \\n\n",
    "    :param n_components: Number of components for fitting Bayesian Gaussian Mixture Model.\n",
    "    \"\"\"\n",
    "    def __init__(self, target_col: str = \"target\", n_components: int = 6):\n",
    "        super().__init__()\n",
    "        self.target_col = target_col\n",
    "        self.n_components = n_components\n",
    "        self.ridge = Ridge(fit_intercept=False)\n",
    "        self.bins = [0, 0.05, 0.25, 0.75, 0.95, 1]\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        all_eras = dataf[dataf.meta.era_col].unique()\n",
    "        coefs = self._get_coefs(dataf=dataf, all_eras=all_eras)\n",
    "        bgmm = self._fit_bgmm(coefs=coefs)\n",
    "        fake_target = self._generate_target(dataf=dataf,\n",
    "                                            bgmm=bgmm,\n",
    "                                            all_eras=all_eras)\n",
    "        dataf[f\"fake_{self.target_col}\"] = fake_target\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def _get_coefs(self, dataf: NumerFrame, all_eras: list) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate coefficients for BGMM.\n",
    "        Data should already be scaled between 0 and 1\n",
    "        (Already done with Numerai Classic data)\n",
    "        \"\"\"\n",
    "        coefs = []\n",
    "        for era in all_eras:\n",
    "            features, target = self.__get_features_target(dataf=dataf, era=era)\n",
    "            self.ridge.fit(features, target)\n",
    "            coefs.append(self.ridge.coef_)\n",
    "        stacked_coefs = np.vstack(coefs)\n",
    "        return stacked_coefs\n",
    "\n",
    "    def _fit_bgmm(self, coefs: np.ndarray) -> BayesianGaussianMixture:\n",
    "        \"\"\"\n",
    "        Fit Bayesian Gaussian Mixture model on coefficients and normalize.\n",
    "        \"\"\"\n",
    "        bggm = BayesianGaussianMixture(n_components=self.n_components)\n",
    "        bggm.fit(coefs)\n",
    "        # make probability of sampling each component equal to better balance rare regimes\n",
    "        bggm.weights_[:] = 1 / self.n_components\n",
    "        return bggm\n",
    "\n",
    "    def _generate_target(self, dataf: NumerFrame,\n",
    "                         bgmm: BayesianGaussianMixture,\n",
    "                         all_eras: list) -> np.ndarray:\n",
    "        \"\"\" Generate fake target using Bayesian Gaussian Mixture model. \"\"\"\n",
    "        fake_target = []\n",
    "        for era in tqdm(all_eras, desc=\"Generating fake target\"):\n",
    "            features, _ = self.__get_features_target(dataf=dataf, era=era)\n",
    "            # Sample a set of weights from GMM\n",
    "            beta, _ = bgmm.sample(1)\n",
    "            # Create fake continuous target\n",
    "            fake_targ = features @ beta[0]\n",
    "            # Bin fake target like real target\n",
    "            fake_targ = (rankdata(fake_targ) - .5) / len(fake_targ)\n",
    "            fake_targ = (np.digitize(fake_targ, self.bins) - 1) / 4\n",
    "            fake_target.append(fake_targ)\n",
    "        return np.concatenate(fake_target)\n",
    "\n",
    "    def __get_features_target(self, dataf: NumerFrame, era) -> tuple:\n",
    "        \"\"\" Get features and target for one era and center data. \"\"\"\n",
    "        sub_df = dataf[dataf.era == era]\n",
    "        features = sub_df.get_feature_data\n",
    "        target = sub_df[self.target_col]\n",
    "        features = features.values - .5\n",
    "        target = target.values - .5\n",
    "        return features, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "No existing directory found at \u001B[32m'\u001B[0m\u001B[34mbgmm_test\u001B[0m\u001B[32m'\u001B[0m. Creating directory\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">bgmm_test</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "📁 \u001B[32mDownloading\u001B[0m \u001B[32m'numerai_validation_data.parquet'\u001B[0m 📁\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">📁 <span style=\"color: #008000; text-decoration-color: #008000\">Downloading</span> <span style=\"color: #008000; text-decoration-color: #008000\">'numerai_validation_data.parquet'</span> 📁\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 21:28:27,368 INFO numerapi.utils: starting download\n",
      "bgmm_test/numerai_validation_data.parquet: 228MB [01:36, 2.35MB/s]                            \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 19;\n                var nbb_unformatted_code = \"# hide\\ndirectory = \\\"bgmm_test/\\\"\\ndownloader = NumeraiClassicDownloader(directory_path=directory)\\ndownloader.download_single_dataset(filename=\\\"numerai_validation_data.parquet\\\",\\n                                   dest_path=directory + \\\"numerai_validation_data.parquet\\\")\\nval_dataf = create_numerframe(\\\"bgmm_test/numerai_validation_data.parquet\\\")\";\n                var nbb_formatted_code = \"# hide\\ndirectory = \\\"bgmm_test/\\\"\\ndownloader = NumeraiClassicDownloader(directory_path=directory)\\ndownloader.download_single_dataset(\\n    filename=\\\"numerai_validation_data.parquet\\\",\\n    dest_path=directory + \\\"numerai_validation_data.parquet\\\",\\n)\\nval_dataf = create_numerframe(\\\"bgmm_test/numerai_validation_data.parquet\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "directory = \"bgmm_test/\"\n",
    "downloader = NumeraiClassicDownloader(directory_path=directory)\n",
    "downloader.download_single_dataset(filename=\"numerai_validation_data.parquet\",\n",
    "                                   dest_path=directory + \"numerai_validation_data.parquet\")\n",
    "val_dataf = create_numerframe(\"bgmm_test/numerai_validation_data.parquet\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Generating fake target:   0%|          | 0/105 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2b3d7f0f0b84e579deb32b8223a59ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mBayesianGMMTargetProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m539658\u001B[0m, \u001B[1;36m1074\u001B[0m\u001B[1m)\u001B[0m. Time taken for \nstep: \u001B[1;34m0:02:28\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m736787\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">BayesianGMMTargetProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">539658</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1074</span><span style=\"font-weight: bold\">)</span>. Time taken for \nstep: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:02:28</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">736787</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "                  target  fake_target\nid                                   \nn000777698096000    0.25         0.50\nn0009793a3b91c27    0.50         0.75\nn00099ccd6698ab0    0.00         0.25",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>fake_target</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n000777698096000</th>\n      <td>0.25</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>n0009793a3b91c27</th>\n      <td>0.50</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>n00099ccd6698ab0</th>\n      <td>0.00</td>\n      <td>0.25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 20;\n                var nbb_unformatted_code = \"bgmm = BayesianGMMTargetProcessor()\\nval_dataf = bgmm(val_dataf)\\nval_dataf[['target', 'fake_target']].head(3)\";\n                var nbb_formatted_code = \"bgmm = BayesianGMMTargetProcessor()\\nval_dataf = bgmm(val_dataf)\\nval_dataf[[\\\"target\\\", \\\"fake_target\\\"]].head(3)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bgmm = BayesianGMMTargetProcessor()\n",
    "val_dataf = bgmm(val_dataf)\n",
    "val_dataf[['target', 'fake_target']].head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "⚠ \u001B[31mDeleting directory for \u001B[0m\u001B[31m'NumeraiClassicDownloader\u001B[0m\u001B[32m'\u001B[0m ⚠\nPath: \u001B[32m'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/bgmm_test'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">⚠ <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'NumeraiClassicDownloader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> ⚠\nPath: <span style=\"color: #008000; text-decoration-color: #008000\">'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/bgmm_test'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 21;\n                var nbb_unformatted_code = \"# hide\\ndownloader.remove_base_directory()\";\n                var nbb_formatted_code = \"# hide\\ndownloader.remove_base_directory()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "downloader.remove_base_directory()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Numerai Classic: Version 1 specific\n",
    "\n",
    "Preprocessors that only work for version 1 (legacy data).\n",
    "When using version 1 preprocessor it is recommended that the input `NumerFrame` has `version` in its metadata.\n",
    "This avoids using version 1 preprocessors on version 2 data and encountering confusing error messages.\n",
    "\n",
    "As a new user we recommend to start modeling the version 2 data and avoid version 1.\n",
    "The preprocessors below are only there for legacy and compatibility reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1.1. GroupStatsPreProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The version 1 legacy data has 6 groups of features which allows us to calculate aggregate features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 22;\n                var nbb_unformatted_code = \"# export\\nclass GroupStatsPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    WARNING: Only supported for Version 1 (legacy) data. \\\\n\\n    Calculate group statistics for all data groups. \\\\n\\n    | :param groups: Groups to create features for. All groups by default.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, groups: list = None):\\n        super().__init__()\\n        self.all_groups = [\\n            \\\"intelligence\\\",\\n            \\\"wisdom\\\",\\n            \\\"charisma\\\",\\n            \\\"dexterity\\\",\\n            \\\"strength\\\",\\n            \\\"constitution\\\",\\n        ]\\n        self.group_names = groups if groups else self.all_groups\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        \\\"\\\"\\\"Check validity and add group features.\\\"\\\"\\\"\\n        self._check_data_validity(dataf=dataf)\\n        dataf = dataf.pipe(self._add_group_features)\\n        return NumerFrame(dataf)\\n\\n    def _add_group_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"Mean, standard deviation and skew for each group.\\\"\\\"\\\"\\n        for group in self.group_names:\\n            cols = [col for col in dataf.columns if group in col]\\n            dataf[f\\\"feature_{group}_mean\\\"] = dataf[cols].mean(axis=1)\\n            dataf[f\\\"feature_{group}_std\\\"] = dataf[cols].std(axis=1)\\n            dataf[f\\\"feature_{group}_skew\\\"] = dataf[cols].skew(axis=1)\\n        return dataf\\n\\n    def _check_data_validity(self, dataf: NumerFrame):\\n        \\\"\\\"\\\"Make sure this is only used for version 1 data.\\\"\\\"\\\"\\n        assert hasattr(\\n            dataf.meta, \\\"version\\\"\\n        ), f\\\"Version should be specified for '{self.__class__.__name__}' This Preprocessor will only work on version 1 data.\\\"\\n        assert (\\n            getattr(dataf.meta, \\\"version\\\") == 1\\n        ), f\\\"'{self.__class__.__name__}' only works on version 1 data. Got version: '{getattr(dataf.meta, 'version')}'.\\\"\";\n                var nbb_formatted_code = \"# export\\nclass GroupStatsPreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    WARNING: Only supported for Version 1 (legacy) data. \\\\n\\n    Calculate group statistics for all data groups. \\\\n\\n    | :param groups: Groups to create features for. All groups by default.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, groups: list = None):\\n        super().__init__()\\n        self.all_groups = [\\n            \\\"intelligence\\\",\\n            \\\"wisdom\\\",\\n            \\\"charisma\\\",\\n            \\\"dexterity\\\",\\n            \\\"strength\\\",\\n            \\\"constitution\\\",\\n        ]\\n        self.group_names = groups if groups else self.all_groups\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        \\\"\\\"\\\"Check validity and add group features.\\\"\\\"\\\"\\n        self._check_data_validity(dataf=dataf)\\n        dataf = dataf.pipe(self._add_group_features)\\n        return NumerFrame(dataf)\\n\\n    def _add_group_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"Mean, standard deviation and skew for each group.\\\"\\\"\\\"\\n        for group in self.group_names:\\n            cols = [col for col in dataf.columns if group in col]\\n            dataf[f\\\"feature_{group}_mean\\\"] = dataf[cols].mean(axis=1)\\n            dataf[f\\\"feature_{group}_std\\\"] = dataf[cols].std(axis=1)\\n            dataf[f\\\"feature_{group}_skew\\\"] = dataf[cols].skew(axis=1)\\n        return dataf\\n\\n    def _check_data_validity(self, dataf: NumerFrame):\\n        \\\"\\\"\\\"Make sure this is only used for version 1 data.\\\"\\\"\\\"\\n        assert hasattr(\\n            dataf.meta, \\\"version\\\"\\n        ), f\\\"Version should be specified for '{self.__class__.__name__}' This Preprocessor will only work on version 1 data.\\\"\\n        assert (\\n            getattr(dataf.meta, \\\"version\\\") == 1\\n        ), f\\\"'{self.__class__.__name__}' only works on version 1 data. Got version: '{getattr(dataf.meta, 'version')}'.\\\"\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class GroupStatsPreProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    WARNING: Only supported for Version 1 (legacy) data. \\n\n",
    "    Calculate group statistics for all data groups. \\n\n",
    "    | :param groups: Groups to create features for. All groups by default.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, groups: list = None):\n",
    "        super().__init__()\n",
    "        self.all_groups = [\n",
    "            \"intelligence\",\n",
    "            \"wisdom\",\n",
    "            \"charisma\",\n",
    "            \"dexterity\",\n",
    "            \"strength\",\n",
    "            \"constitution\",\n",
    "        ]\n",
    "        self.group_names = groups if groups else self.all_groups\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        \"\"\"Check validity and add group features.\"\"\"\n",
    "        self._check_data_validity(dataf=dataf)\n",
    "        dataf = dataf.pipe(self._add_group_features)\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def _add_group_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Mean, standard deviation and skew for each group.\"\"\"\n",
    "        for group in self.group_names:\n",
    "            cols = [col for col in dataf.columns if group in col]\n",
    "            dataf[f\"feature_{group}_mean\"] = dataf[cols].mean(axis=1)\n",
    "            dataf[f\"feature_{group}_std\"] = dataf[cols].std(axis=1)\n",
    "            dataf[f\"feature_{group}_skew\"] = dataf[cols].skew(axis=1)\n",
    "        return dataf\n",
    "\n",
    "    def _check_data_validity(self, dataf: NumerFrame):\n",
    "        \"\"\"Make sure this is only used for version 1 data.\"\"\"\n",
    "        assert hasattr(\n",
    "            dataf.meta, \"version\"\n",
    "        ), f\"Version should be specified for '{self.__class__.__name__}' This Preprocessor will only work on version 1 data.\"\n",
    "        assert (\n",
    "            getattr(dataf.meta, \"version\") == 1\n",
    "        ), f\"'{self.__class__.__name__}' only works on version 1 data. Got version: '{getattr(dataf.meta, 'version')}'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mGroupStatsPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m332\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m061970\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">GroupStatsPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">332</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">061970</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 23;\n                var nbb_unformatted_code = \"dataf = create_numerframe(\\n    \\\"test_assets/mini_numerai_version_1_data.csv\\\", metadata={\\\"version\\\": 1}\\n)\\ngroup_features_dataf = GroupStatsPreProcessor().transform(dataf)\\ngroup_features_dataf.head(2)\\nassert group_features_dataf.meta.version == 1\";\n                var nbb_formatted_code = \"dataf = create_numerframe(\\n    \\\"test_assets/mini_numerai_version_1_data.csv\\\", metadata={\\\"version\\\": 1}\\n)\\ngroup_features_dataf = GroupStatsPreProcessor().transform(dataf)\\ngroup_features_dataf.head(2)\\nassert group_features_dataf.meta.version == 1\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataf = create_numerframe(\n",
    "    \"test_assets/mini_numerai_version_1_data.csv\", metadata={\"version\": 1}\n",
    ")\n",
    "group_features_dataf = GroupStatsPreProcessor().transform(dataf)\n",
    "group_features_dataf.head(2)\n",
    "assert group_features_dataf.meta.version == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   feature_intelligence_mean  feature_intelligence_std  \\\n0                   0.333333                  0.246183   \n1                   0.208333                  0.234359   \n\n   feature_intelligence_skew  feature_wisdom_mean  feature_wisdom_std  \\\n0                   0.558528             0.668478            0.236022   \n1                   0.382554             0.559783            0.358177   \n\n   feature_wisdom_skew  feature_charisma_mean  feature_charisma_std  \\\n0            -0.115082               0.438953              0.259910   \n1            -0.062362               0.485465              0.252501   \n\n   feature_charisma_skew  feature_dexterity_mean  feature_dexterity_std  \\\n0              -0.004783                0.696429               0.200446   \n1              -0.021737                0.267857               0.249312   \n\n   feature_dexterity_skew  feature_strength_mean  feature_strength_std  \\\n0               -0.607620               0.480263              0.292829   \n1                0.382267               0.407895              0.309866   \n\n   feature_strength_skew  feature_constitution_mean  feature_constitution_std  \\\n0              -0.372064                   0.427632                   0.27572   \n1               0.220625                   0.644737                   0.33408   \n\n   feature_constitution_skew  \n0                   0.276155  \n1                  -0.794938  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_intelligence_mean</th>\n      <th>feature_intelligence_std</th>\n      <th>feature_intelligence_skew</th>\n      <th>feature_wisdom_mean</th>\n      <th>feature_wisdom_std</th>\n      <th>feature_wisdom_skew</th>\n      <th>feature_charisma_mean</th>\n      <th>feature_charisma_std</th>\n      <th>feature_charisma_skew</th>\n      <th>feature_dexterity_mean</th>\n      <th>feature_dexterity_std</th>\n      <th>feature_dexterity_skew</th>\n      <th>feature_strength_mean</th>\n      <th>feature_strength_std</th>\n      <th>feature_strength_skew</th>\n      <th>feature_constitution_mean</th>\n      <th>feature_constitution_std</th>\n      <th>feature_constitution_skew</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.333333</td>\n      <td>0.246183</td>\n      <td>0.558528</td>\n      <td>0.668478</td>\n      <td>0.236022</td>\n      <td>-0.115082</td>\n      <td>0.438953</td>\n      <td>0.259910</td>\n      <td>-0.004783</td>\n      <td>0.696429</td>\n      <td>0.200446</td>\n      <td>-0.607620</td>\n      <td>0.480263</td>\n      <td>0.292829</td>\n      <td>-0.372064</td>\n      <td>0.427632</td>\n      <td>0.27572</td>\n      <td>0.276155</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.208333</td>\n      <td>0.234359</td>\n      <td>0.382554</td>\n      <td>0.559783</td>\n      <td>0.358177</td>\n      <td>-0.062362</td>\n      <td>0.485465</td>\n      <td>0.252501</td>\n      <td>-0.021737</td>\n      <td>0.267857</td>\n      <td>0.249312</td>\n      <td>0.382267</td>\n      <td>0.407895</td>\n      <td>0.309866</td>\n      <td>0.220625</td>\n      <td>0.644737</td>\n      <td>0.33408</td>\n      <td>-0.794938</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 24;\n                var nbb_unformatted_code = \"# hide\\nnew_cols = [\\n    \\\"feature_intelligence_mean\\\",\\n    \\\"feature_intelligence_std\\\",\\n    \\\"feature_intelligence_skew\\\",\\n    \\\"feature_wisdom_mean\\\",\\n    \\\"feature_wisdom_std\\\",\\n    \\\"feature_wisdom_skew\\\",\\n    \\\"feature_charisma_mean\\\",\\n    \\\"feature_charisma_std\\\",\\n    \\\"feature_charisma_skew\\\",\\n    \\\"feature_dexterity_mean\\\",\\n    \\\"feature_dexterity_std\\\",\\n    \\\"feature_dexterity_skew\\\",\\n    \\\"feature_strength_mean\\\",\\n    \\\"feature_strength_std\\\",\\n    \\\"feature_strength_skew\\\",\\n    \\\"feature_constitution_mean\\\",\\n    \\\"feature_constitution_std\\\",\\n    \\\"feature_constitution_skew\\\",\\n]\\nassert set(group_features_dataf.columns).intersection(new_cols)\\ngroup_features_dataf.get_feature_data[new_cols].head(2)\";\n                var nbb_formatted_code = \"# hide\\nnew_cols = [\\n    \\\"feature_intelligence_mean\\\",\\n    \\\"feature_intelligence_std\\\",\\n    \\\"feature_intelligence_skew\\\",\\n    \\\"feature_wisdom_mean\\\",\\n    \\\"feature_wisdom_std\\\",\\n    \\\"feature_wisdom_skew\\\",\\n    \\\"feature_charisma_mean\\\",\\n    \\\"feature_charisma_std\\\",\\n    \\\"feature_charisma_skew\\\",\\n    \\\"feature_dexterity_mean\\\",\\n    \\\"feature_dexterity_std\\\",\\n    \\\"feature_dexterity_skew\\\",\\n    \\\"feature_strength_mean\\\",\\n    \\\"feature_strength_std\\\",\\n    \\\"feature_strength_skew\\\",\\n    \\\"feature_constitution_mean\\\",\\n    \\\"feature_constitution_std\\\",\\n    \\\"feature_constitution_skew\\\",\\n]\\nassert set(group_features_dataf.columns).intersection(new_cols)\\ngroup_features_dataf.get_feature_data[new_cols].head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "new_cols = [\n",
    "    \"feature_intelligence_mean\",\n",
    "    \"feature_intelligence_std\",\n",
    "    \"feature_intelligence_skew\",\n",
    "    \"feature_wisdom_mean\",\n",
    "    \"feature_wisdom_std\",\n",
    "    \"feature_wisdom_skew\",\n",
    "    \"feature_charisma_mean\",\n",
    "    \"feature_charisma_std\",\n",
    "    \"feature_charisma_skew\",\n",
    "    \"feature_dexterity_mean\",\n",
    "    \"feature_dexterity_std\",\n",
    "    \"feature_dexterity_skew\",\n",
    "    \"feature_strength_mean\",\n",
    "    \"feature_strength_std\",\n",
    "    \"feature_strength_skew\",\n",
    "    \"feature_constitution_mean\",\n",
    "    \"feature_constitution_std\",\n",
    "    \"feature_constitution_skew\",\n",
    "]\n",
    "assert set(group_features_dataf.columns).intersection(new_cols)\n",
    "group_features_dataf.get_feature_data[new_cols].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GroupStatsPreProcessor` should break if `version != 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mGroupStatsPreProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m10\u001B[0m, \u001B[1;36m332\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:00\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m031489\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">GroupStatsPreProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">332</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:00</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">031489</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 25;\n                var nbb_unformatted_code = \"# hide\\ndef test_invalid_version(dataf: NumerFrame):\\n    copied_dataf = dataf.copy()\\n    copied_dataf.version = 2\\n    try:\\n        GroupStatsPreProcessor().transform(copied_dataf)\\n    except AssertionError:\\n        return True\\n    return False\\n\\n\\ntest_invalid_version(dataf)\";\n                var nbb_formatted_code = \"# hide\\ndef test_invalid_version(dataf: NumerFrame):\\n    copied_dataf = dataf.copy()\\n    copied_dataf.version = 2\\n    try:\\n        GroupStatsPreProcessor().transform(copied_dataf)\\n    except AssertionError:\\n        return True\\n    return False\\n\\n\\ntest_invalid_version(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "def test_invalid_version(dataf: NumerFrame):\n",
    "    copied_dataf = dataf.copy()\n",
    "    copied_dataf.version = 2\n",
    "    try:\n",
    "        GroupStatsPreProcessor().transform(copied_dataf)\n",
    "    except AssertionError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "test_invalid_version(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Numerai Classic: Version 2 specific\n",
    "\n",
    "Preprocessors that are only compatible with version 2 data. If the preprocessor is agnostic to Numerai Classic version implement under heading 1.1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 26;\n                var nbb_unformatted_code = \"# 1.1.2\\n# No version 2 specific Numerai Classic preprocessors implemented yet.\";\n                var nbb_formatted_code = \"# 1.1.2\\n# No version 2 specific Numerai Classic preprocessors implemented yet.\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.1.2\n",
    "# No version 2 specific Numerai Classic preprocessors implemented yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Numerai Signals\n",
    "\n",
    "Preprocessors that are specific to Numerai Signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. TA-Lib Features (TalibFeatureGenerator)\n",
    "\n",
    "[TA-Lib](https://mrjbq7.github.io/ta-lib) is an optimized technical analysis library. It is based on Cython and includes 150+ indicators. We have selected features based on feature importances, SHAP and correlation with the Numerai Signals target. If you want to implement other features check out the [TA-Lib documentation](https://mrjbq7.github.io/ta-lib/index.html).\n",
    "\n",
    "Installation of TA-Lib is a bit more involved than just a pip install and is an optional dependency for this library. Visit the [installation documentation](https://mrjbq7.github.io/ta-lib/install.html) for instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 27;\n                var nbb_unformatted_code = \"# export\\nclass TalibFeatureGenerator(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Generate relevant features available in TA-Lib. \\\\n\\n    More info: https://mrjbq7.github.io/ta-lib \\\\n\\n    Input DataFrames for these functions should have the following columns defined:\\n    ['open', 'high', 'low', 'close', 'volume'] \\\\n\\n    Make sure that all values are sorted in chronological order (by ticker). \\\\n\\n    :param windows: List of ranges for window features.\\n    Windows will be applied for all features specified in self.window_features. \\\\n\\n    :param ticker_col: Which column to groupby for feature generation.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, windows: List[int], ticker_col: str = \\\"bloomberg_ticker\\\"):\\n        self.__check_talib_import()\\n        super().__init__()\\n\\n        self.windows = windows\\n        self.ticker_col = ticker_col\\n        self.window_features = [\\n            \\\"NATR\\\",\\n            \\\"ADXR\\\",\\n            \\\"AROONOSC\\\",\\n            \\\"DX\\\",\\n            \\\"MFI\\\",\\n            \\\"MINUS_DI\\\",\\n            \\\"MINUS_DM\\\",\\n            \\\"MOM\\\",\\n            \\\"ROCP\\\",\\n            \\\"ROCR100\\\",\\n            \\\"PLUS_DI\\\",\\n            \\\"PLUS_DM\\\",\\n            \\\"BETA\\\",\\n            \\\"RSI\\\",\\n            \\\"ULTOSC\\\",\\n            \\\"TRIX\\\",\\n            \\\"ADXR\\\",\\n            \\\"CCI\\\",\\n            \\\"CMO\\\",\\n            \\\"WILLR\\\",\\n        ]\\n        self.no_window_features = [\\\"AD\\\", \\\"OBV\\\", \\\"APO\\\", \\\"MACD\\\", \\\"PPO\\\"]\\n        self.hlocv_cols = [\\\"open\\\", \\\"high\\\", \\\"low\\\", \\\"close\\\", \\\"volume\\\"]\\n\\n    def get_no_window_features(self, dataf: pd.DataFrame):\\n        for func in tqdm(self.no_window_features, desc=\\\"No window features\\\"):\\n            dataf.loc[:, f\\\"feature_{func}\\\"] = (\\n                dataf.groupby(self.ticker_col)\\n                .apply(lambda x: pd.Series(self._no_window(x, func)).bfill())\\n                .values.astype(np.float32)\\n            )\\n        return dataf\\n\\n    def get_window_features(self, dataf: pd.DataFrame):\\n        for win in tqdm(self.windows, position=0, desc=\\\"Window features\\\"):\\n            for func in tqdm(self.window_features, position=1):\\n                dataf.loc[:, f\\\"feature_{func}_{win}\\\"] = (\\n                    dataf.groupby(self.ticker_col)\\n                    .apply(lambda x: pd.Series(self._window(x, func, win)).bfill())\\n                    .values.astype(np.float32)\\n                )\\n        return dataf\\n\\n    def get_all_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        dataf = self.get_no_window_features(dataf)\\n        dataf = self.get_window_features(dataf)\\n        return dataf\\n\\n    def transform(self, dataf: pd.DataFrame, *args, **kwargs) -> NumerFrame:\\n        return NumerFrame(self.get_all_features(dataf=dataf))\\n\\n    def _no_window(self, dataf: pd.DataFrame, func) -> pd.Series:\\n        from talib import abstract as tab\\n\\n        inputs = self.__get_inputs(dataf)\\n        if func in [\\\"MACD\\\"]:\\n            # MACD outputs tuple of 3 elements (value, signal and hist)\\n            return tab.Function(func)(inputs[\\\"close\\\"])[0]\\n        else:\\n            return tab.Function(func)(inputs)\\n\\n    def _window(self, dataf: pd.DataFrame, func, window: int) -> pd.Series:\\n        from talib import abstract as tab\\n\\n        inputs = self.__get_inputs(dataf)\\n        if func in [\\\"ULTOSC\\\"]:\\n            # ULTOSC requires 3 timeperiods as input\\n            return tab.Function(func)(\\n                inputs[\\\"high\\\"],\\n                inputs[\\\"low\\\"],\\n                inputs[\\\"close\\\"],\\n                timeperiod1=window,\\n                timeperiod2=window * 2,\\n                timeperiod3=window * 4,\\n            )\\n        else:\\n            return tab.Function(func)(inputs, timeperiod=window)\\n\\n    def __get_inputs(self, dataf: pd.DataFrame) -> dict:\\n        return {col: dataf[col].values.astype(np.float64) for col in self.hlocv_cols}\\n\\n    @staticmethod\\n    def __check_talib_import():\\n        try:\\n            from talib import abstract as tab\\n        except ImportError:\\n            raise ImportError(\\n                \\\"TA-Lib is not installed for this environment. If you are using this class make sure to have TA-Lib installed. check https://mrjbq7.github.io/ta-lib/install.html for instructions on installation.\\\"\\n            )\";\n                var nbb_formatted_code = \"# export\\nclass TalibFeatureGenerator(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Generate relevant features available in TA-Lib. \\\\n\\n    More info: https://mrjbq7.github.io/ta-lib \\\\n\\n    Input DataFrames for these functions should have the following columns defined:\\n    ['open', 'high', 'low', 'close', 'volume'] \\\\n\\n    Make sure that all values are sorted in chronological order (by ticker). \\\\n\\n    :param windows: List of ranges for window features.\\n    Windows will be applied for all features specified in self.window_features. \\\\n\\n    :param ticker_col: Which column to groupby for feature generation.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, windows: List[int], ticker_col: str = \\\"bloomberg_ticker\\\"):\\n        self.__check_talib_import()\\n        super().__init__()\\n\\n        self.windows = windows\\n        self.ticker_col = ticker_col\\n        self.window_features = [\\n            \\\"NATR\\\",\\n            \\\"ADXR\\\",\\n            \\\"AROONOSC\\\",\\n            \\\"DX\\\",\\n            \\\"MFI\\\",\\n            \\\"MINUS_DI\\\",\\n            \\\"MINUS_DM\\\",\\n            \\\"MOM\\\",\\n            \\\"ROCP\\\",\\n            \\\"ROCR100\\\",\\n            \\\"PLUS_DI\\\",\\n            \\\"PLUS_DM\\\",\\n            \\\"BETA\\\",\\n            \\\"RSI\\\",\\n            \\\"ULTOSC\\\",\\n            \\\"TRIX\\\",\\n            \\\"ADXR\\\",\\n            \\\"CCI\\\",\\n            \\\"CMO\\\",\\n            \\\"WILLR\\\",\\n        ]\\n        self.no_window_features = [\\\"AD\\\", \\\"OBV\\\", \\\"APO\\\", \\\"MACD\\\", \\\"PPO\\\"]\\n        self.hlocv_cols = [\\\"open\\\", \\\"high\\\", \\\"low\\\", \\\"close\\\", \\\"volume\\\"]\\n\\n    def get_no_window_features(self, dataf: pd.DataFrame):\\n        for func in tqdm(self.no_window_features, desc=\\\"No window features\\\"):\\n            dataf.loc[:, f\\\"feature_{func}\\\"] = (\\n                dataf.groupby(self.ticker_col)\\n                .apply(lambda x: pd.Series(self._no_window(x, func)).bfill())\\n                .values.astype(np.float32)\\n            )\\n        return dataf\\n\\n    def get_window_features(self, dataf: pd.DataFrame):\\n        for win in tqdm(self.windows, position=0, desc=\\\"Window features\\\"):\\n            for func in tqdm(self.window_features, position=1):\\n                dataf.loc[:, f\\\"feature_{func}_{win}\\\"] = (\\n                    dataf.groupby(self.ticker_col)\\n                    .apply(lambda x: pd.Series(self._window(x, func, win)).bfill())\\n                    .values.astype(np.float32)\\n                )\\n        return dataf\\n\\n    def get_all_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        dataf = self.get_no_window_features(dataf)\\n        dataf = self.get_window_features(dataf)\\n        return dataf\\n\\n    def transform(self, dataf: pd.DataFrame, *args, **kwargs) -> NumerFrame:\\n        return NumerFrame(self.get_all_features(dataf=dataf))\\n\\n    def _no_window(self, dataf: pd.DataFrame, func) -> pd.Series:\\n        from talib import abstract as tab\\n\\n        inputs = self.__get_inputs(dataf)\\n        if func in [\\\"MACD\\\"]:\\n            # MACD outputs tuple of 3 elements (value, signal and hist)\\n            return tab.Function(func)(inputs[\\\"close\\\"])[0]\\n        else:\\n            return tab.Function(func)(inputs)\\n\\n    def _window(self, dataf: pd.DataFrame, func, window: int) -> pd.Series:\\n        from talib import abstract as tab\\n\\n        inputs = self.__get_inputs(dataf)\\n        if func in [\\\"ULTOSC\\\"]:\\n            # ULTOSC requires 3 timeperiods as input\\n            return tab.Function(func)(\\n                inputs[\\\"high\\\"],\\n                inputs[\\\"low\\\"],\\n                inputs[\\\"close\\\"],\\n                timeperiod1=window,\\n                timeperiod2=window * 2,\\n                timeperiod3=window * 4,\\n            )\\n        else:\\n            return tab.Function(func)(inputs, timeperiod=window)\\n\\n    def __get_inputs(self, dataf: pd.DataFrame) -> dict:\\n        return {col: dataf[col].values.astype(np.float64) for col in self.hlocv_cols}\\n\\n    @staticmethod\\n    def __check_talib_import():\\n        try:\\n            from talib import abstract as tab\\n        except ImportError:\\n            raise ImportError(\\n                \\\"TA-Lib is not installed for this environment. If you are using this class make sure to have TA-Lib installed. check https://mrjbq7.github.io/ta-lib/install.html for instructions on installation.\\\"\\n            )\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class TalibFeatureGenerator(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Generate relevant features available in TA-Lib. \\n\n",
    "    More info: https://mrjbq7.github.io/ta-lib \\n\n",
    "    Input DataFrames for these functions should have the following columns defined:\n",
    "    ['open', 'high', 'low', 'close', 'volume'] \\n\n",
    "    Make sure that all values are sorted in chronological order (by ticker). \\n\n",
    "    :param windows: List of ranges for window features.\n",
    "    Windows will be applied for all features specified in self.window_features. \\n\n",
    "    :param ticker_col: Which column to groupby for feature generation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, windows: List[int], ticker_col: str = \"bloomberg_ticker\"):\n",
    "        self.__check_talib_import()\n",
    "        super().__init__()\n",
    "\n",
    "        self.windows = windows\n",
    "        self.ticker_col = ticker_col\n",
    "        self.window_features = [\n",
    "            \"NATR\",\n",
    "            \"ADXR\",\n",
    "            \"AROONOSC\",\n",
    "            \"DX\",\n",
    "            \"MFI\",\n",
    "            \"MINUS_DI\",\n",
    "            \"MINUS_DM\",\n",
    "            \"MOM\",\n",
    "            \"ROCP\",\n",
    "            \"ROCR100\",\n",
    "            \"PLUS_DI\",\n",
    "            \"PLUS_DM\",\n",
    "            \"BETA\",\n",
    "            \"RSI\",\n",
    "            \"ULTOSC\",\n",
    "            \"TRIX\",\n",
    "            \"ADXR\",\n",
    "            \"CCI\",\n",
    "            \"CMO\",\n",
    "            \"WILLR\",\n",
    "        ]\n",
    "        self.no_window_features = [\"AD\", \"OBV\", \"APO\", \"MACD\", \"PPO\"]\n",
    "        self.hlocv_cols = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "\n",
    "    def get_no_window_features(self, dataf: pd.DataFrame):\n",
    "        for func in tqdm(self.no_window_features, desc=\"No window features\"):\n",
    "            dataf.loc[:, f\"feature_{func}\"] = (\n",
    "                dataf.groupby(self.ticker_col)\n",
    "                .apply(lambda x: pd.Series(self._no_window(x, func)).bfill())\n",
    "                .values.astype(np.float32)\n",
    "            )\n",
    "        return dataf\n",
    "\n",
    "    def get_window_features(self, dataf: pd.DataFrame):\n",
    "        for win in tqdm(self.windows, position=0, desc=\"Window features\"):\n",
    "            for func in tqdm(self.window_features, position=1):\n",
    "                dataf.loc[:, f\"feature_{func}_{win}\"] = (\n",
    "                    dataf.groupby(self.ticker_col)\n",
    "                    .apply(lambda x: pd.Series(self._window(x, func, win)).bfill())\n",
    "                    .values.astype(np.float32)\n",
    "                )\n",
    "        return dataf\n",
    "\n",
    "    def get_all_features(self, dataf: pd.DataFrame) -> pd.DataFrame:\n",
    "        dataf = self.get_no_window_features(dataf)\n",
    "        dataf = self.get_window_features(dataf)\n",
    "        return dataf\n",
    "\n",
    "    def transform(self, dataf: pd.DataFrame, *args, **kwargs) -> NumerFrame:\n",
    "        return NumerFrame(self.get_all_features(dataf=dataf))\n",
    "\n",
    "    def _no_window(self, dataf: pd.DataFrame, func) -> pd.Series:\n",
    "        from talib import abstract as tab\n",
    "\n",
    "        inputs = self.__get_inputs(dataf)\n",
    "        if func in [\"MACD\"]:\n",
    "            # MACD outputs tuple of 3 elements (value, signal and hist)\n",
    "            return tab.Function(func)(inputs[\"close\"])[0]\n",
    "        else:\n",
    "            return tab.Function(func)(inputs)\n",
    "\n",
    "    def _window(self, dataf: pd.DataFrame, func, window: int) -> pd.Series:\n",
    "        from talib import abstract as tab\n",
    "\n",
    "        inputs = self.__get_inputs(dataf)\n",
    "        if func in [\"ULTOSC\"]:\n",
    "            # ULTOSC requires 3 timeperiods as input\n",
    "            return tab.Function(func)(\n",
    "                inputs[\"high\"],\n",
    "                inputs[\"low\"],\n",
    "                inputs[\"close\"],\n",
    "                timeperiod1=window,\n",
    "                timeperiod2=window * 2,\n",
    "                timeperiod3=window * 4,\n",
    "            )\n",
    "        else:\n",
    "            return tab.Function(func)(inputs, timeperiod=window)\n",
    "\n",
    "    def __get_inputs(self, dataf: pd.DataFrame) -> dict:\n",
    "        return {col: dataf[col].values.astype(np.float64) for col in self.hlocv_cols}\n",
    "\n",
    "    @staticmethod\n",
    "    def __check_talib_import():\n",
    "        try:\n",
    "            from talib import abstract as tab\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"TA-Lib is not installed for this environment. If you are using this class make sure to have TA-Lib installed. check https://mrjbq7.github.io/ta-lib/install.html for instructions on installation.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 28;\n                var nbb_unformatted_code = \"# hide\\n# Example usage\\n# dataf = pd.DataFrame() # Your Signals DataFrame here.\\n# tfg = TalibFeatureGenerator(windows=[10, 20, 40], ticker_col=\\\"bloomberg_ticker\\\")\\n# ta_dataf = tfg.transform(dataf=dataf)\\n# ta_dataf.head(2)\";\n                var nbb_formatted_code = \"# hide\\n# Example usage\\n# dataf = pd.DataFrame() # Your Signals DataFrame here.\\n# tfg = TalibFeatureGenerator(windows=[10, 20, 40], ticker_col=\\\"bloomberg_ticker\\\")\\n# ta_dataf = tfg.transform(dataf=dataf)\\n# ta_dataf.head(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# Example usage\n",
    "# dataf = pd.DataFrame() # Your Signals DataFrame here.\n",
    "# tfg = TalibFeatureGenerator(windows=[10, 20, 40], ticker_col=\"bloomberg_ticker\")\n",
    "# ta_dataf = tfg.transform(dataf=dataf)\n",
    "# ta_dataf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. KatsuFeatureGenerator\n",
    "\n",
    "[Katsu1110](https://www.kaggle.com/code1110) provides an excellent and fast feature engineering scheme in his [Kaggle notebook on starting with Numerai Signals](https://www.kaggle.com/code1110/numeraisignals-starter-for-beginners). It is surprisingly effective, fast and works well for modeling. This preprocessor is based on his feature engineering setup in that notebook.\n",
    "\n",
    "Features generated:\n",
    "1. MACD and MACD signal\n",
    "2. RSI\n",
    "3. Percentage rate of return\n",
    "4. Volatility\n",
    "5. MA (moving average) gap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 29;\n                var nbb_unformatted_code = \"# export\\nclass KatsuFeatureGenerator(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Effective feature engineering setup based on Katsu's starter notebook.\\n    Based on source by Katsu1110: https://www.kaggle.com/code1110/numeraisignals-starter-for-beginners\\n\\n    :param windows: Time interval to apply for window features: \\\\n\\n    1. Percentage Rate of change \\\\n\\n    2. Volatility \\\\n\\n    3. Moving Average gap \\\\n\\n    :param ticker_col: Columns with tickers to iterate over. \\\\n\\n    :param close_col: Column name where you have closing price stored.\\n    \\\"\\\"\\\"\\n\\n    warnings.filterwarnings(\\\"ignore\\\")\\n\\n    def __init__(\\n        self,\\n        windows: list,\\n        ticker_col: str = \\\"ticker\\\",\\n        close_col: str = \\\"close\\\",\\n        num_cores: int = None,\\n    ):\\n        super().__init__()\\n        self.windows = windows\\n        self.ticker_col = ticker_col\\n        self.close_col = close_col\\n        self.num_cores = num_cores if num_cores else os.cpu_count()\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        \\\"\\\"\\\"Multiprocessing feature engineering.\\\"\\\"\\\"\\n        tickers = dataf.loc[:, self.ticker_col].unique().tolist()\\n        rich_print(\\n            f\\\"Feature engineering for {len(tickers)} tickers using {self.num_cores} CPU cores.\\\"\\n        )\\n        dataf_list = [\\n            x\\n            for _, x in tqdm(\\n                dataf.groupby(self.ticker_col), desc=\\\"Generating ticker DataFrames\\\"\\n            )\\n        ]\\n        dataf = self._generate_features(dataf_list=dataf_list)\\n        return NumerFrame(dataf)\\n\\n    def feature_engineering(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"Feature engineering for single ticker.\\\"\\\"\\\"\\n        close_series = dataf.loc[:, self.close_col]\\n        for x in self.windows:\\n            dataf.loc[\\n                :, f\\\"feature_{self.close_col}_ROCP_{x}\\\"\\n            ] = close_series.pct_change(x)\\n\\n            dataf.loc[:, f\\\"feature_{self.close_col}_VOL_{x}\\\"] = (\\n                np.log1p(close_series).pct_change().rolling(x).std()\\n            )\\n\\n            dataf.loc[:, f\\\"feature_{self.close_col}_MA_gap_{x}\\\"] = (\\n                close_series / close_series.rolling(x).mean()\\n            )\\n\\n        dataf.loc[:, \\\"feature_RSI\\\"] = self._rsi(close_series)\\n        macd, macd_signal = self._macd(close_series)\\n        dataf.loc[:, \\\"feature_MACD\\\"] = macd\\n        dataf.loc[:, \\\"feature_MACD_signal\\\"] = macd_signal\\n        return dataf.bfill()\\n\\n    def _generate_features(self, dataf_list: list) -> pd.DataFrame:\\n        \\\"\\\"\\\"Add features for list of ticker DataFrames and concatenate.\\\"\\\"\\\"\\n        with Pool(self.num_cores) as p:\\n            feature_datafs = list(\\n                tqdm(\\n                    p.imap(self.feature_engineering, dataf_list),\\n                    desc=\\\"Generating features\\\",\\n                    total=len(dataf_list),\\n                )\\n            )\\n        return pd.concat(feature_datafs)\\n\\n    @staticmethod\\n    def _rsi(close: pd.Series, period: int = 14) -> pd.Series:\\n        \\\"\\\"\\\"\\n        See source https://github.com/peerchemist/finta\\n        and fix https://www.tradingview.com/wiki/Talk:Relative_Strength_Index_(RSI)\\n        \\\"\\\"\\\"\\n        delta = close.diff()\\n        up, down = delta.copy(), delta.copy()\\n        up[up < 0] = 0\\n        down[down > 0] = 0\\n\\n        gain = up.ewm(com=(period - 1), min_periods=period).mean()\\n        loss = down.abs().ewm(com=(period - 1), min_periods=period).mean()\\n\\n        rs = gain / loss\\n        return pd.Series(100 - (100 / (1 + rs)))\\n\\n    def _macd(\\n        self, close: pd.Series, span1=12, span2=26, span3=9\\n    ) -> Tuple[pd.Series, pd.Series]:\\n        \\\"\\\"\\\"Compute MACD and MACD signal.\\\"\\\"\\\"\\n        exp1 = self.__ema1(close, span1)\\n        exp2 = self.__ema1(close, span2)\\n        macd = 100 * (exp1 - exp2) / exp2\\n        signal = self.__ema1(macd, span3)\\n        return macd, signal\\n\\n    @staticmethod\\n    def __ema1(series: pd.Series, span: int) -> pd.Series:\\n        \\\"\\\"\\\"Exponential moving average\\\"\\\"\\\"\\n        a = 2 / (span + 1)\\n        return series.ewm(alpha=a).mean()\";\n                var nbb_formatted_code = \"# export\\nclass KatsuFeatureGenerator(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Effective feature engineering setup based on Katsu's starter notebook.\\n    Based on source by Katsu1110: https://www.kaggle.com/code1110/numeraisignals-starter-for-beginners\\n\\n    :param windows: Time interval to apply for window features: \\\\n\\n    1. Percentage Rate of change \\\\n\\n    2. Volatility \\\\n\\n    3. Moving Average gap \\\\n\\n    :param ticker_col: Columns with tickers to iterate over. \\\\n\\n    :param close_col: Column name where you have closing price stored.\\n    \\\"\\\"\\\"\\n\\n    warnings.filterwarnings(\\\"ignore\\\")\\n\\n    def __init__(\\n        self,\\n        windows: list,\\n        ticker_col: str = \\\"ticker\\\",\\n        close_col: str = \\\"close\\\",\\n        num_cores: int = None,\\n    ):\\n        super().__init__()\\n        self.windows = windows\\n        self.ticker_col = ticker_col\\n        self.close_col = close_col\\n        self.num_cores = num_cores if num_cores else os.cpu_count()\\n\\n    @display_processor_info\\n    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\\n        \\\"\\\"\\\"Multiprocessing feature engineering.\\\"\\\"\\\"\\n        tickers = dataf.loc[:, self.ticker_col].unique().tolist()\\n        rich_print(\\n            f\\\"Feature engineering for {len(tickers)} tickers using {self.num_cores} CPU cores.\\\"\\n        )\\n        dataf_list = [\\n            x\\n            for _, x in tqdm(\\n                dataf.groupby(self.ticker_col), desc=\\\"Generating ticker DataFrames\\\"\\n            )\\n        ]\\n        dataf = self._generate_features(dataf_list=dataf_list)\\n        return NumerFrame(dataf)\\n\\n    def feature_engineering(self, dataf: pd.DataFrame) -> pd.DataFrame:\\n        \\\"\\\"\\\"Feature engineering for single ticker.\\\"\\\"\\\"\\n        close_series = dataf.loc[:, self.close_col]\\n        for x in self.windows:\\n            dataf.loc[\\n                :, f\\\"feature_{self.close_col}_ROCP_{x}\\\"\\n            ] = close_series.pct_change(x)\\n\\n            dataf.loc[:, f\\\"feature_{self.close_col}_VOL_{x}\\\"] = (\\n                np.log1p(close_series).pct_change().rolling(x).std()\\n            )\\n\\n            dataf.loc[:, f\\\"feature_{self.close_col}_MA_gap_{x}\\\"] = (\\n                close_series / close_series.rolling(x).mean()\\n            )\\n\\n        dataf.loc[:, \\\"feature_RSI\\\"] = self._rsi(close_series)\\n        macd, macd_signal = self._macd(close_series)\\n        dataf.loc[:, \\\"feature_MACD\\\"] = macd\\n        dataf.loc[:, \\\"feature_MACD_signal\\\"] = macd_signal\\n        return dataf.bfill()\\n\\n    def _generate_features(self, dataf_list: list) -> pd.DataFrame:\\n        \\\"\\\"\\\"Add features for list of ticker DataFrames and concatenate.\\\"\\\"\\\"\\n        with Pool(self.num_cores) as p:\\n            feature_datafs = list(\\n                tqdm(\\n                    p.imap(self.feature_engineering, dataf_list),\\n                    desc=\\\"Generating features\\\",\\n                    total=len(dataf_list),\\n                )\\n            )\\n        return pd.concat(feature_datafs)\\n\\n    @staticmethod\\n    def _rsi(close: pd.Series, period: int = 14) -> pd.Series:\\n        \\\"\\\"\\\"\\n        See source https://github.com/peerchemist/finta\\n        and fix https://www.tradingview.com/wiki/Talk:Relative_Strength_Index_(RSI)\\n        \\\"\\\"\\\"\\n        delta = close.diff()\\n        up, down = delta.copy(), delta.copy()\\n        up[up < 0] = 0\\n        down[down > 0] = 0\\n\\n        gain = up.ewm(com=(period - 1), min_periods=period).mean()\\n        loss = down.abs().ewm(com=(period - 1), min_periods=period).mean()\\n\\n        rs = gain / loss\\n        return pd.Series(100 - (100 / (1 + rs)))\\n\\n    def _macd(\\n        self, close: pd.Series, span1=12, span2=26, span3=9\\n    ) -> Tuple[pd.Series, pd.Series]:\\n        \\\"\\\"\\\"Compute MACD and MACD signal.\\\"\\\"\\\"\\n        exp1 = self.__ema1(close, span1)\\n        exp2 = self.__ema1(close, span2)\\n        macd = 100 * (exp1 - exp2) / exp2\\n        signal = self.__ema1(macd, span3)\\n        return macd, signal\\n\\n    @staticmethod\\n    def __ema1(series: pd.Series, span: int) -> pd.Series:\\n        \\\"\\\"\\\"Exponential moving average\\\"\\\"\\\"\\n        a = 2 / (span + 1)\\n        return series.ewm(alpha=a).mean()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class KatsuFeatureGenerator(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Effective feature engineering setup based on Katsu's starter notebook.\n",
    "    Based on source by Katsu1110: https://www.kaggle.com/code1110/numeraisignals-starter-for-beginners\n",
    "\n",
    "    :param windows: Time interval to apply for window features: \\n\n",
    "    1. Percentage Rate of change \\n\n",
    "    2. Volatility \\n\n",
    "    3. Moving Average gap \\n\n",
    "    :param ticker_col: Columns with tickers to iterate over. \\n\n",
    "    :param close_col: Column name where you have closing price stored.\n",
    "    \"\"\"\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        windows: list,\n",
    "        ticker_col: str = \"ticker\",\n",
    "        close_col: str = \"close\",\n",
    "        num_cores: int = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.windows = windows\n",
    "        self.ticker_col = ticker_col\n",
    "        self.close_col = close_col\n",
    "        self.num_cores = num_cores if num_cores else os.cpu_count()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: Union[pd.DataFrame, NumerFrame]) -> NumerFrame:\n",
    "        \"\"\"Multiprocessing feature engineering.\"\"\"\n",
    "        tickers = dataf.loc[:, self.ticker_col].unique().tolist()\n",
    "        rich_print(\n",
    "            f\"Feature engineering for {len(tickers)} tickers using {self.num_cores} CPU cores.\"\n",
    "        )\n",
    "        dataf_list = [\n",
    "            x\n",
    "            for _, x in tqdm(\n",
    "                dataf.groupby(self.ticker_col), desc=\"Generating ticker DataFrames\"\n",
    "            )\n",
    "        ]\n",
    "        dataf = self._generate_features(dataf_list=dataf_list)\n",
    "        return NumerFrame(dataf)\n",
    "\n",
    "    def feature_engineering(self, dataf: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Feature engineering for single ticker.\"\"\"\n",
    "        close_series = dataf.loc[:, self.close_col]\n",
    "        for x in self.windows:\n",
    "            dataf.loc[\n",
    "                :, f\"feature_{self.close_col}_ROCP_{x}\"\n",
    "            ] = close_series.pct_change(x)\n",
    "\n",
    "            dataf.loc[:, f\"feature_{self.close_col}_VOL_{x}\"] = (\n",
    "                np.log1p(close_series).pct_change().rolling(x).std()\n",
    "            )\n",
    "\n",
    "            dataf.loc[:, f\"feature_{self.close_col}_MA_gap_{x}\"] = (\n",
    "                close_series / close_series.rolling(x).mean()\n",
    "            )\n",
    "\n",
    "        dataf.loc[:, \"feature_RSI\"] = self._rsi(close_series)\n",
    "        macd, macd_signal = self._macd(close_series)\n",
    "        dataf.loc[:, \"feature_MACD\"] = macd\n",
    "        dataf.loc[:, \"feature_MACD_signal\"] = macd_signal\n",
    "        return dataf.bfill()\n",
    "\n",
    "    def _generate_features(self, dataf_list: list) -> pd.DataFrame:\n",
    "        \"\"\"Add features for list of ticker DataFrames and concatenate.\"\"\"\n",
    "        with Pool(self.num_cores) as p:\n",
    "            feature_datafs = list(\n",
    "                tqdm(\n",
    "                    p.imap(self.feature_engineering, dataf_list),\n",
    "                    desc=\"Generating features\",\n",
    "                    total=len(dataf_list),\n",
    "                )\n",
    "            )\n",
    "        return pd.concat(feature_datafs)\n",
    "\n",
    "    @staticmethod\n",
    "    def _rsi(close: pd.Series, period: int = 14) -> pd.Series:\n",
    "        \"\"\"\n",
    "        See source https://github.com/peerchemist/finta\n",
    "        and fix https://www.tradingview.com/wiki/Talk:Relative_Strength_Index_(RSI)\n",
    "        \"\"\"\n",
    "        delta = close.diff()\n",
    "        up, down = delta.copy(), delta.copy()\n",
    "        up[up < 0] = 0\n",
    "        down[down > 0] = 0\n",
    "\n",
    "        gain = up.ewm(com=(period - 1), min_periods=period).mean()\n",
    "        loss = down.abs().ewm(com=(period - 1), min_periods=period).mean()\n",
    "\n",
    "        rs = gain / loss\n",
    "        return pd.Series(100 - (100 / (1 + rs)))\n",
    "\n",
    "    def _macd(\n",
    "        self, close: pd.Series, span1=12, span2=26, span3=9\n",
    "    ) -> Tuple[pd.Series, pd.Series]:\n",
    "        \"\"\"Compute MACD and MACD signal.\"\"\"\n",
    "        exp1 = self.__ema1(close, span1)\n",
    "        exp2 = self.__ema1(close, span2)\n",
    "        macd = 100 * (exp1 - exp2) / exp2\n",
    "        signal = self.__ema1(macd, span3)\n",
    "        return macd, signal\n",
    "\n",
    "    @staticmethod\n",
    "    def __ema1(series: pd.Series, span: int) -> pd.Series:\n",
    "        \"\"\"Exponential moving average\"\"\"\n",
    "        a = 2 / (span + 1)\n",
    "        return series.ewm(alpha=a).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "No existing directory found at \u001B[32m'\u001B[0m\u001B[34mkatsu_features_test\u001B[0m\u001B[32m'\u001B[0m. Creating directory\u001B[33m...\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">No existing directory found at <span style=\"color: #008000; text-decoration-color: #008000\">'</span><span style=\"color: #000080; text-decoration-color: #000080\">katsu_features_test</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span>. Creating directory<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 30;\n                var nbb_unformatted_code = \"# other\\nfrom numerblox.download import KaggleDownloader\\n# Get price data from Kaggle\\nhome_dir = \\\"katsu_features_test/\\\"\\nkd = KaggleDownloader(home_dir)\\nkd.download_training_data(\\\"code1110/yfinance-stock-price-data-for-numerai-signals\\\")\";\n                var nbb_formatted_code = \"# other\\nfrom numerblox.download import KaggleDownloader\\n\\n# Get price data from Kaggle\\nhome_dir = \\\"katsu_features_test/\\\"\\nkd = KaggleDownloader(home_dir)\\nkd.download_training_data(\\\"code1110/yfinance-stock-price-data-for-numerai-signals\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "from numerblox.download import KaggleDownloader\n",
    "# Get price data from Kaggle\n",
    "home_dir = \"katsu_features_test/\"\n",
    "kd = KaggleDownloader(home_dir)\n",
    "kd.download_training_data(\"code1110/yfinance-stock-price-data-for-numerai-signals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 31;\n                var nbb_unformatted_code = \"# other\\ndataf = create_numerframe(f\\\"{home_dir}/full_data.parquet\\\")\\ndataf.loc[:, 'friday_date'] = dataf['date']\\n# Take 500 ticker sample for test\\ndataf = dataf[dataf['ticker'].isin(dataf['ticker'].unique()[:500])]\";\n                var nbb_formatted_code = \"# other\\ndataf = create_numerframe(f\\\"{home_dir}/full_data.parquet\\\")\\ndataf.loc[:, \\\"friday_date\\\"] = dataf[\\\"date\\\"]\\n# Take 500 ticker sample for test\\ndataf = dataf[dataf[\\\"ticker\\\"].isin(dataf[\\\"ticker\\\"].unique()[:500])]\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "dataf = create_numerframe(f\"{home_dir}/full_data.parquet\")\n",
    "dataf.loc[:, 'friday_date'] = dataf['date']\n",
    "# Take 500 ticker sample for test\n",
    "dataf = dataf[dataf['ticker'].isin(dataf['ticker'].unique()[:500])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Feature engineering for \u001B[1;36m500\u001B[0m tickers using \u001B[1;36m8\u001B[0m CPU cores.\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Feature engineering for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span> tickers using <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> CPU cores.\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating ticker DataFrames:   0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da0a72adb48e482e861c6d8d0ac9ebff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 21:35:36,083 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-04-04 21:35:36,083 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating features:   0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "199fa512c8a44f16950b8035a6e6b602"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 21:35:36,083 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-04-04 21:35:36,088 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "2022-04-04 21:35:36,089 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "2022-04-04 21:35:36,089 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "2022-04-04 21:35:36,088 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-04-04 21:35:36,093 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "2022-04-04 21:35:36,095 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-04-04 21:35:36,102 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "2022-04-04 21:35:36,105 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-04-04 21:35:36,113 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "2022-04-04 21:35:36,109 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-04-04 21:35:36,117 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n",
      "2022-04-04 21:35:36,123 INFO numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-04-04 21:35:36,131 INFO numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mKatsuFeatureGenerator\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m2523144\u001B[0m, \u001B[1;36m21\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:00:07\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m059162\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">KatsuFeatureGenerator</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2523144</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:00:07</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">059162</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 32;\n                var nbb_unformatted_code = \"# other\\nkfpp = KatsuFeatureGenerator(windows=[20, 40, 60], num_cores=8)\\nnew_dataf = kfpp.transform(dataf)\";\n                var nbb_formatted_code = \"# other\\nkfpp = KatsuFeatureGenerator(windows=[20, 40, 60], num_cores=8)\\nnew_dataf = kfpp.transform(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "kfpp = KatsuFeatureGenerator(windows=[20, 40, 60], num_cores=8)\n",
    "new_dataf = kfpp.transform(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 features are generated in this test (3*3 window features + 3 non window features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          feature_close_ROCP_20  feature_close_VOL_20  \\\n19849675              -0.040000              0.011970   \n19854897              -0.012097              0.012178   \n\n          feature_close_MA_gap_20  feature_close_ROCP_40  \\\n19849675                 0.993480              -0.150442   \n19854897                 1.014808              -0.141856   \n\n          feature_close_VOL_40  feature_close_MA_gap_40  \\\n19849675              0.009611                 0.941269   \n19854897              0.009730                 0.964709   \n\n          feature_close_ROCP_60  feature_close_VOL_60  \\\n19849675              -0.185059              0.008468   \n19854897              -0.169492              0.008587   \n\n          feature_close_MA_gap_60  feature_RSI  feature_MACD  \\\n19849675                 0.899522    43.858443     -2.812436   \n19854897                 0.921139    48.401512     -2.428545   \n\n          feature_MACD_signal  \n19849675            -2.858512  \n19854897            -2.772518  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_close_ROCP_20</th>\n      <th>feature_close_VOL_20</th>\n      <th>feature_close_MA_gap_20</th>\n      <th>feature_close_ROCP_40</th>\n      <th>feature_close_VOL_40</th>\n      <th>feature_close_MA_gap_40</th>\n      <th>feature_close_ROCP_60</th>\n      <th>feature_close_VOL_60</th>\n      <th>feature_close_MA_gap_60</th>\n      <th>feature_RSI</th>\n      <th>feature_MACD</th>\n      <th>feature_MACD_signal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19849675</th>\n      <td>-0.040000</td>\n      <td>0.011970</td>\n      <td>0.993480</td>\n      <td>-0.150442</td>\n      <td>0.009611</td>\n      <td>0.941269</td>\n      <td>-0.185059</td>\n      <td>0.008468</td>\n      <td>0.899522</td>\n      <td>43.858443</td>\n      <td>-2.812436</td>\n      <td>-2.858512</td>\n    </tr>\n    <tr>\n      <th>19854897</th>\n      <td>-0.012097</td>\n      <td>0.012178</td>\n      <td>1.014808</td>\n      <td>-0.141856</td>\n      <td>0.009730</td>\n      <td>0.964709</td>\n      <td>-0.169492</td>\n      <td>0.008587</td>\n      <td>0.921139</td>\n      <td>48.401512</td>\n      <td>-2.428545</td>\n      <td>-2.772518</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 33;\n                var nbb_unformatted_code = \"# other\\nnew_dataf.sort_values([\\\"ticker\\\", \\\"date\\\"]).get_feature_data.tail(2)\";\n                var nbb_formatted_code = \"# other\\nnew_dataf.sort_values([\\\"ticker\\\", \\\"date\\\"]).get_feature_data.tail(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "new_dataf.sort_values([\"ticker\", \"date\"]).get_feature_data.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. EraQuantileProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 34;\n                var nbb_unformatted_code = \"# export\\nclass EraQuantileProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Transform features into quantiles on a per-era basis\\n\\n    :param num_quantiles: Number of buckets to split data into: \\\\n\\n    :param era_col: Era column name in the dataframe to perform each transformation \\\\n\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        num_quantiles: int = 50,\\n        era_col: str = \\\"friday_date\\\",\\n        features: list = None,\\n        num_cores: int = None,\\n    ):\\n        super().__init__()\\n        self.num_quantiles = num_quantiles\\n        self.era_col = era_col\\n        self.num_cores = num_cores if num_cores else os.cpu_count()\\n        self.features = features\\n\\n    def _process_eras(self, groupby_object):\\n        quantizer = QuantileTransformer(n_quantiles=self.num_quantiles, random_state=0)\\n        qt = lambda x: quantizer.fit_transform(x.values.reshape(-1, 1)).ravel()\\n\\n        column = groupby_object.transform(qt)\\n        return column\\n\\n    @display_processor_info\\n    def transform(\\n        self,\\n        dataf: Union[pd.DataFrame, NumerFrame],\\n    ) -> NumerFrame:\\n        \\\"\\\"\\\"Multiprocessing quantile transforms by era.\\\"\\\"\\\"\\n        self.features = self.features if self.features else dataf.feature_cols\\n        rich_print(\\n            f\\\"Quantiling for {len(self.features)} features using {self.num_cores} CPU cores.\\\"\\n        )\\n\\n        date_groups = dataf.groupby(self.era_col)\\n        groupby_objects = [date_groups[feature] for feature in self.features]\\n\\n        with Pool() as p:\\n            results = list(\\n                tqdm(\\n                    p.imap(self._process_eras, groupby_objects),\\n                    total=len(groupby_objects),\\n                )\\n            )\\n\\n        quantiles = pd.concat(results, axis=1)\\n        dataf[[f\\\"{feature}_quantile\\\" for feature in self.features]] = quantiles\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\nclass EraQuantileProcessor(BaseProcessor):\\n    \\\"\\\"\\\"\\n    Transform features into quantiles on a per-era basis\\n\\n    :param num_quantiles: Number of buckets to split data into: \\\\n\\n    :param era_col: Era column name in the dataframe to perform each transformation \\\\n\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        num_quantiles: int = 50,\\n        era_col: str = \\\"friday_date\\\",\\n        features: list = None,\\n        num_cores: int = None,\\n    ):\\n        super().__init__()\\n        self.num_quantiles = num_quantiles\\n        self.era_col = era_col\\n        self.num_cores = num_cores if num_cores else os.cpu_count()\\n        self.features = features\\n\\n    def _process_eras(self, groupby_object):\\n        quantizer = QuantileTransformer(n_quantiles=self.num_quantiles, random_state=0)\\n        qt = lambda x: quantizer.fit_transform(x.values.reshape(-1, 1)).ravel()\\n\\n        column = groupby_object.transform(qt)\\n        return column\\n\\n    @display_processor_info\\n    def transform(\\n        self,\\n        dataf: Union[pd.DataFrame, NumerFrame],\\n    ) -> NumerFrame:\\n        \\\"\\\"\\\"Multiprocessing quantile transforms by era.\\\"\\\"\\\"\\n        self.features = self.features if self.features else dataf.feature_cols\\n        rich_print(\\n            f\\\"Quantiling for {len(self.features)} features using {self.num_cores} CPU cores.\\\"\\n        )\\n\\n        date_groups = dataf.groupby(self.era_col)\\n        groupby_objects = [date_groups[feature] for feature in self.features]\\n\\n        with Pool() as p:\\n            results = list(\\n                tqdm(\\n                    p.imap(self._process_eras, groupby_objects),\\n                    total=len(groupby_objects),\\n                )\\n            )\\n\\n        quantiles = pd.concat(results, axis=1)\\n        dataf[[f\\\"{feature}_quantile\\\" for feature in self.features]] = quantiles\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class EraQuantileProcessor(BaseProcessor):\n",
    "    \"\"\"\n",
    "    Transform features into quantiles on a per-era basis\n",
    "\n",
    "    :param num_quantiles: Number of buckets to split data into: \\n\n",
    "    :param era_col: Era column name in the dataframe to perform each transformation \\n\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_quantiles: int = 50,\n",
    "        era_col: str = \"friday_date\",\n",
    "        features: list = None,\n",
    "        num_cores: int = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_quantiles = num_quantiles\n",
    "        self.era_col = era_col\n",
    "        self.num_cores = num_cores if num_cores else os.cpu_count()\n",
    "        self.features = features\n",
    "\n",
    "    def _process_eras(self, groupby_object):\n",
    "        quantizer = QuantileTransformer(n_quantiles=self.num_quantiles, random_state=0)\n",
    "        qt = lambda x: quantizer.fit_transform(x.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "        column = groupby_object.transform(qt)\n",
    "        return column\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(\n",
    "        self,\n",
    "        dataf: Union[pd.DataFrame, NumerFrame],\n",
    "    ) -> NumerFrame:\n",
    "        \"\"\"Multiprocessing quantile transforms by era.\"\"\"\n",
    "        self.features = self.features if self.features else dataf.feature_cols\n",
    "        rich_print(\n",
    "            f\"Quantiling for {len(self.features)} features using {self.num_cores} CPU cores.\"\n",
    "        )\n",
    "\n",
    "        date_groups = dataf.groupby(self.era_col)\n",
    "        groupby_objects = [date_groups[feature] for feature in self.features]\n",
    "\n",
    "        with Pool() as p:\n",
    "            results = list(\n",
    "                tqdm(\n",
    "                    p.imap(self._process_eras, groupby_objects),\n",
    "                    total=len(groupby_objects),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        quantiles = pd.concat(results, axis=1)\n",
    "        dataf[[f\"{feature}_quantile\" for feature in self.features]] = quantiles\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Quantiling for \u001B[1;36m12\u001B[0m features using \u001B[1;36m16\u001B[0m CPU cores.\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Quantiling for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> features using <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span> CPU cores.\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/12 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e010ae614454071a322e51bc729583a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "✅ Finished step \u001B[1mEraQuantileProcessor\u001B[0m. Output \u001B[33mshape\u001B[0m=\u001B[1m(\u001B[0m\u001B[1;36m2523144\u001B[0m, \u001B[1;36m33\u001B[0m\u001B[1m)\u001B[0m. Time taken for step: \n\u001B[1;34m0:03:29\u001B[0m\u001B[34m.\u001B[0m\u001B[1;34m624579\u001B[0m. ✅\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Finished step <span style=\"font-weight: bold\">EraQuantileProcessor</span>. Output <span style=\"color: #808000; text-decoration-color: #808000\">shape</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2523144</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span><span style=\"font-weight: bold\">)</span>. Time taken for step: \n<span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">0:03:29</span><span style=\"color: #000080; text-decoration-color: #000080\">.</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">624579</span>. ✅\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 35;\n                var nbb_unformatted_code = \"# other\\nera_quantiler = EraQuantileProcessor(num_quantiles=50)\\nera_dataf = era_quantiler.transform(new_dataf)\";\n                var nbb_formatted_code = \"# other\\nera_quantiler = EraQuantileProcessor(num_quantiles=50)\\nera_dataf = era_quantiler.transform(new_dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "era_quantiler = EraQuantileProcessor(num_quantiles=50)\n",
    "era_dataf = era_quantiler.transform(new_dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "          feature_close_ROCP_20  feature_close_VOL_20  \\\n19849675              -0.040000              0.011970   \n19854897              -0.012097              0.012178   \n\n          feature_close_MA_gap_20  feature_close_ROCP_40  \\\n19849675                 0.993480              -0.150442   \n19854897                 1.014808              -0.141856   \n\n          feature_close_VOL_40  feature_close_MA_gap_40  \\\n19849675              0.009611                 0.941269   \n19854897              0.009730                 0.964709   \n\n          feature_close_ROCP_60  feature_close_VOL_60  \\\n19849675              -0.185059              0.008468   \n19854897              -0.169492              0.008587   \n\n          feature_close_MA_gap_60  feature_RSI  ...  \\\n19849675                 0.899522    43.858443  ...   \n19854897                 0.921139    48.401512  ...   \n\n          feature_close_MA_gap_20_quantile  feature_close_ROCP_40_quantile  \\\n19849675                          0.246373                        0.034870   \n19854897                          0.454079                        0.035387   \n\n          feature_close_VOL_40_quantile  feature_close_MA_gap_40_quantile  \\\n19849675                       0.960689                          0.069401   \n19854897                       0.962643                          0.157835   \n\n          feature_close_ROCP_60_quantile  feature_close_VOL_60_quantile  \\\n19849675                        0.106101                       0.960712   \n19854897                        0.117604                       0.961300   \n\n          feature_close_MA_gap_60_quantile  feature_RSI_quantile  \\\n19849675                          0.045926              0.177787   \n19854897                          0.079544              0.326628   \n\n          feature_MACD_quantile  feature_MACD_signal_quantile  \n19849675               0.029794                      0.041381  \n19854897               0.040558                      0.039853  \n\n[2 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_close_ROCP_20</th>\n      <th>feature_close_VOL_20</th>\n      <th>feature_close_MA_gap_20</th>\n      <th>feature_close_ROCP_40</th>\n      <th>feature_close_VOL_40</th>\n      <th>feature_close_MA_gap_40</th>\n      <th>feature_close_ROCP_60</th>\n      <th>feature_close_VOL_60</th>\n      <th>feature_close_MA_gap_60</th>\n      <th>feature_RSI</th>\n      <th>...</th>\n      <th>feature_close_MA_gap_20_quantile</th>\n      <th>feature_close_ROCP_40_quantile</th>\n      <th>feature_close_VOL_40_quantile</th>\n      <th>feature_close_MA_gap_40_quantile</th>\n      <th>feature_close_ROCP_60_quantile</th>\n      <th>feature_close_VOL_60_quantile</th>\n      <th>feature_close_MA_gap_60_quantile</th>\n      <th>feature_RSI_quantile</th>\n      <th>feature_MACD_quantile</th>\n      <th>feature_MACD_signal_quantile</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19849675</th>\n      <td>-0.040000</td>\n      <td>0.011970</td>\n      <td>0.993480</td>\n      <td>-0.150442</td>\n      <td>0.009611</td>\n      <td>0.941269</td>\n      <td>-0.185059</td>\n      <td>0.008468</td>\n      <td>0.899522</td>\n      <td>43.858443</td>\n      <td>...</td>\n      <td>0.246373</td>\n      <td>0.034870</td>\n      <td>0.960689</td>\n      <td>0.069401</td>\n      <td>0.106101</td>\n      <td>0.960712</td>\n      <td>0.045926</td>\n      <td>0.177787</td>\n      <td>0.029794</td>\n      <td>0.041381</td>\n    </tr>\n    <tr>\n      <th>19854897</th>\n      <td>-0.012097</td>\n      <td>0.012178</td>\n      <td>1.014808</td>\n      <td>-0.141856</td>\n      <td>0.009730</td>\n      <td>0.964709</td>\n      <td>-0.169492</td>\n      <td>0.008587</td>\n      <td>0.921139</td>\n      <td>48.401512</td>\n      <td>...</td>\n      <td>0.454079</td>\n      <td>0.035387</td>\n      <td>0.962643</td>\n      <td>0.157835</td>\n      <td>0.117604</td>\n      <td>0.961300</td>\n      <td>0.079544</td>\n      <td>0.326628</td>\n      <td>0.040558</td>\n      <td>0.039853</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 36;\n                var nbb_unformatted_code = \"# other\\nera_dataf.get_feature_data.tail(2)\";\n                var nbb_formatted_code = \"# other\\nera_dataf.get_feature_data.tail(2)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "era_dataf.get_feature_data.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "⚠ \u001B[31mDeleting directory for \u001B[0m\u001B[31m'KaggleDownloader\u001B[0m\u001B[32m'\u001B[0m ⚠\nPath: \n\u001B[32m'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/katsu_features_test'\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">⚠ <span style=\"color: #800000; text-decoration-color: #800000\">Deleting directory for </span><span style=\"color: #800000; text-decoration-color: #800000\">'KaggleDownloader</span><span style=\"color: #008000; text-decoration-color: #008000\">'</span> ⚠\nPath: \n<span style=\"color: #008000; text-decoration-color: #008000\">'/Users/clepelaars/Desktop/crowdcent/repositories/numerai-blocks/nbs/katsu_features_test'</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 37;\n                var nbb_unformatted_code = \"# other\\n# hide\\nkd.remove_base_directory()\";\n                var nbb_formatted_code = \"# other\\n# hide\\nkd.remove_base_directory()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# other\n",
    "# hide\n",
    "kd.remove_base_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom preprocessors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are an almost unlimited number of ways to preprocess (selection, engineering and manipulation). We have only scratched the surface with the preprocessors currently implemented. We invite the Numerai community to develop Numerai Classic and Numerai Signals preprocessors.\n",
    "\n",
    "A new Preprocessor should inherit from `BaseProcessor` and implement a `transform` method. For efficient implementation, we recommend you use `NumerFrame` functionality for preprocessing. You can also support Pandas DataFrame input as long as the `transform` method returns a `NumerFrame`. This ensures that the Preprocessor still works within a full `numerai-blocks` pipeline. A template for new preprocessors is given below.\n",
    "\n",
    "To enable fancy logging output. Add the `@display_processor_info` decorator to the `transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 38;\n                var nbb_unformatted_code = \"# export\\nclass AwesomePreProcessor(BaseProcessor):\\n    \\\"\\\"\\\" TEMPLATE - Do some awesome preprocessing. \\\"\\\"\\\"\\n    def __init__(self):\\n        super().__init__()\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        # Do processing\\n        ...\\n        # Parse all contents of NumerFrame to the next pipeline step\\n        return NumerFrame(dataf)\";\n                var nbb_formatted_code = \"# export\\nclass AwesomePreProcessor(BaseProcessor):\\n    \\\"\\\"\\\"TEMPLATE - Do some awesome preprocessing.\\\"\\\"\\\"\\n\\n    def __init__(self):\\n        super().__init__()\\n\\n    @display_processor_info\\n    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\\n        # Do processing\\n        ...\\n        # Parse all contents of NumerFrame to the next pipeline step\\n        return NumerFrame(dataf)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# export\n",
    "class AwesomePreProcessor(BaseProcessor):\n",
    "    \"\"\" TEMPLATE - Do some awesome preprocessing. \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @display_processor_info\n",
    "    def transform(self, dataf: NumerFrame, *args, **kwargs) -> NumerFrame:\n",
    "        # Do processing\n",
    "        ...\n",
    "        # Parse all contents of NumerFrame to the next pipeline step\n",
    "        return NumerFrame(dataf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_misc.ipynb.\n",
      "Converted 01_download.ipynb.\n",
      "Converted 02_numerframe.ipynb.\n",
      "Converted 03_preprocessing.ipynb.\n",
      "Converted 04_model.ipynb.\n",
      "Converted 05_postprocessing.ipynb.\n",
      "Converted 06_modelpipeline.ipynb.\n",
      "Converted 07_evaluation.ipynb.\n",
      "Converted 08_key.ipynb.\n",
      "Converted 09_submission.ipynb.\n",
      "Converted 10_staking.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 39;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "# Run this cell to sync all changes with library\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 39;\n                var nbb_unformatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_formatted_code = \"# hide\\n# Run this cell to sync all changes with library\\nfrom nbdev.export import notebook2script\\n\\nnotebook2script()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}