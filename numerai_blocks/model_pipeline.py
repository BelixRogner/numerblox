# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/06_modelpipeline.ipynb (unless otherwise specified).

__all__ = ['ModelPipeline', 'ModelPipelineCollection']

# Cell
import uuid
from typing import List
from tqdm.auto import tqdm
from typeguard import typechecked
from rich import print as rich_print

from .dataset import Dataset
from .preprocessing import BaseProcessor, CopyPreProcessor, display_processor_info
from .model import BaseModel

# Cell
@typechecked
class ModelPipeline:
    """
    Execute all preprocessing, prediction and postprocessing for a given setup.

    :param model: A numerai-blocks Model that add prediction columns to a given input Dataset
    :param preprocessors: List of initialized (!) PreProcessors.
    :param postprocessors: List of initialized (!) PostProcessors.
    :param copy_first: Whether to copy the Dataset as a first preprocessing step.
    Highly recommended in order to avoid accidentally manipulating the original Dataset and/or DataFrame.
    :param pipeline_name: Name for display purposes
    """
    def __init__(self,
                 model: BaseModel,
                 preprocessors: List[BaseProcessor] = [],
                 postprocessors: List[BaseProcessor] = [],
                 copy_first = True,
                 pipeline_name: str = None):
        self.pipeline_name = pipeline_name if pipeline_name else uuid.uuid4().hex
        self.model = model
        self.copy_first = copy_first
        self.preprocessors = preprocessors
        self.postprocessors = postprocessors

    def preprocess(self, dataset: Dataset) -> Dataset:
        if self.copy_first:
            dataset = CopyPreProcessor()(dataset)
        for preprocessor in tqdm(self.preprocessors,
                                 desc=f"{self.pipeline_name} Preprocessing:",
                                 position=0):
            rich_print(f":car: Applying preprocessing {preprocessor.__class__.__name__} :car:")
            dataset = preprocessor(dataset)
        return dataset

    def postprocess(self, dataset: Dataset) -> Dataset:
        for postprocessor in tqdm(self.postprocessors,
                                  desc=f"{self.pipeline_name} Postprocessing: ",
                                  position=0):
            rich_print(f":car: Applying postprocessing {postprocessor.__class__.__name__} :car:")
            dataset = postprocessor(dataset)
        return dataset

    def pipeline(self, dataset: Dataset) -> Dataset:
        preprocessed_dataset = self.preprocess(dataset)
        prediction_dataset = self.model(preprocessed_dataset)
        processed_prediction_dataset = self.postprocess(prediction_dataset)
        rich_print(f":check_mark: Finished pipeline: {self.pipeline_name}")
        return processed_prediction_dataset

    def __call__(self, dataset: Dataset):
        return self.pipeline(dataset)

# Cell
@typechecked
class ModelPipelineCollection:
    """
    Execute multiple initialized ModelPipelines in a sequence.
    :param pipelines: List of initialized ModelPipelines.
    """
    def __init__(self, pipelines: List[ModelPipeline]):
        self.pipelines = {pipe.pipeline_name: pipe for pipe in pipelines}
        self.pipeline_names = list(self.pipelines.keys())

    def process_all_pipelines(self, dataset: Dataset) -> Dataset:
        for name, pipeline in tqdm(self.pipelines.items(),
                                   desc="Processing Pipeline Collection"):
            dataset = self.process_single_pipeline(dataset, name)
        return dataset

    def process_single_pipeline(self, dataset: Dataset, pipeline_name: str) -> Dataset:
        rich_print(f":construction_worker: [bold green]Processing model pipeline:[/bold green] '{pipeline_name}' :construction_worker:")
        pipeline = self.get_pipeline(pipeline_name)
        dataset = pipeline(dataset)
        return dataset

    def get_pipeline(self, pipeline_name: str) -> ModelPipeline:
        available_pipelines = self.pipeline_names
        assert pipeline_name in available_pipelines, f"Requested pipeline '{pipeline_name}', but only the following models are in the collection: '{available_pipelines}'."
        return self.pipelines[pipeline_name]

    def __call__(self, dataset: Dataset) -> Dataset:
        return self.process_all_pipelines(dataset=dataset)