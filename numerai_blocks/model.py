# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/04_model.ipynb (unless otherwise specified).

__all__ = ['BaseModel', 'JoblibModel', 'CatboostModel', 'LGBMModel', 'ConstantModel', 'AwesomeModel']

# Cell
import gc
import uuid
import joblib
import numpy as np
from tqdm.auto import tqdm
from pathlib import Path
from typeguard import typechecked
from abc import ABC, abstractmethod
from rich import print as rich_print
import lightgbm as lgb
from catboost import CatBoostRegressor
from sklearn.dummy import DummyRegressor

from .dataset import Dataset, create_dataset
from .preprocessing import display_processor_info

# Cell
@typechecked
class BaseModel(ABC):
    """
    Setup for model prediction on a Dataset.

    :param model_directory: Main directory from which to read in models.
    :param file_suffix: File format to load (For example, .joblib, .cbm or .lgb)
    :param model_name: Name that will be used to create column names and for display purposes.
    """
    def __init__(self, model_directory: str, file_suffix: str, model_name: str = None, *args, **kwargs):
        self.model_directory = Path(model_directory)
        self.__dict__.update(*args, **kwargs)
        self.model_name = model_name if model_name else uuid.uuid4().hex
        self.prediction_col_name = f"prediction_{self.model_name}"
        self.description = f"{self.__class__.__name__}: '{self.model_name}' prediction"

        self.file_suffix = file_suffix
        self.model_paths = list(self.model_directory.glob(f'*.{self.file_suffix}'))
        if self.file_suffix:
            assert self.model_paths, f"No {self.file_suffix} files found in {self.model_directory}."
        self.total_models = len(self.model_paths)

    @abstractmethod
    def predict(self, dataset: Dataset) -> Dataset:
        """ Return Dataset with column added for prediction. """
        ...
        return Dataset(**dataset.__dict__)

    def __call__(self, dataset: Dataset) -> Dataset:
        return self.predict(dataset)

# Cell
@typechecked
class JoblibModel(BaseModel):
    """ Load and predict for arbitrary models saved as .joblib. """
    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):
        file_suffix = 'joblib'
        super(JoblibModel, self).__init__(model_directory=model_directory,
                                          file_suffix=file_suffix,
                                          model_name=model_name,
                                          *args, **kwargs)

    @display_processor_info
    def predict(self, dataset: Dataset, *args, **kwargs) -> Dataset:
        dataset.dataf.loc[:, self.prediction_col_name] = np.zeros(len(dataset.dataf))
        feature_df = dataset.get_feature_data
        models = self._load_models()
        for model in tqdm(models, desc=self.description):
            predictions = model.predict(feature_df, *args, **kwargs)
            dataset.dataf.loc[:, self.prediction_col_name] += predictions / self.total_models
        del models; gc.collect()
        return Dataset(**dataset.__dict__)

    def _load_models(self) -> list:
        return [joblib.load(path) for path in self.model_paths]

# Cell
@typechecked
class CatboostModel(BaseModel):
    """ Load and predict with all .cbm models (CatBoostRegressor) in directory. """
    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):
        file_suffix = 'cbm'
        super(CatboostModel, self).__init__(model_directory=model_directory,
                                            file_suffix=file_suffix,
                                            model_name=model_name, *args, **kwargs)

    @display_processor_info
    def predict(self, dataset: Dataset) -> Dataset:
        dataset.dataf.loc[:, f"prediction_{self.model_name}"] = 0
        feature_df = dataset.get_feature_data
        models = self._load_models()
        for model in tqdm(models, desc=self.description):
            predictions = model.predict(feature_df)
            dataset.dataf.loc[:, self.model_name] += predictions / self.total_models
        del models; gc.collect()
        return Dataset(**dataset.__dict__)

    def _load_models(self) -> list:
        return [CatBoostRegressor().load_model(path) for path in self.model_paths]

# Cell
@typechecked
class LGBMModel(BaseModel):
    """ Load and predict with all .lgb models (LightGBM) in directory. """
    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):
        file_suffix = 'lgb'
        super(LGBMModel, self).__init__(model_directory=model_directory,
                                        file_suffix=file_suffix,
                                        model_name=model_name, *args, **kwargs)

    @display_processor_info
    def predict(self, dataset: Dataset) -> Dataset:
        dataset.dataf.loc[:, f"prediction_{self.model_name}"] = 0
        feature_df = dataset.get_feature_data
        models = self._load_models()
        for model in tqdm(models, desc=self.description):
            predictions = model.predict(feature_df)
            dataset.dataf.loc[:, self.model_name] += predictions / self.total_models
        del models; gc.collect()
        return Dataset(**dataset.__dict__)

    def _load_models(self) -> list:
        return [lgb.Booster(str(path)) for path in self.model_paths]

# Cell
class ConstantModel(BaseModel):
    """
    WARNING: Only use this Model for testing purposes.
    Create constant prediction.
    """
    def __init__(self, constant: float = 0.5, model_name: str = None):
        self.constant = constant
        file_suffix = ''
        model_name = model_name if model_name else f"constant_{self.constant}"
        super(ConstantModel, self).__init__(model_directory="",
                                            file_suffix=file_suffix,
                                            model_name=model_name)
        self.clf = DummyRegressor(strategy='constant', constant=constant).fit([0.], [0.])

    def predict(self, dataset: Dataset) -> Dataset:
        feature_df = dataset.get_feature_data
        dataset.dataf.loc[:, f"prediction_{self.model_name}"] = self.clf.predict(feature_df)
        return Dataset(**dataset.__dict__)

# Cell
@typechecked
class AwesomeModel(BaseModel):
    """
    - TEMPLATE -
    Predict with arbitrary model formats.
    """
    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):
        file_suffix = 'anything'
        super(AwesomeModel, self).__init__(model_directory=model_directory,
                                           file_suffix=file_suffix,
                                           model_name=model_name, *args, **kwargs)

    @display_processor_info
    def predict(self, dataset: Dataset) -> Dataset:
        """ Return Dataset with column(s) added for prediction(s). """
        ...
        dataset.dataf.loc[:, f"prediction_{self.model_name}"] = 0
        feature_df = dataset.get_feature_data
        ...
        # Parse all contents of Dataset to the next pipeline step
        return Dataset(**dataset.__dict__)