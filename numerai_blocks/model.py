# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/04_model.ipynb (unless otherwise specified).

__all__ = ['BaseModel', 'DirectoryModel', 'JoblibModel', 'CatBoostModel', 'LGBMModel', 'ConstantModel', 'RandomModel',
           'AwesomeModel', 'AwesomeDirectoryModel']

# Cell
import gc
import uuid
import joblib
import numpy as np
from tqdm.auto import tqdm
from pathlib import Path
from typeguard import typechecked
from abc import ABC, abstractmethod
import lightgbm as lgb
from catboost import CatBoost
from sklearn.dummy import DummyRegressor

from .dataset import Dataset, create_dataset
from .preprocessing import display_processor_info

# Cell
@typechecked
class BaseModel(ABC):
    """
    Setup for model prediction on a Dataset.

    :param model_directory: Main directory from which to read in models.
    :param file_suffix: File format to load (For example, .joblib, .cbm or .lgb)
    :param model_name: Name that will be used to create column names and for display purposes.
    """
    def __init__(self, model_directory: str, file_suffix: str, model_name: str = None, *args, **kwargs):
        self.model_directory = Path(model_directory)
        self.__dict__.update(*args, **kwargs)
        self.model_name = model_name if model_name else uuid.uuid4().hex
        self.prediction_col_name = f"prediction_{self.model_name}"
        self.description = f"{self.__class__.__name__}: '{self.model_name}' prediction"

        self.file_suffix = file_suffix
        self.model_paths = list(self.model_directory.glob(f'*.{self.file_suffix}'))
        if self.file_suffix:
            assert self.model_paths, f"No {self.file_suffix} files found in {self.model_directory}."
        self.total_models = len(self.model_paths)

    @abstractmethod
    def predict(self, dataset: Dataset) -> Dataset:
        """ Return Dataset with column added for prediction. """
        ...
        return Dataset(**dataset.__dict__)

    def __call__(self, dataset: Dataset) -> Dataset:
        return self.predict(dataset)

# Cell
class DirectoryModel(BaseModel):
    """
    Base class implementation for JoblibModel, CatBoostModel, LGBMModel, etc.
    Walks through every file with given file_suffix in a directory.
    """
    def __init__(self, model_directory: str, file_suffix: str, model_name: str = None, *args, **kwargs):
        super(DirectoryModel, self).__init__(model_directory=model_directory,
                                             file_suffix=file_suffix,
                                             model_name=model_name,
                                             *args, **kwargs
                                             )

    @display_processor_info
    def predict(self, dataset: Dataset, *args, **kwargs) -> Dataset:
        """
        Use all recognized models to make predictions and average them out.
        :param dataset: A Preprocessed dataset where all its features can be passed to the model predict method.
        *args, **kwargs will be parsed into the model.predict method.
        :return: A new dataset with prediction column added.
        """
        dataset.dataf.loc[:, self.prediction_col_name] = np.zeros(len(dataset.dataf))
        feature_df = dataset.get_feature_data
        models = self.load_models()
        for model in tqdm(models, desc=self.description, position=1):
            predictions = model.predict(feature_df, *args, **kwargs)
            dataset.dataf.loc[:, self.prediction_col_name] += predictions / self.total_models
        del models; gc.collect()
        return Dataset(**dataset.__dict__)

    @abstractmethod
    def load_models(self) -> list:
        """ Instantiate all models detected in self.model_paths. """
        ...


# Cell
@typechecked
class JoblibModel(DirectoryModel):
    """ Load and predict for arbitrary models saved as .joblib. """
    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):
        file_suffix = 'joblib'
        super(JoblibModel, self).__init__(model_directory=model_directory,
                                          file_suffix=file_suffix,
                                          model_name=model_name,
                                          *args, **kwargs
                                          )

    def load_models(self) -> list:
        return [joblib.load(path) for path in self.model_paths]

# Cell
@typechecked
class CatBoostModel(DirectoryModel):
    """ Load and predict with all .cbm models (CatBoostRegressor) in directory. """
    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):
        file_suffix = 'cbm'
        super(CatBoostModel, self).__init__(model_directory=model_directory,
                                            file_suffix=file_suffix,
                                            model_name=model_name,
                                            *args, **kwargs
                                            )

    def load_models(self) -> list:
        return [CatBoost().load_model(path) for path in self.model_paths]

# Cell
@typechecked
class LGBMModel(DirectoryModel):
    """ Load and predict with all .lgb models (LightGBM) in directory. """
    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):
        file_suffix = 'lgb'
        super(LGBMModel, self).__init__(model_directory=model_directory,
                                        file_suffix=file_suffix,
                                        model_name=model_name,
                                        *args, **kwargs
                                        )

    def load_models(self) -> list:
        return [lgb.Booster(model_file=str(path)) for path in self.model_paths]

# Cell
class ConstantModel(BaseModel):
    """
    WARNING: Only use this Model for testing purposes.
    Create constant prediction.
    """
    def __init__(self, constant: float = 0.5, model_name: str = None):
        self.constant = constant
        file_suffix = ''
        model_name = model_name if model_name else f"constant_{self.constant}"
        super(ConstantModel, self).__init__(model_directory="",
                                            file_suffix=file_suffix,
                                            model_name=model_name
                                            )
        self.clf = DummyRegressor(strategy='constant', constant=constant).fit([0.], [0.])

    def predict(self, dataset: Dataset) -> Dataset:
        dataset.dataf.loc[:, self.prediction_col_name] = self.clf.predict(dataset.get_feature_data)
        return Dataset(**dataset.__dict__)

# Cell
class RandomModel(BaseModel):
    """
    WARNING: Only use this Model for testing purposes.
    Create uniformly distributed predictions.
    """
    def __init__(self, model_name: str = None):
        file_suffix = ''
        model_name = model_name if model_name else "random"
        super(RandomModel, self).__init__(model_directory="",
                                          file_suffix=file_suffix,
                                          model_name=model_name
                                          )

    def predict(self, dataset: Dataset) -> Dataset:
        dataset.dataf.loc[:, self.prediction_col_name] = np.random.uniform(size=len(dataset.dataf))
        return Dataset(**dataset.__dict__)

# Cell
@typechecked
class AwesomeModel(BaseModel):
    """
    - TEMPLATE -
    Predict with arbitrary model formats.
    """
    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):
        file_suffix = 'anything'
        super(AwesomeModel, self).__init__(model_directory=model_directory,
                                           file_suffix=file_suffix,
                                           model_name=model_name,
                                           *args, **kwargs
                                           )

    @display_processor_info
    def predict(self, dataset: Dataset) -> Dataset:
        """ Return Dataset with column(s) added for prediction(s). """
        ...
        dataset.dataf.loc[:, self.prediction_col_name] = 0
        feature_df = dataset.get_feature_data
        # Predict and add to new column
        ...
        # Parse all contents of Dataset to the next pipeline step
        return Dataset(**dataset.__dict__)

# Cell
@typechecked
class AwesomeDirectoryModel(DirectoryModel):
    """
    - TEMPLATE -
    Load in all models of arbitrary file format where model has .predict method.
    """
    def __init__(self, model_directory: str, model_name: str = None, *args, **kwargs):
        file_suffix = 'anything'
        super(AwesomeDirectoryModel, self).__init__(model_directory=model_directory,
                                                    file_suffix=file_suffix,
                                                    model_name=model_name,
                                                    *args, **kwargs
                                                    )

    def load_models(self) -> list:
        """ Instantiate all models and return as a list. (abstract method) """
        ...