# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/07_evaluation.ipynb (unless otherwise specified).

__all__ = ['BaseEvaluator', 'NumeraiClassicEvaluator', 'NumeraiSignalsEvaluator']

# Cell
import numpy as np
import pandas as pd
from typing import Tuple
from abc import ABC, abstractmethod

from .dataset import Dataset, create_dataset
from .postprocessing import FeatureNeutralizer

# Cell
class BaseEvaluator(ABC):
    def __init__(self, era_col: str = "era"):
        self.era_col = era_col

    def full_evaluation(self, dataset: Dataset) -> Tuple[pd.DataFrame, pd.DataFrame]:
        validation_stats = {}
        validations_by_era = {}

        for pred_col, target_col in zip(dataset.prediction_cols, dataset.target_cols):
            self.evaluation_one_col(dataset=dataset,
                                    pred_col=pred_col,
                                    target_col=target_col)
        return validation_stats, validations_by_era

    @abstractmethod
    def evaluation_one_col(self, dataset: Dataset, pred_col: str, target_col: str):
        val_corrs = self._per_era_corrs(dataf=dataset.dataf,
                                        pred_col=pred_col,
                                        target_col=target_col)


    def _per_era_corrs(self, dataf: pd.DataFrame, pred_col: str,
                       target_col: str) -> pd.Series:
        """ Correlation between prediction and target for each era. """
        return dataf.groupby(dataf[self.era_col])\
            .apply(lambda d: self._normalize_uniform(d[pred_col])
                   .corr(self._normalize_uniform(d[target_col])))

    def _tb200(self, ):
        ...

    def _mean_std_sharpe(self, era_corrs: pd.Series) -> Tuple[np.float64, np.float64, np.float64]:
        mean = era_corrs.mean()
        std = era_corrs.std(ddof=0)
        sharpe = mean / std
        return mean, std, sharpe

    def _max_drawdown(self, era_corrs: pd.Series) -> np.float64:
        # arbitrarily large window
        rolling_max = (era_corrs + 1).cumprod().rolling(window=9000,
                                                        min_periods=1).max()
        daily_value = (era_corrs + 1).cumprod()
        max_drawdown = -((rolling_max - daily_value) / rolling_max).max()
        return max_drawdown

    def _mmc(self, ):
        ...

    def _apy(self, era_corrs: pd.Series) -> np.float64:
        payout_scores = era_corrs.clip(-0.25, 0.25)
        payout_daily_value = (payout_scores + 1).cumprod()
        apy = (
                      (
                              (payout_daily_value.dropna().iloc[-1])
                              ** (1 / len(payout_scores))
                      )
                      ** 49  # 52 weeks of compounding minus 3 for stake compounding lag
                      - 1
              ) * 100
        return apy

    def _max_feature_exposure(self):
        ...

    def _example_correlation(self, dataset: Dataset,
                             pred_col: str, example_col: str):
        """ Get correlations with example predictions. """
        return self._per_era_corrs(dataf=dataset.dataf,
                                   pred_col=pred_col,
                                   target_col=example_col,
                                   ).mean()

    @staticmethod
    def feature_neutral_mean(dataset: Dataset, pred_col: str) -> np.float64:
        fn = FeatureNeutralizer(pred_name=pred_col,
                                proportion=1.0)
        neutralized_dataset = fn.transform(dataset=dataset)
        return neutralized_dataset[fn.final_col_name].mean()

    @staticmethod
    def _normalize_uniform(df: pd.DataFrame) -> pd.Series:
        x = (df.rank(method="first") - 0.5) / len(df)
        return pd.Series(x, index=df.index)


# Cell
class NumeraiClassicEvaluator(BaseEvaluator):
    def __init__(self):
        super().__init__()

# Cell
class NumeraiSignalsEvaluator(BaseEvaluator):
    def __init__(self):
        super().__init__()